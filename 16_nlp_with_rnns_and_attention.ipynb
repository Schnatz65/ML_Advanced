{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 16 – Natural Language Processing with RNNs and Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code in chapter 16._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"nlp\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting a sequence into batches of shuffled windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's split the sequence 0 to 14 into windows of length 5, each shifted by 2 (e.g.,`[0, 1, 2, 3, 4]`, `[2, 3, 4, 5, 6]`, etc.), then shuffle them, and split them into inputs (the first 4 steps) and targets (the last 4 steps) (e.g., `[2, 3, 4, 5, 6]` would be split into `[[2, 3, 4, 5], [3, 4, 5, 6]]`), then create batches of 3 such input/target pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________ Batch 0 \n",
      "X_batch\n",
      "[[6 7 8 9]\n",
      " [2 3 4 5]\n",
      " [4 5 6 7]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 7  8  9 10]\n",
      " [ 3  4  5  6]\n",
      " [ 5  6  7  8]]\n",
      "____________________ Batch 1 \n",
      "X_batch\n",
      "[[ 0  1  2  3]\n",
      " [ 8  9 10 11]\n",
      " [10 11 12 13]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 1  2  3  4]\n",
      " [ 9 10 11 12]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_steps = 5\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
    "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
    "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
    "dataset = dataset.batch(3).prefetch(1)\n",
    "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
    "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
    "    print(X_batch.numpy())\n",
    "    print(\"=\" * 5, \"\\nY_batch\")\n",
    "    print(Y_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "1122304/1115394 [==============================] - 1s 0us/step\n",
      "1130496/1115394 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in previous versions of this code, we used `dataset.repeat()` now to make the dataset \"infinite\", and later in the notebook we set the `steps_per_epoch` argument when calling the `model.fit()` method. This was needed to work around some TensorFlow bugs. However, since these bugs have now been fixed, we can simplify the code: no need for `dataset.repeat()` or `steps_per_epoch` anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the following code may take up to 24 hours to run, depending on your hardware. If you use a GPU, it may take just 1 or 2 hours, or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the `GRU` class will only use the GPU (if you have one) when using the default values for the following arguments: `activation`, `recurrent_activation`, `recurrent_dropout`, `unroll`, `use_bias` and `reset_after`. This is why I commented out `recurrent_dropout=0.2` (compared to the book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31368/31368 [==============================] - 2838s 90ms/step - loss: 1.6206\n",
      "Epoch 2/10\n",
      "31368/31368 [==============================] - 2866s 91ms/step - loss: 1.5369\n",
      "Epoch 3/10\n",
      "31368/31368 [==============================] - 2865s 91ms/step - loss: 1.5174\n",
      "Epoch 4/10\n",
      "31368/31368 [==============================] - 2850s 91ms/step - loss: 1.5059\n",
      "Epoch 5/10\n",
      "31368/31368 [==============================] - 2873s 92ms/step - loss: 1.4984\n",
      "Epoch 6/10\n",
      "31368/31368 [==============================] - 2802s 89ms/step - loss: 1.4931\n",
      "Epoch 7/10\n",
      "31368/31368 [==============================] - 2814s 90ms/step - loss: 1.4895\n",
      "Epoch 8/10\n",
      "31368/31368 [==============================] - 2831s 90ms/step - loss: 1.4867\n",
      "Epoch 9/10\n",
      "31368/31368 [==============================] - 2878s 92ms/step - loss: 1.4845\n",
      "Epoch 10/10\n",
      "31368/31368 [==============================] - 2853s 91ms/step - loss: 1.4824\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `predict_classes()` method is deprecated. Instead, we must use `np.argmax(model(X_new), axis=-1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = preprocess([\"How are yo\"])\n",
    "#Y_pred = model.predict_classes(X_new)\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1,\n",
       "        0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there i should be to the chaster\n",
      "to make a baptista\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this verier,\n",
      "and i'll perck it in our doiel to your\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th no fmepuless.; rebea cintp a blay o\n",
      "baptistom's'\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: once again, I commented out `recurrent_dropout=0.2` (compared to the book) so you can get GPU acceleration (if you have one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 28s 83ms/step - loss: 2.6200\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 2.2410\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 2.1105\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 2.0368\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.9860\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.9488\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.9205\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 1.8985\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 1.8797\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 1.8655\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.8533\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.8412\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.8328\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.8233\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.8160\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.8072\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.8008\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.7936\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.7885 1\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.7851\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.7814\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7760\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7729\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7697\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7645\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7606\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7583\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7564\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7538\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7496\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7470\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7455\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7432\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7408\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7376\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7363\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7343\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7308\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7286\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7284\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7269\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7252\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.7233\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7233\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.7222\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7193\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7181\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 1.7175\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.7146\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.7138\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model with different batch sizes, we need to create a stateless copy. We can get rid of dropout since it is only used during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the weights, we first need to build the model (so the weights get created):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timins\n",
      "as eye your city blood have dis, him.\n",
      "pear n\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the IMDB dataset easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    id_to_word[id_] = token\n",
    "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test', 'unsupervised'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 53), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Cons']], dtype=object)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0], dtype=int64)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "12\n",
      "11\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
    "for word in b\"This movie was faaaaaantastic\".split():\n",
    "    print(word_to_id.get(word) or vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]], dtype=int64)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = datasets[\"train\"].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  22   11   28 ...    0    0    0]\n",
      " [   6   21   70 ...    0    0    0]\n",
      " [4099 6881    1 ...    0    0    0]\n",
      " ...\n",
      " [  22   12  118 ...  331 1047    0]\n",
      " [1757 4101  451 ...    0    0    0]\n",
      " [3365 4392    6 ...    0    0    0]], shape=(32, 60), dtype=int64)\n",
      "tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_set.take(1):\n",
    "    print(X_batch)\n",
    "    print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 56s 65ms/step - loss: 0.5305 - accuracy: 0.7281\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.3459 - accuracy: 0.8549\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1934 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1360 - accuracy: 0.9503\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1032 - accuracy: 0.9634\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                           mask_zero=True, # not shown in the book\n",
    "                           input_shape=[None]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using manual masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 56s 65ms/step - loss: 0.5425 - accuracy: 0.7156\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.3481 - accuracy: 0.8548\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1759 - accuracy: 0.9378\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1232 - accuracy: 0.9562\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1103 - accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "embed_size = 128\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFHUB_CACHE_DIR = os.path.join(os.curdir, \"my_tfhub_cache\")\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = TFHUB_CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\my_tfhub_cache\\82c4aaf4250ffb09088bd48368ee7fd00e5464fe.descriptor.txt\n",
      ".\\my_tfhub_cache\\82c4aaf4250ffb09088bd48368ee7fd00e5464fe\\saved_model.pb\n",
      ".\\my_tfhub_cache\\82c4aaf4250ffb09088bd48368ee7fd00e5464fe\\assets\\tokens.txt\n",
      ".\\my_tfhub_cache\\82c4aaf4250ffb09088bd48368ee7fd00e5464fe\\variables\\variables.data-00000-of-00001\n",
      ".\\my_tfhub_cache\\82c4aaf4250ffb09088bd48368ee7fd00e5464fe\\variables\\variables.index\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(TFHUB_CACHE_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7267\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5130 - accuracy: 0.7493\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5082 - accuracy: 0.7522\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5047 - accuracy: 0.7544\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5018 - accuracy: 0.7557\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embed_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths)\n",
    "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
    "    outputs=[Y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 7s 131ms/step - loss: 4.6054\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 4.6031\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
    "seq_lengths = np.full([1000], 15)\n",
    "\n",
    "history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, None, 10)          660       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 20)          1320      \n",
      "=================================================================\n",
      "Total params: 1,980\n",
      "Trainable params: 1,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(10, return_sequences=True, input_shape=[None, 10]),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims += 1 # max_dims must be even\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 201\n",
    "max_dims = 512\n",
    "pos_emb = PositionalEncoding(max_steps, max_dims)\n",
    "PE = pos_emb(np.zeros((1, max_steps, max_dims), np.float32))[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure positional_embedding_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAFgCAYAAAArYcg8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOxdeZwUxfX/9swesCz3LSiigAqIoKByKCwggqIiGsErmkOjxqhRkxijUaMxag79xSvxjveNioJy7CJeCAiLiAoqKiCgnAu7y14z7/fH29qtqanq7pnp7p3F/n4+/ZmZnp6unnqvXn3fq1dVFhEhRIgQIUKECBEixI8HkaZ+gBAhQoQIESJEiBDBIiSAIUKECBEiRIgQPzKEBDBEiBAhQoQIEeJHhpAAhggRIkSIECFC/MgQEsAQIUKECBEiRIgfGUICGCJEiBAhQoQI8SNDSABDhAgRIkSIECF+ZMh6AmhZ1qWWZS21LKvasqzHHK79rWVZmy3LKrMs6xHLsvIDeswQIUKECBEiRIhmg6wngAA2ArgFwCN2F1mWdTyAawCMA7A/gAMA3OT3w4UIESJEiBAhQjQ3ZD0BJKKXiegVANscLj0PwMNEtIqIdgC4GcD5Pj9eiBAhQoQIESJEs0NOUz+AhxgA4FXp8woAXS3L6khESeTRsqwLAVwIAB2BI/bPy0O8XTvEO3cGcryrll27LKxfH0VdXeO5ggLCfvvFkZ+f3dvwxWIxRKPRJivfKi9HZOtWWLt3A/E4AIBatgS1b494x45AxBv/hQjYujWCzZsjohgAQNu2hJ49Ywnq0NR1ko2IbN8ObNuGSGVlwzlq3RrxDh1A7dp5Vk48DmzeHMGWLYly79Iljm7d4rAsz4ryDFmjL0SIfP89rLIyWFVVfM6yQO3aId6xI6hVK8+Kqq0FvvsuirKyRoFEIsA++8TRsWM8e+okyxCLxRAFEN24kW1ebS1/EY0i3qED4p06AXl5npVXWWnhu+8iqKxslFNuLrDvvjG0bp09fVNW6kt1NcupogKIxfhcXh7inToh3qED4OHzlpVZ2Lgxipoa+exHW4moc8Y3J6JmcYCHgR+z+f4rABOlz7kACMD+Tvcesu++RBMnEuXkEPXrR7RhA2WKrVuJpk8nAogGDSJ68EGihx8muuMOovbtiVq0IPr734lisYyL8g1btmxpusKffpooGiXq3p3o4ouJXn+d6J//JDriCK7UCROIKiszLmbVKqJhw/iWEycSPf440UMPEV1zDVFuLlHXrkQzZzZe36R1km2Ix7miAKo95BCia68levNNouuuI9pvP67Uyy/n6zLErFlEPXrwLS+4gOjJJ4n+8x+i887jc4MHsyyzDVmhL5WVRCefzBVVVER0220sp4svJmrThs8/+qgnRd15J1FBAdu3P/+Z5XT33UTjx3MxU6cSrVmz1ZOy9jZsW7mS6NBD2fD85CdE99xD9OqrRKedxrawoIDovfcyLqemhuiXv2R5dOlC9O9/s937xz+IBgwgsixuyrW1HvwpD5AVbUjGhx8Sde7MHfkFFxA99hjRM88QHXMMV+p++xGtW5dxMVu3Nt6yf3+i//2P6JFHiP7yFyIAS8kLXuXFTYI4XBDAFQDOkD53rCeAHZ3ufdhhh3GNv/suUWEh0YEHZiTA6mqio4/mdvyXv/BnGRs3Ep1yCtf+ddelXUzauPzyy+nyyy93vK7JGt7DD7MVGj2aaNeu5O8feYS/z5AEbtrE/LJzZ+abKk8pLWV7DBC9+CKfC7JOZs+eTbNnzw6svJQQixFdcglXzoUX0pbNm5O/v+IK/v53v8uIBC5aRJSXRzRwINH77yd//+qrLMOCAqKVK9Muxhc0eee1cye3I8tiQqGivJzbUSTCnVgGeOQRFvfkyURff534XSzGDm9uLtH++9fR9u0ZFbX34bPPqK5nT+5/5s5N/v6bb4j69iVq25Zo+fKMirr0UpbTVVcRlZUlfldR0UgOJ00iqqvLqChP0ORtSMZrrxG1bEnUuzfR6tXJ37/zDjtVBx9MlMFzV1dzs83PJ/rvf5PJeEgAk79/GsBfpc9jAWx2c+8GAkjEPUybNizg7793kpMWl13GNfv88+Zr4nGin/+cr5s1K61i0sbo0aNp9OjRjtc1ScN76ilqiPBVVJivEyTx+OPTclVraoiOPZbb8ooV5uuqqoiOPJJV4ssvg62TRx99lB71KDLjOX772wRyp62XeLyRJKbp6WzezJG//fdnj9iEDRs4WnvIIcxpsgVN2nnFYqzkOTns4ZhQUcHXRaNEr7ySVlEffMAkffx4++a4cCFRTk6cTjvNk8Dw3oHt24m6d6dY585EH31kvu7bb4n23Ze9nc8/T6uo//63kfzZ4d//5utuvTWtYjxF1hDA0lJuS0OHsmEy4e23OQQ+dKg+gOGAeJzoF7/g+n/qKf01PxoCCM5TbAHgbwCeqH+fo7luIoDNAPoDaA+gGMBtbspIIIBEHHLIzSU6+2wbMenxzDNcq1dc4XxtZSXRYYcRdejADl5QyFoCuGkTUbt2RKNGMfNygrBm//xnykUJ/vLkk87Xfv01R/uHDCFavz4kgPTuu1x5l1zS0IsbdSUWa/R0SkpSKqamhodAWrZ0F/SYN499gvPPT6kYX9Gkndfdd3O9P/KI87W7drGnU1hI9N13KRXz3XccSe/d256kC9xwQzkBRPffn1Ixey/OP58oGqXt8+Y5X7t6NY/bHnJI8tCSA95+m/nLxInOkb14nGjaNPYJPvggpWI8R1YQwJoazjPp2tWdkr/2GlfetGkpF/Wvf3Gz/dOfzNf8mAjgjfVDufJxI4D9AJQD2E+69koA3wPYBeBRAPluykgigERE11/P1aMLxxuwZg1Rq1ZEI0eyvrjBF19wdGnYsOByLrKWAE6fzmEEt95tPE50wgncaa1f77qYV15h0f7mN+4f7bXX+Dc/+1nmeYdukZUEsKqKO5/99iPavbvhtK2uVFRwCK9//5Q6rWuvJVsvWAfRbP/3P/e/8RNN1nl9+y23iwkT3IfavvySx5zOPNN1MfE40XHHsd37+GN3v/n++y10/PFclNvf7LWYPZsV9tpr3evKzJn8m3/8w3UxlZVEPXtyivuOHe5+s2MHUa9eTOx37nRdlOfICgJ4881c5y+/7P43N97Ivykudv2TNWuYpJ96qv38gB8NAQzi0BLAPXuI+vThY88esyQknHYaUevWqc8hefZZlsRDD6X2u3SRlQRw1iyuhJtuSu13a9dyuP2001xdXlPDIh04MGUHuiFqaDdK4yWykgAKo6bkLTjqiui0br/dVTHr17NYzzkntcerreWoYbt27js6P9EknVc8zglcrVolJ+M54YYbUuq03nqLL7/zTvdFbNmyhb7/nqhbNx4l+9EOBe/axY7UwQcT7dmTmq6ceCIT/I0bXV1+660sp7ffTu0R33uPA1m/+lVqv/MSTU4AV67kEcFUo3mVlcygBw50Hd2ZOpXFummT/XUhAfSbABJx9A/gsIIDlizhS2+80fHSJMTjREcdxR6aS66ZES644AK64IILHK8LrOGVl3NDOfhgd0O/Kv76V678N95wvPQ//+FL5Zm9brFzJ1G7djGaNCn136aD1157jV577bVgCnODzz7jCK0mQuRKV045hWdquJhg9YtfcFGp8hciHi522Wx9R5N0Xk8/zRVw112p/7aykkM+LoYYYzEeFdt//9SaragTMWkkzbTD5o/LL+echfqZTSnpyhdfcANx4SH98AMHJk4+Ob3H/PWvOSq1dm16v88UTUoA43Ee0uvcmSsyVbz0Eiv5v//teKnIrPnLX5xv6xUBtPheP24MHjyYSktL9V+ecw7wwgvA118D++xjvMeECcCyZcDatUCbNqk/Q3ExMG4ccOedwBVXpP57P7B161Z06tTJ/4LuuAP4wx+At98Gjj029d/X1ACDB/O6WZ9/blyDqbIS6NMHOOAA4J13kNa6cX/+cwVuvrkV3n0XGDky9d83a0ybBrz5JvDFF0CXLglfudKVb78FDjkEOOkk4LnnjJd99hkwcCBw2WXcHtLBT37Cj/r110AQKmxCYG1IIBYD+vcHCgqApUvTW4/s9ddZRv/4B3DVVcbLnnqKzeNTTwFnneX+9qJO6upYHVq1Ytvp0bKezQObNwP77w+cfTbw8MMA0tCV664D/vpXYOFC4JhjjJddfjlwzz3AJ59wfTthx44d2LRpE2pqauqJApvYaNTTJXKbB+Jx7ldyctJf26+2lu+Tb78zLV9mobAwDz16dEf79u2N11qW9RERDU3vgSR4wSKb+2GMABIRffUVL5Hwhz8YLykupnTnIiRg3Dh2NNKYOOQLAvG8qqqI9tmH/3wmePllFsILLxgvue02vuSdd9Iv5ptvtlDXrjxF/0c1dPXll9wOfv977deudeXaaznq8cUXxkumTOGIRSbqt2oVF/O736V/Dy8QePTixRfJcQkCNzjuOB6jNYT2qqo48jdkSOprmcp18sQTjs1278Qf/sDtac2ahlMp60pFBdvO8eONl3zxBUfvLrzQ3S23b99OK1eupPLycopJgt2zh5eMaYp1a2NNuVhueTl3yJkY+7o6rjyb4b2aGnFJjMrLy2nlypW03WatJIRDwAERQCJelLNtWy0zi8d5zb8ePTJfl3jRIpbIzTdndh8nZNUQsBgHeuutzO5TV8fJfUceqW2sO3ZwXtjkyZkVs2XLloYlEubMyexeTsiqIeCLL+YhJ0POkWtd2bSJ7/PrX2u//vBDcj0M4oSzz+YZxE75NH4iUAIYj3NSXZ8+mS/gNmcO2S0QLSYYp9MG5Dqpq+PMj/79s2PNuUCwcyfP/DvjjITTaenK3/7GgjDMpvnpTznrwmWqIK1atYrKNesoxWJMUDxYez9lNBkBFMQtnbQkFRUVRiIZj/N8ut27G78uLy+nVTYr23tFAH9MQff08bvfAWVlwIMPJn21cCGwaBFw/fVAy5aZFXPUUcDJJwP/+hewZ09m97LDmjVrsGbNGv8KcIt4HPj734HDDgOOOy6ze0WjwJVXAosXA+++m/T1ww8DO3cCf/lLZsUAwIUXAvvt58297LBt2zZs2+a0BXYA+OEH4NFHgZ/+FOjePbN7devGw16PPAJo/ttddwFt2wK//W1mxQDADTfw0NXf/575vZoFSkp42Pd3v8t8K6rx44FDD2VjRIlpQkTA3XcDRx/tTbO98Ubg00+BF1/M7F7NBvfdB+zaBVxzTeb3uvBCHu6/666kr7ZsAZ59FvjZz9w325qaGrTUdGSRCO9CJ0YzfxSoruZXL7bfy8vjhiO295MQi3Gd5uU1piW1bNkSNYl7v/mCkAC6wbBhwOjRnJCkCPD++4F27bhv9AK//S2wYwenHe71eOMNTvj6/e/TS8hTcd55QMeOnLskIR4H/vMfztkbMiTzYvLzgd/8hnnmqlWZ3y/r8e9/szG8+mpv7nfllezh/Oc/Cae//55JwPnnA4WFmRfTty/nAj7yiL8OVdbgttuYYHthjCyL5bRyJTB/fsJX8+cDa9YAv/515sUALKO+fTlPba/Hnj1M1o4/3htj1KEDN5gnn+QGJOHhh9kBuuQS97cjIkQMyZiCBwXAS5oesRhQV5fIyjJBNMosuqYmyaGqqeEicnMbz0UiER6i9RkhAXSL3/0O2LCBXap6fP898PLL3P4yjf4JjB4NHHRQUt+4d+KOO4BevbgH8AIFBdwrvfYasHp1w+n584EvvwQuvtibYgCWeV4e8N//enfPrER5OXDvvcCUKayYXmDgQGDiRO7xhZcN7rBqa72V069+xZHfvd6hWrYMmDuXPcgWLby555lnAl27Av/8Z8Lp++7jiTVeNdtIhANZ777LkcC9Go8/zhH1P/7Ru3tefjmziPvvbzgVi/HHsWN5TpAXiER4LkRtbRKH2fsgWK4X0T+AGV5+Pkcj6uoaTouPubne8MxUERJAt5g0iVuSFGp/5BFuDL/6lXfFWBZw0UXABx8AK1Z4d9+sQ2kpW/wrrkh0fTLFr3/NDU2aPnr//dxhnX66d8WI+z3+OM8u3mvx7LPMoLyK/glcdRXPhHz6aQDcYf33vzwT3iueCbBD1a/fj4CoP/gge6FeGqP8fODSS3k6dX2oe/164NVXgV/+0nFSY0o47zw2Aw884N09sxIPPQQMGpTeagcm9OvHs7bvuw+oqgLAE7nXrfMuSisgRjIlDrP3QQzV5uZ6OzU9J4c7eCmE6jXPTBUhAXSLSISN67JlwMqViMXYWBUVAQcf7G1RP/0pO/F+RQEHDx6MwYMH+3Nzt/jf/1jrvRo7F+jShZcreeYZYM8ebNjAAcGf/9zbDgtgdSgrs13RJCN069YN3bp18+fmbvHYY6zgw4d7e99x49ihql8CY9Ys7rBSGa5yA8vi6NL77/MyGHslqqpY3087jRMovcRFF3HDqWdm//0v949e8kwA6NwZmDqVHaq9drj+k084R/NnP/M+3PPb33LSX32o+957gZ49OafcS8gjmXstRJqXl4EJgGWel8febizWwDNzcppwCSQvZpI098NxFrDADz/wnPqrr6Y33uDJV8895+6nqeK883hF8KZcEsa3GYw1NbzejcvdO1LGvHksnGefpT//mZcD+eorb24t10k8zuvlHnWUN/fOOnzxBdfj3/7meGlauiLW5fnyS5o4kVe08GM7xC1beOJxKlv/eVd2ALOAxVZCbvaSTQenn07UuTNVl9dQly5EJ52U2e1MdTJ/Pv+NJ57I7P5Ziyuv5P7DsKBwRroSj/MC3hMm0Oefp7+axLJlyxyvqariybFBzdoOfBZweXnilFwFt956Kw0dOpRat25NnTp1osmTJ9PKlSvdXSOmU+/ZQ9XV/NZk8+xkgXAWcBOgc2fghBOAJ5/EA/fVoWtXTo3yAxddxOlX9SNkexfefJO91fPO8+f+Y8YAPXsi/vgTeOghzrc+4ADvi7EsjoR8+CGPaO91+N//2DU991x/7n/22YBlYcc9T+LNNzlS58dCs506cXBsrx2uf/RRYN99eTjCD5x7LrBlC5b8dQ5++MHbHE0ZY8bwQu175TBwbS1P1DjpJO5HvIZl8arc8+bhpXs2IRrlYXo/IAJjmgmtzR/xOEfobJLyFixYgEsuuQTvv/8+iouLkZOTg/Hjx2P79u3O1+zc2ZBIWVtLiEQyn7CfEbxgkc39cB0BJGrY2uWEyGy7taEzRjxONGgQrzHoNc4++2w6++yzHa/zLXpx2mkcAayp8ef+RETXXEOxSJS6YLOni8yqdbJ9O+9Ze+ml3pUh8NJLL9FLL73k/Y3dIBbjfUqPP97V5WnryrhxtL3DgQTE09r2zS0WLOCoyP/+518ZOvgeAdywgRcUvu46/8qoribq2JHe7TmNunbNPPJjVye3385y+vTTzMrIOrz6Kv+xV181XpKxrqxeTQTQze3/6bbZJsFNBJDIdlk7z+E2ArhlyxYCQP/6179o6NChlJ+fT3379qW3UlljNo0Vr3fv3k2RSMR2zdaEa+pXfS4vq7Xd+jWMAGYjTjwRVQXtcXb8cZx5pn/FWBZPwlu0iHfQ8hIbNmzAhg0bvL2pW2zfDsycydEfr3MsZJx7LiLxGM7PewYnnuhfMe3bc1D4xRfZcfQSu3btwq5du7y9qVssWMBJeX5FaQXOPRftt3+FCwZ+gP3396+YY4/lCefSJP69A088wVELP+WUl4eaqdNx+IZX8dNTynyNWPz0pxx0fuYZ/8poEjz6KOcnT5rkXxn9+mF3/yNx4o4nPO+bxowZk3BMmjQGDzxwH+rqgMrKyqTvx4wZg8ceewwAb3Gn+/65+uTp9evXJ32XDpYvXw4AuOeee3Dbbbfh448/xqBBg3DWWWdhj5JYeuutt6KwsDD56NQJhfvsg8I2bfDOO++4Knf37t2Ix+O2W7clXJOTAwKQi1pfu0A3CAlgqsjPx5vtzsRUawYG9SrztagzzuDX55/3tZhg8eyznEHsM7Go6dMfy6JDcXGrxz1boseEadN4QqtLe9E88L//8abWfuU41GPNwKmoQAF+0+ZxX8uxLG5Pc+eyD7JXgIgn6YwaxWOnPmL+PueiJapwYceXfC2nWzeeuf3883vRUiNbtvC03HPP9dfpBfBWp3MwBKU47SB/ZzxZFh/ZNBu4tLQU0WgUs2bNwrhx49CvXz/cfvvt2LZtGz7//POEay+66CKUlpYmHkuXovSdd1C6ZAlKS0sxdKi7rXYvv/xyDB48GMNtJsolXGNZiFm5yEUtopEmVnIvwojN/UhlCHjjRqKjUL9n24MPuv5duhg6lOiII7y95+jRo2n06NGO1/kyfHXUUTy27TNef53oUtTv2WbYJikd6OqkvJy3W7roIs+KISKiRx99lB41bMXlK8QfcrFdoEC6unLjjURP4GyKtW1nu1emF1iyhNXh4Yd9LSYBvg4Biz8UgB068YQ4fZXTl+JjxmR8L6c6uf9+z5tt00L8oRUrbC/LVFdqa4kGdP6e6qyo7d71dnA7BEzE28KVlfk/DOx2CPiss86iKVOmJJxbt24dAXD3v9L4Q7/97W+pe/fu9JXNLEP1mliMqLyslsuySYMKh4CzEC++CHyII1Hdq28goblp04CPPuKFjJs91q3jGRNnneV7Uc89B8xuMx0Ujfo+ntSqFTB5MvDSS9nlEaeNt97i2RLTp/taDBEHhD8edC4iZTt5LRgfccQRPBlor4mov/wyZ5CfeqqvxWzbBrw1x8KXR58LS6QG+IipU3kYeK+SU9++vLWej3j7bWDVli74YchE4KmnfN+zTQQzs8XmlZaWYoiyu8qSJUvQokULHKQsLqodAu7cmYd/W7dGYWGh4xDwb3/7WzzzzDMoLi7GAYZZhrpramuBGKIgy2rymTQhAUwRzz0HDBxoIX/6VN57c8cOX8sTw8Be7mQwfPhw23C1b3jlFX6dOtXXYqqquKjRp3eGNXo0MGOGr+UBLKctWzh1ziv07NkTPXv29O6GbjFjBm8x5eVitRp8/DHw+edAn1+N4/J8lpMYBp43T7sNcfMCEXscY8bw9oc+4uWXuZPvcXV9YpnPcurShf/WXjEMvH079xNTp/q+1cMzz/AWih1/cxbvWrVoka/lRaPZMwxcVVWF1atXI66Q3rvuugvTp09HQUFBwvmkIWBl+NdpCPjyyy/H008/jeLiYhxsWAjYdE1tLRCNWrByc7nymlLJvQgjNvfD7RDwunXUuL7Sovph4AAWrRo+nCiVicpewfPhq9GjiQYM8PaeGrz8MovmrbeI6O67+cNnn3lyb1OdVFYStWqV0qhpdqK6mqhtW6Kf/Syln6WjK9dcQxSN8jp9dN55RO3a+TsznIiWLQts1JSIfBwCXrWK/8i99/pzfwljxxL161c/MjZgAFGGw8Bu6sTlqGn247HH+I8sXux4aSa6UlXFzeecc4ho506i3Fyi3/0u5fukMgRMFMwwsJsh4MWLF1M0GqV+/frRwoUL6fPPP6dzzjmHunfvTps2bXIuJIU/cskll1Dr1q1p/vz5tGnTpoZj9+7djtfs3LmbysrYzFKt/TBwOAScZRBRuGnTAAwbBuyzTyDRpWnTeFs4aXvb5octW3iWhM/RP4CjtJ068T6YDZMYfJZTy5a86v5LLzV5VD8zlJTw9iY+y4mI5XTccSwrTJnCW869/bav5Q4ezPMlmv3w4ssv86vPk3R++IGj2tOm1QewpkwBFi70PYS61wwDv/wyr9HockJBuigu5uYzbRp4N5iiIh4G8Tm6lC3DwKWlpejbty9uuukmnHnmmRgyZAh2796NJUuWOO+mRPV724mt2hxw3333Yffu3Rg3bhy6d+/ecPzjH/9wvObvf+drcnKQFSHUkACmgJde4g6kb1+wdZoyhRc19nnvIrGH7YsvenO/0047Daeddpo3N3OL117jnBSf85Wqq4E33uBicnLA+yENG9Y4/Owjpk3jEZ/iYm/u99xzzzUslRAYZszgcaTx430t5pNPgK+/5gWaAQATJjCL9llOYhi4uJh9kmaLl18GRoxgJ9RHvPEGN9sGf+DUU/nE66/7Wm6XLsxhmvUwcHk559MGMPw7cyZQUCA12ylTgC++4BwLH5EFHAYAE8BDDz0U06dPx4YNG1BZWYlXXnkFPXr0cP5xLMZK5nIVelM07cYbb3S85pprbmzYTg+W1bAodFMpeUgAXWLrVuCDD4BTTpFOnnoqJ8vPmeNr2T16AEceyY3cC2zbtg3bgk6CmjED2H9/ZtA+4u232e4m7IE5ZQqweDHw3Xe+ln388WyEvZLTnj17ktav8hWxGBOwE07gzah9hKijhjUaCwq4AgOIWpx2Gv9Vn+ec+IevvwaWLw8kmj5zJgewDjus/sThh7NTFYBDdfrpzGFWrfK9KH8waxZ7pAFE02fO5ObT0GyFAQzAoWpiDgOACeCgQYPS+7Fgrz4v0ROP85HAM8UHrxeRdYmQALrErFms4CedJJ0cPZpXAg5gGHjyZOYw33/ve1HeY9cuXoDt1FMD8YRbtgTGjZNOiqijz8awRQv2wF9/vZlGLT74gBUsIGIxbBjQvbt08tRTmaQvXepr2UOGcODM5yCWfxD2xudoelUVB7AmT5aarWWxQyVmivsIYWvfeMPXYvzDyy9zKHPkSF+LKS3lOR8JfZOIGgRA1JuYw4CIsHLlyvQIIBGzV5fDv5lA8EwtAWyivKGQALrE669zZ5Uwyzw3l1vdzJm+x8AnT2ZdnT3b12L8wezZvPizzx0WEctp3DgkLv58yCHAQQcFYgwnT+adW5pl1OLll4G8PI4A+ogffuDVgBI6LIArLxoNJGpx4onMYWpqfC3KH7z8MkfS/djgWkJJCXO8JDlNmcJpL3Pn+lp+jx78N5slURe5KFOm+L7Z62uvNep0AgIa+RAcpqmGgS3Lwq5du3BywrCPS8TjKQ3/ZoK6OpZTRGZdIoTaRLOBQwLoAjU1nOo3ebIiPIBJzfbtnBjtIwYPZoPo1fBioJgxgz3hESN8LWbVKuCbbzQdFsByWrDA92V7BHdqdp0WEfDqqxzCbN3a16LeeEMTTQd4KZiAlu2ZPBnYvbsZ7t6ydSvw/vtKLoo/mDmT17gsKlK+OPZYoF27wByq999vhru3LFyoyUXxBzNnAkcfzSY2AWKC0Guv+Vq+ZTHHbeo8wLSgDct5DzHPJDdXE2jMyeELfF63UYdmQQAty+pgWdYMy7IqLMv61rIs7UrClmWdb1lWzLKscukYk2n577zDncXkyZovJ0wA8vN9H6ewLC5/zhx2LjPBuHHjMC5hjNRH1NVxqOWEE3z3hAU51srplFP4WXwOofbowWlSXhDA3r17o3fv3pnfyA2++AJYu1YTRvAeM2dyGllDXpmMKVOAzz7j5/ER48Zxs212RH3OHO4sfJaTyCubMEGTDpqby41s5kzfx/0mT+Z+8c03fS3Ge8yaxQqWxJ69xYYNvFGAlmcefDDQr18gDlVuLsupqYaB00ZdHUd1kiI73hcDGHhmEw4DNwsCCOBeADUAugI4G8D9lmUNMFz7AREVSseCTAufObMxvysJBQUctQhgbPakk9ipzHSljOuvvx7XX3+9Nw/lhA8/5PUJ/NwEvR4zZ/JuD9qJkcOG8YK5AfQkkydzOt3WrZndZ/To0Rg9erQ3D+UEob8+y6mqijlMQl6ZDEFsfJZTq1a8TNDMmc0sX3PWLKBzZ1Z0H6HNK5Nx0km8FMzixb4+x7Bh/HebXR7g7NlM/pQFiL2GcGC0BNCy+AsxM85HNPUwcFogYsYa0PAvYIiBRCJNFkLNegJoWVYrAKcBuJ6IyonoXQCvATg3iPKFJzx2rE1bnjSJoxbffuvrs4wdy7ltzSpqMXs2K/hxx/lazJYtvPC9scOKRjmc8dZbvofam2XUYvZszpP0OeK4YAFQUWEjpwMO4HWWAnCoJk8GvvoKWLPG96K8QTzO+nv88b5HLGbONOSVCYwfz8/gs5JHIjx4MHt2MyIXa9fyoq0BOb0HHMBpzlpMmsQ5TF5uUaSBCKI1GxkBgQ//2s4zyclpnCYcIPynvpmjH4AYEclmegUAU2hkiGVZWwFsB/AEgL8RUZJaWpZ1IYALAWCfffbBVkO4Zs2aKNaubY+LLy7H1q1V2muiRx+N9gDKX3gBVeef7+5fpYljjmmD116L4vrrd6Q9aWnatGkA4LjGXFlZWXoFSGg3cyZo6FCUxWKZh8Rs8Nxz+SBqjVGjdmDrVv04RP6oUWj9zDPYUVKCmHb80Rlu6qRXL6Bz5w546aVaTJy4O61yAOCF+pXHf/KTn6R9D1eorETHBQtQ9bOfoSJNGbnVleefb4WCghYYNGibUR1ajR6NFk89hW3r1yuzebzF8OERAB3w/PPluPhifdvOFF60IYGcZcvQbutW7DrmGNT42JYAYMaMtjjiCCASKTPKqe0RRwCvv46y3/wmpXunWifHHpuH//2vDd58cyeOPjr7GUaLF15AIYDtRx+NeApySrVeKiuB+fM74rzzqrBtW4X+ooMOQseCAlTNmIGKo492dV91OzW3iEYt1NYC8bj3IfV0n8kOVm0tYFmgSMRX4hWPWyCykJNDxrqxolFYAKiuDiQRUhMv8QxebCfi5wHgGACblXMXAFigufYAAL3Bkc1DAXwK4I9OZdhtBXfHHbyTz7p1xkt4+5j99yc6+WSbi7zBf//Lz/PJJ+nfY/To0TR69GjH6zLexmrTJn7YW27J7D4ucMYZRN27O+zk8/330l5+6cFtnfz857yjWiY7mz366KP06KOPpn8Dt3j9da6XOXPSvoWbenHdTGbNkvby8xcDBxIVFfl3f0+3grvhBqJIhGjrVu/uqcEPPxBZFtFf/uJw4U038YUp/sdU62TnTqKcHKI//CGlnzUdTjiBqE+flH+War3Mns3N5M03HS486SSiAw90dc9Ut4KT4bCzWdpwsxVcyojHiXbtIqqo8P7eCqqquF5s/4bmecKt4BjlANoo59oASAqtENFaIvqaiOJEtBLAXwCcnknhc+YAAwfyYqhGWBaH2ufP931dCTGq4PPa097grbf41eehkFgMmDePR8Zso6JdunDuVABjsyeeyDuq+bwfuzeYPZvzG4491tdivvqKZ2kff7zDhaNHcwJ9AMPAJ57Ik7x27fK9qMwxezav7daxo6/FzJvHw1aOcpo4kS/02Ri1bcuq2SzyAPfs4W1mfF5KCeBqz88HjjnG4cKJE7nxffmlr88j8tuaxTBwwMu/OM4zEcvBiF1JAkJzIIBrAORYltVXOncYADcrrRGAtFd3rKzkzmHCBBcXT5rEyU3vvptuca6w7748uatZEMDZs4GuXX3f/eOjj3iZCNdy+uAD35eDGTuWG3zWy0ksLjl2LPcmPkL4A45yKigAxowJhKhPnMgG2ucUqcyxZQuwZElgxKJDBxfzTIYO5Y2cA5LTJ58AGzf6XlRmePttnukUQP7fW28xMXacZzJxIr/6LKcmXtIuNQSY/+d6nkkTLAeT9QSQiCoAvAzgL5ZltbIsaySAU8D5fQmwLGuSZVld698fDOB6AK+mW/Y77/CSK66IRVERL6IbQNRiwoRGO5O1qKvjnmTiRN8T1ufMYePjap7JxIncwObN8/WZ2rUDjjrK97VyM4dY/iWADmvOHJ5jcuCBLi6eOJH3Mf3mG1+fafhw7kCznqi/9RZ3Dj7LSQT0xo93sWpTJBLYxCrRtrO+Pc2axXmrPs/e37AB+PRTl32TmFgVAFFvwiXtUkNdHRo35fW3GMAlAWyCEGrWE8B6XAKgJYAfADwD4GIiWmVZ1n71a/3tV3/dOAAfW5ZVAWAWmDjemm6hrkPsAFBYyBcGRAD37AHeey+930+ePBmTtYvleYjFiznKFhCxOPxwDkY44qijmJ0FJKclS9JfxLZfv37o16+ftw+lIqDlX2preWRswgSXOy4FFLXIz+dgY9YTi9mzOYXh8MN9LWbVKo6yOQ7/CkycyFu7lJb6+VgYNIj/frOQU1GRr5OXgEaHJSU5lZT4HjVoFsvBZMvyLyqaYDmYZkEAiWg7EU0holZEtB8RPV1/fh3xWn/r6j9fTURd6687gIj+TERpr644Zw5zOtdLOU2axBZ0/fp0i3SF0aN54c10oxZXX301rr76am8fSsWcOYEs/7JrF4/ouvKEAW70xx3HxMLncYrjjmNPuLg4vd+PGDECI3zePQVz53J0wOflXxYt4qXIXHdYBx0E7L9/IFGL447jpWB8XsUpfcTjLKfjjvM9YuF6mF5AXOizQxWJcFRy7twsji598w3n2bmuvPQxZw5vTTpwoMsfTJzIOU0+pyiJXLesXhA6JVamx6ZNm3Deeeehc+fOaNGiBfr374+3lQV67733PhxySG906dICQ4cegXfcbDsUjQaaB9gsCGBTYNMmzjlJqS2Li30eXiws5P3Fs9obLi7maEWHDr4Ws2ABt+eU5DRxIgvY5w17jzwSaNMmi+VUV8dbVgWwK8xbb7Ftc70xgmWxnObP932FfKE7WSunTz7hHECfnSmAiUX//rxTiyt07crtPCCi/sMPwMqVvheVHubP51ftjgHeIRZjXXUdTQcaJ1YFICcRxMraPMAMCeDOnTsxcuRIEBHeeOMNfPbZZ7j77rvRRdqL77nnnsMVV1yOK6+8Fh9+uBwjRozApEmTsG7dOvubBxxCDQmgAaIzSIlYDBzI4xTCEPiI444Dli9ng5gqxowZgzFjxnj+TA2orOSQj8/bIAHcYbVqxblcriEMtM9EPTeX51aI9K1U8dhjj+Gxxx7z/Lka8NFHvMdhQHISo++uMW4chw2XLvXrsQDwIro9emRxHqDQU5+J+p497A+kHMA67jhu7xWGteg8QtbnAc6bB3TrxgzaRyxbxmklrqPpABvJUaN8t3lAI4cJOgq4detWWJaFO++8E8OGDUOLFi3Qr18/zFEbthj+TXMh3TvuuAPdu3fH448/jiOPPBK9e/fGuHHjcIi0Gve//vUv/PSn5+P88y/AoYcegrvvvhvdu3fH/fffb3/zgPMAm8NC0E2COXOYyx16aAo/siwmF2IdhXRXanaBCROAP/2JizpLuzNyE+K99zhqM3as70XNmcM5XClNYN1vP6BPHybqV1zh05MxJkwAXnmFR4b69nW8PFiIsWk/nQHwjmFLlwI33JDiD8VzFRenyPBTg5hA9Oqr3Df4vGV16pg3j6f+uw7LpYd33uEUsZSIBcDt/PbbeXgx5R+7R48ezK3mzAH8zmBJGfE42xPHtagyx1tvNXY1KWHsWO40tm51mTDdCJ0jOmDAAAwbNgy1tbV46qmnGs4TsR4dfvhgHHXUYFRWVuL5559P+v3QoUMxcOBAlJWVYYayX/H5aWyosHz5cgDAPffcgwceeAD77rsvrr32Wpx11llYv349WrZs2bDbxq133olbb7/d9n6zZ8/GMZoJAK+88gomTpyIadOmoaSkBPvssw9++ctf4te//jUsy0JNTQ0++ugj/OY3V8OyGrM2JkyYgPfff9/+T8hTqQNAGAHUIKOUm3HjgO+/9314ccgQXg4sK6MWJSWsxKNG+VrM11/zJNa0Um7Gj+fxY5+HF7M6alFS0hi19hGu15VT0akTcNhh6SdRpoAJE3jO0rJlvheVGmpqeMq/z8OKQOOkt5SXgxw5ksPdAcnpnXc4WplVWLkysGH6uXPZ/nfunOIPhUPu85pHgvQEHQEsLS1FNBrFrFmzMG7cOPTr1w+33347tm3bhs8//5wvqidWF110EUpLS22PoUOHastZu3Yt7rvvPhxwwAF46623cPnll+Oaa67BvffeC4AjkbFYDB07dk2YZ9K1a1ds3rzZ+Y+IqdQBjKGHEUANPv6Yh1bTJhYAe4OuM3RTRzTKRc2Z43uwMXWUlPAu7oWFvhYjRjPSsrnjxgH/+Q9P0/VxosWBB/L8ijlzgEsu8a2Y1FFTwxGbX/7S96LmzePFfA321B5jxwL33cchhRYtPH82ATG6OmcOq27WYNEiTqkIgADOn89NwfWkN4FWrYCjjw6EAB53HHDXXay6AXAt9whomL6ykie9/fa3afx46FCgdWuW0+mp7Y9gF5HLzc1N+r66mg8ioKCgwPb3bdu2TSvip6K0tBQnnXQSDjrooIZzeXl5iRfV1QGWhQ6dOqFDygyaEY/HMXToUPztb38DAAwZMgRffPEF7r33Xlx66aUN11mWlUAAiQiWm45aDEEEMNspjABqIFL40mrLYngxgFyL8eN5LoNwbrICu3czqQpg+Le4mGfCHXxwGj8uKmLW7LOcxPBicXGWLY3w4YccRglATiUlnIOe1qoLY8dyT/LBB54/l4wuXTiqknWR2nnzOJwSwDD9ihUZqMPYsRw+9XmB9UxXQPANc+c2JpP6CJFdk1babk4OL2sRAFFvil1BSktLMWTIkIRzS5YsQYsWLZgUSsu/3Pq3v6GwsND2MM3a7d69O/oreZ6HHHJIwwSPTp06IRqN4vvvNyekk/zwww/o2rWr8x+JRLjjCCACGBJADUpKgH79MmjLAQ0vCiNQUpLa78444wycccYZ3j8QwOMzsZjvEwuI+H8LHpcyOnbkHj+ACTtjxzIvTnV4ccCAARgwYIA/D1VSwhXn84K169bxLlRpq8Oxx3JvEkCnNW4c88ysGl6cN4+nk7dt62sxb7/NbSptOY0dyxGLhQs9fS4VYsJXAOrgHtXV/L8DiNJmnF0zdiywejXw3XeePpeKoAlgVVUVVq9ejbgSNbvrrrswffp0FBQUNG7/Fo1mNAQ8cuRIrF69OuHcmjVr0KtXLwAcdRwy5AgsWDA3IYVs7ty57pb1siyuQPG8fsKLDYWb+3HYYYc1bLJcW0vUujXRr36VtP+ye7z4Io/gv/deBjdxRjxOtO++RKef7s/909rI/qqriPLyiCorvX8gCZ9+ylX80EMZ3OT3vyfKzSUqL3f9k3TqZPNmftbbbkv5p/5h9Giiww/37HamennsMf7vpaUZ3Pzoo4lGjMjgBu7wxhv8rPPne3fPtNqQwM6dRNEo0XXXefdABlx6KVFBAVF1dZo3qKoiatmS6LLLHC/NqE6I6IYbiCyLaPv2jG7jHUpKWHFefTWj27ipl4ybwrJl/KxPPGH4elkGN09ERQXR7t2Z3ycWizles3jxYopGo9SvXz9auHAhff7553TOOedQ9+7dadOmTXxRVRVRWRmRi/s5lZWTk0O33HILffHFF/T8889TmzZt6J577iEi7pcfeeRZys3NpQcffJA+/fRTuuyyy6hVq1b0zTffuCukupqWffAB0eefa78GsJQ84D5hBFDBsmUerIwR4PBiUREHG1NJF6isrERlZaU/D1VSwi66zyvhiwhARnIaP56jtG4W6MwAXbvy7MVUI7W1tbWo9SOKvGcPh7oCWP6lpISDrSnNplcxdizvLLN7t2fPpcMxx7DjnaqcfMPbb3M0PaDI0jHH8G6WaSE/n8NSAYTmioo4MOJzsNE95s1jxfE5mi6yazJqtocdBrRvH9gwcP2kW99RWlqKvn374qabbsKZZ56JIUOGYPfu3ViyZAm6devGF9XVNa5UnQGGDRuGV155Bc8//zwGDhyIP/3pT7j55ptxSX2SdywGnHbaNPzzn3fhlltuweDBg/Huu+9i1qxZDVFCR4h8GZ/l5LomLMu6wLIsko4qy7I+sSzrPD8fMGgI459Ryk2HDrw4agB5gGPH8qz+VCYdn3DCCTjBj03ld+zgxQkDIhb77ZfhBhYjR3KPF4Ccioo4cT0VPvfUU08lLK/gGT74gCeBBDRMP2ZMhjZ37Fg23j4T9datOU8+awjg/PnsSB19tK/FiEULMlaHsWN50ervv/fkuUw4+mieD5Q1ciou5plDPg/Te5JdE4nwDQKovCDXAywtLcWhhx6K6dOnY8OGDaisrMQrr7yCHiKPy+Pt30488USsWLECVVVVWLNmDS677LKGCR7i/1566SX45ptvUF1djY8++gjHpjK93rL48FlOqZjlwQCqAAyvP04FsAvAY5Zl+d/jB4SSEo7WuMnVtMW4cYEsjppuHqAvEIlEPk8siMc56pl2/p9AQQGTwIAIYEUFe/BNjuJids9dbXKdPr7+mnMAMyYWI0YwUQ8ourR4se/N1h1KSlg/U1rkMnWIVUE8IYDyDX1Cfj6rRFbYvPJyD8Jy7lBczM0g40ULxo7lbeu+/tqLxzJCOH1B5AGWlpZi0KBB5gsEKwtgkU8RaMyobxJr6ZSU+BpCTZUAfkpEi+qP2QB+Uf+dD+Gk4CFWxvCkLY8dy+Ge997z4GZm7LcfcMABWZIUXVLCEYsjj/S1mE8+4VmLnslpxQq+oY8Qo0NZ0WmVlHCoq00bX4vxZJgeYJ0aMSIwAhhAs3XG1q28tlxA0fQ2bXjQIiMcfjjfKCA5ffwxV1OT4r33uMf3eZY24GF2jSDqPsspqDWNiQgrV650RwA9igCan8XDQGMkwgr+ySce3MxQhJuLLI5tDgKg7sK4q/7V34SvgLBkCXv+ngSwRo5kLQigxy8qakwXalIEFLEQVepJ3yhuomzk7TU6dQIGDcoCAlheziGugJZ/6dqVV8fIGGPHAqWlvhN1saZxk8tJ6GMAxKK4mCdbZ9xp5eSwpxMQAQR8b7bOENNyR470tRiRXeNJsz34YN6yLqA8QCJ/8wAty8KuXbtw8sknmy/yJCznDE8DjeJZfZST2whgXwCFAD5Wzous1488e6ImhKcrYxQW8uanARnDnTs5kNVk2LKFIxYBEYsDD+ToZ8YYNozXlghITu+9x6tGNBnefZeNYbYv06Ni7Fi+qc89fqtWHMBucgJYUsIpCj6vSv3dd7ybjmfqMHYs73votOl9hhg2jKunyeW0YAErTKtWvhaT8TI9MiyL5VRc7PsyI8KpaNI1UD3O/7OD+J+eFGVZvKZwFhDAwfWvn1qWlWNZVnvLsqYCuBPA5wCe8ePhgkZJCUdpOnb06IZFRcBHHwG7djlfm2ExgHtjeP7553uy8noCPEskskcs1pj/5wny8nj2YkCR2qoqXoPZDQYPHozBgwd7+xDFxRzi8jlisWYNL1LumZwCJupLl/o+6dgeCxawXubm+lqMp9F0oNEB9Lk9Bdhszdi9mxUloGF6T7NrioqAzZt930VABN2adHQqwPw/sZe4Z4HGsWOZ/fvEoN0SQLG89mwAtQC2A3gWwAIARURUBQCWZb1gWVbaPUs9sSyxGO9alnVAuvdKFdXVwPvve9yWi4pYI3yevbjPPrxwdZMSwOLixmmUPqK0FCgr80FOn37KBtFHHHtsahO7fCGAJSU8jTLl/b5Sg2f5fwJ5eYHtYhBQszXjhx88mpbrjOJiXhXksMM8uuHAgZzvEJCcPv3U90nHZrz7biCL3gPcbEeN8jC7JsA8wGi0iSOAAef/ecozx47lAJJPm5SnEgHcAGAYgKEABgBoS0TTiGgzAFiWNRRAByJKO32aiHYQUVH9Qof/AnBTuvdKFYsWcXTG07Y8fDi32ICM4cKF7hra1q1bsdXr7GmxkJjPjczziAUQ2OzF9u158xG3BNDz9Rp37mRDElCH1bMnj2B4hnHjgM8+49Cijxg+nPlmk0WXAsz/82SZHhlimZEAhheFGvvcbM0oKeEI7fDhvhYjsms8bba9ewO9egXSN+Xk+J8HaIuA8/887QKFDfDJGKVCAJcS0VIi+oiIPiUidcOkCwE8LZ+wLOsGy7LmWpb1jmVZn9a/djIVYlnWXyzL+nP9x5kAJlqW1c7lM2aEkhLWkVSW6nFEy5ZsHAIaXnS73djpp5+O01PcDNwWGzfy9kIBEYuDDuI9gD3DkCE8ezEgObndbuz555/H888/713hCxeyFfY5T5PIo2V6VAQ0vCiW3muymfUlJZxDfMQRvhbz9de8GojnzXbsWGDDBs4F9BFHHMGDDk1KAAOIpvuSXSPyAH1eZgRomn2BG9AE+X+eRgC7duWouk/GyJEAWpbVFUA3AMsdLh0HQM1uGgqeITyZiPoD+B5MFE04AvUTSoioFjzrON1dD1NCcTHzgHbtPL5xURGPW27f7vGNE+Gzo2APUajPxKK2ljmM58UEPHuxpoZJYOAoKeEVdH1eWHjVKo5aeE4sAtzFoKiIZ13u2OF7UclYsICj6QHl/3nengIaXszJ4WpqEptXVsbedkCztH3Jrhk7lhXc59mDTZoHGPD6f57m/wkUFXE+Sk2Nxzd2FwEU+X9OBLAnmODJGArgCiIqq/+8EoAxAggmgHIMa3P9fX1FPM5DwL4EsAKavdi1KzBgQBMSwHbtPEwk0uOjj3gVE1/kVFTEEYsNG3y4eSOadLux4mJeT8/nZXpEv+85sYhGucPdm7cb27yZh7kDGv7t0oUXvvcUffsCPXoEJqfVq3kQIlC88w53HAGNeviSXSOePcA8QJ+zApLh6bRcM8QQty/FjB3LQ0ZuZw+mADcEcHD9qxMBrIS0HqBlWT0BdEAioTsawFLdj+uvjxORnODTAoCLwbLMUFFhobbWpwDWkUcGtl6B2G7MB0fBHiKRyGcvy5Nt+kwIaHixTZsm2m5s61ZeOTegZXpEipHnGDuWxy593sWgybYbE45igNv0eR6xCHB4scnyABcsYEfK5/w/X7NrevTgfJq9OQ8wFgsk/8+X4V+B0aP5+X2QkyMBJKLbiMgiIqfQyMcADpY+DwOQB6APAFiWdRqAHgBeqP/8uGVZp0rXNwz/SjgEgO+r25WXW4hGeZaV5xDrFQTkDQe+3di33wJr1wbmCQ8cCHTu7MPNDz2U1/8JSE4ffhjwdmMBEYt4nIvyrZiAhhebbLuxkhIe7xsyxPnaDPDll7wGoG/+wNixnAeQyiblaWDwYB58aBI5CS/B52IAn+W0cGFqm5SnAUGMAh0GDjD/z9eR5vbteZedpiCAKeBFAJOkz0MB/BvAfZZlrQRwHoCJ9bl94nuZVCYM/1qW1RtAFAERwGHD2O76gqIiNoQ//OBTAQzhKDgZw4svvhgXX3yxN4X6Mi03GTU1vIiyb8VEIo15gAHMXqyr42itHYYOHYqhXiX+FBfzOno+Lyy8YgWnFfkmp0MO4XyHgCLqgW83VlLi0bYc9vB8mR4VARH1aJSrK1ACKLblCMjp9TW7pqiI82qWagfmPIMIwgU6EWRvyP8TGDuW89S8XBUC3hLARwFMsCyrsP7zMABvENF4IjqUiE4moo0AYFlWZwDfEVFDrIqI/kxEN0j3uxjAHfVLwviKykrL37Yc0DhFx47uthubNm0apk2b5k2hJSUckhswwJv7GbB4Meu+r3IaO5Z3MPB5eNHtdmMDBw7EwIEDvSlUJBL5PLHAd2JhWTxuuWBBYMuMBLbd2MaNvIJ2QMRin304Xc8X7Lcf5wEEMDZbVAR89RWwfr3vRTHeeYd1L8BlenzjMAHNHhR5gLFYgHmAPuX/3XvvvRg0aBDatGmDNm3aYPjw4Zg9+42EYm688UZYlpVwdOvWLf1CfZo96BkBJKJyAJcBEIs3Hw5Dvh8RbSGi4xxuuQHAIwBgWVYHy7JmWJZVYVnWt5ZlnWX6kWVZv7Usa7NlWWWWZT1iWZarjHdfba5YryCg4cX337ffbmz9+vVY74W1JOL/5OlCYnoUF3u4TZ8JqW6pkibcbjdWVlaGsrIy+4vcYNMmnlgQUP5fv36cXuQbxozh8UuflxkJfLsxQZZ8JhYi/2/sWJ9To8Qm5QHlAQYmp4Bm0weSXdO5M+fVeEjU77gjWRYlJcBddwWcB+j5thyMnj174vbbb8eyZcuwdOlSjB49FmedNQWrViXulHvQQQdh06ZNDcfKlSvTL3TkSP4vHjtUnvbaRDSfiD6uf9+JiNJe+4SI/k1EQlXuBVADoCuAswHcb1lWUsjJsqzjAVwDXpJmfzAZdVxM2rJ83hkrJyewcQqx3diiReZrzj33XJx77rmZF/bVVzxrNiBiMXgw0KGDj4UEPLzotEvgjBkzMGPGjMwLC2ibvro6TifyPYAVUEQ98O3GFiwA2rZlRfcRn37K2SiByGnHDh5H9xEifTdQOQUwmz6g7Bo0bFLu0ezBYcOAM85ofP6SEv581FH82a88wK1bt8KyLNx5550YNmwYWnTsiH6DB2POnDmelnPKKadg0qRJ6NOnD/r164cbbvgrCgtbY/HixOhcTk4OunXr1nB0ziR5vU0bDiRlMwH0A5ZltQJwGoDriaiciN4F8BoAHYM5D8DDRLSKiHYAuBnA+U5lFBSQ32t5ciNbs4YjFz7i2GM5GBeIMfR9vI9RVcWRb98NoWUFuotBYNuNFRczsfB5YsGyZbwYue9y6tePVwIPiKgHtt2YyP8LaDa973IKaHhRpO8GYvO2b+dE14CGfzt18j27hv9LZSXn2XiAoiLg+eeZ9P35z/z6/PONEWe/8gCXL+eFSu655x7c9te/4uP338egQYNw1llnYY+y8v6tt96KwsJC2+MdF8Y5FovhueeeRUVFOUaOHJHw3dq1a9GjRw/07t0b06dPx9q1azP7g2PG8OxBD/MA/Z8ekzn6AYgR0Rrp3AoAusHAAQBeVa7rallWRyLaJl9oWdaFqF+Uuk2b3njqqae8fWoF7auqcAKA9265Bd/4Mt24Eb16TcRzz9Whb9952u+/r+/NnP5zRUUFWrVqZfx+5KOPoku7dpixZImvScSfftoV1dXjYVkL8NRT/hLoPgUFOGrTJrz2j39g9z77JH3vVCduUVMTRU7OT3Dffauxc6d+haUP6vM9cjPM2zv5tdew88ADsfDZZzO6jx0qKipQXDwMwBBs2/YSnnqqyreyAGDk/vujy+zZmPHkk76OY1ZXdwQwEbfc8i6OPvrblH/vVl9abtuGqV9+iY+OOgqf+2yLHn/8GHTq1AHvv/8q3n/f16JwUteuKHvySSzs0qXhnFdtSEZhYT98++0w3HnnK+jSxb/p9T2XLMFoIsyprcUWj+Uk1wsR8MYbU3DggVvxzDMOs8UyRN7u3fgJgBX/93+IX3MNaj2YETxqFHDhhRHcfHMU114bw6hR8fod2aKoq7NQU1PnutkSESwXF3/00UeIRqN49dVXccgBByBSV4dbbrkFh/Tvj5UrV2KI5AD/4he/wKmnnmpzN6BHjx7Guli5ciWOPfZYVFVVobCwEM8++yIOPvjghuuPOOIIPPTQQzjooIOwZcsW/O1vf8OIESNQWlqKjh07uvrf8Xg8oY/uToSxtbWYf/PNrn7vCkSU1QeAYwBsVs5dAGCB5tqvwDONxedcAARgf7syDjvsMPIdsRhR+/ZEP/+570X97ndEeXlEFRX670ePHk2jR492vM+WLVvMX8bjRF27Ep19dnoPmQKuv54oEiHaudP3ooi++IIIILr/fu3XtnWSIkaPJjr8cPP3jz76KD366KOZFfLtt/x/7rwzs/s4YMuWLXT88UT9+/taTCMeeID/1+ef+1pMbS1R69ZEv/pVer93rS9PPMH/Z9my9ApyiViMqEMHovPP97WYRvzyl0Rt2xLV1TWc8rINCXzyCVffww97futEXHYZUcuWRNXVnt9arpcvv+T/c++9nhejx6BBRGPH0jKP9K+4mKhTJ7bdnTrxZyKutrKyBHVwRCwWc3XdWWedRVOmTOEP5eVE5eW0bt06AuDZ/xKorq6mL774gj74YAn99rfXUMeOHWnlypXG63fv3k2dO3emf/7zn67LSHrmXbuIolGiP/2JwFvzZsyvsn4IGEA5gDbKuTYAdru4VrzXXRssIpFAdzGoqYG/3v1nn/G4WEAzFo84gkcxfceBBwI9e+49240FuE3fu+8Gog4MMQTncx5gYOm7JSW83pfPu+msXMmjmIHJqaiIt03zebux/v15V5NA5DRyJCeI+lwMELCcPOowRM7f888Df/lL43BwSUnjhFw/8gBLS0s5yifW/4tGsWTJErRo0QIHHXRQwrWZDgHn5eWhT58+OOywobjxxr9h8ODBuPPOO43XFxYWYsCAAfjiiy/S/4NiP0APbV5zIIBrAORYliUvWHAYAN0Ko6vqv5Ov+56U4d8mQ1ER777+zTe+FjNqlP12Y1dddRWuuuqqzAoJyEJVVHDaQ2CGUOxisGCB79PVxC6Bpu3Ghg8fjuGZ7jRQUsIZ8l4tJ2PA8uU5qKgIUE59+vBU44DyANes8Xm7sQULOJHN59n0gROLAJcZ8T19d+tWZtABOb3dugEHH+x8rScQswc9sHlLljDpE9UkcgKXLPFvPcCqqiqsXr0a8Xi8kV3m5OCuu+7C9OnTUaAk+V900UUoLS21PdyswSrWmY7H46i2WXqjqqoKn3/+Obp3757R/8SYMZ7lagLI/iFg4tb8LIBnALQCMBJAGYABmusmgvcP7g+gPYBiALc53T+QIWAiopUrOa7/yCO+F3X00UTDh2d2D9uhmtNOI+rVi4eCfcRbb3GVzZ7tazGJePRRLvTjj5O+8nL4qqqKR5Muu8yzWyYiHifad1+Wlc/44x/LCSDyYXTPjLPP5jQEn3Vw2TJWhyefTP23rvRFDNPfdVfqBaSIk08mOvBA34tJRL9+RJMnN3z0YwiYiOg//+FqXL3al9sTvfgiF/Dee77cXtRLPE7UvTvR9Om+FKPH9u1ElkXLlizxvajKSh7NdNts3QwBL168mKLRKPXr148Wzp1Lny9dSueccw51796dNm3alOETJ+IPf/gDLVy4kL766mt6//2P6eqrryHLsmjWrFkN11x11VW0YMECWrt2LS1atIhOPPFEat26NX3zzTeuy9EOW8+eTcRpbT+aIWAAuAS8z/APYCJ4MRGtsixrP8uyyi3L2g8AiOhNAHcAKAHwbf1xg+GewWPAAF53KaDhxSVLeJF3FatXr8bq1avTv3k8zi5qUZHveyyKYQOf580kIqCFxfLzeTTJVMzWrVuxNZNtKNau5dVxA1im5733cjFoEM9aDAxFRZyG8PnnvhZz2GE8OutbsxU39llOsZjP2/SZMGYMh7l93gbC9+28i4uBwkLfd9NZs4aX7gxUTu3b8/JDASzSF416vx5gaWkp+vbti5tuuglnnncehhxzDHbv3o0lS5ZktgCzBps3b8Y555yDQw45CCefPA7Lli3B7NmzMWlS40ZoGzZswJlnnomDDjoIU6dORX5+PhYtWoRemW6QLtYD9AjNYRYwiNcTnKI5vw5AoXLuXwD+FcyTpQgxTlFSwi3AR/JUVAT87W+clzVxYuJ3v/rVrwAAC9LNJRCJRAGt/zdsGNvdwNCrF3DAAVz4ZZf5WlRREfCnP/G2qeoyUa+//joA4Pzzz0/v5gGN91VXA4sX56JerYKDnAd4yCG+FeP7MiPFxYHsplNayul4gRPAoiLggQc44dVH8iSyAoqL4Y8uFhdzQqjPu+kEtGxnMsaMYVbmc98k8gDF9mleoLS0FIceeiimT5uG6SecwN61T+s0PvbYYwCAPXv4PxQWJlfXs36tuCDyAD/80JPbNZcI4N6DoiJeCzCTZFAXcLvdWFoIaP2/3bt5dZkAeGYyiorYEvu8e7mv240VFweSSLRoEVBV5fN2ijoccACw776B5QF+/bUP6btUv5tOUdHel/8nILbv8XnCjvCvfdklcONGjjQH5PT26MGENlAIxfDZ5kUifHhZTGlpKQYNGtQYZd4b9v81wcM1KEMCGDR8H6dgFBTwTkW+DFuVlLB16tnTh5s34p132EgE3mEBLKedO32fvTh0KHuQnsuJKNBhessiHHusr8UkI8B9gX1rtl98wQ5hAMRiwQLgoIN4De1A0b07OyEBEPWxY3mXk08/9fjGAc2mJ2I5BdBsk3HMMfzq81A9wMSprs6bZktEWLlyJRNAwSp9JoAiUBoAz0zGLbd4dquQAAaNvn15F/aAohbLlvGwj2eoq+NwVUCecF4e77oUOATr9DlfMzeX7a7n6vD558DmzYHJ6dBDY2jf3veiklFUxOPnnvf4iRDpu57LKaD8v8C26TNhzBj26HwmF7412+LiQJbpEatrBbDRSDLatWPW6XMEEGgcBvYiD9CyLOzatQsnn3xyYGE5ocY5TZFE52GhIQEMGmKZEZEH6COKiriBmZYZSQvLl/MGtgEthXD00UDLlr4XlYzu3TlcEhBR//xzTvz2DAGN9+3Zw0PAo0Z5s49oyghoX2ARbPS82RYXcyTd5/G+wLbpM6GoiGekffSRr8Xsvz8fvhD1vXmYXkCMzfrcN4nImaf+QDzORwCsLBZjm+CzOviOZv74zRRFRT6NUyTi6KM5D1Y1htdddx2uu+669G4akIXauZO5ZpMZQoCJ+sKFvMqxjzBxmGOPPRbHpjuuWlzM+XEHHJDRsznh/fd50fGRI/2tIyP2358n7QQ0vLhhA/DVVx7dUMymHzcukGF6oIkiS0BgeYCAD8t4iuTPgKLp++0H9O7te1F6CEYTUB6gpwRQWv/PTxA1Yf6fxwgJYFMgoGVGWrTg4VO1mPHjx2P8+PHp3bSkhJfd79o18we0wcKFbMCblAAGFLUYMoR3OVHldMABB+CAdAhcPM49oNh93UeUlLAhHD7c/7whI0Tmv89LWHg+vPjJJ7y4cEDEYsAA3i2jSdC1K9uNgCLqO3Z4mL4b0DC9aLZNkv8nIAhgAHmAOTkeBxvFM/scluPFIJto+NdjhASwKdC7N0cuAlgPcOxYNoTbpL1QxErnKaO2lvN4AmBlxcVMYI8+2veizAhoF4NolAMkqjps3rwZmzdvTv2Gn3zCAg9wm77Wrf0dMrLFmDH8f1fpNgfyDv36cWaAZ+oQ0Gz6wLfpM6GoiB8koIi6p3IKYDb9Z59Fg2q29ohGA8kDFMPAnhUltuUIKP+vSSaAeIyQADYVAoxaECUuM3LFFVfgiiuuSP1mS5bw3mwBRSxGjPBtKSd36NwZOPTQwKIWX33F6zYLvPnmm3jzzTdTv1lAxKK8nHclavIOK+DtxjzLAywu5klh++7rwc3MEM22yYZ/BcaMASoqkJOO85kCevRgsu6JOsjL9PhMLN59l9cXbPL2JAigz3mAnu4LLPL/AmBle0v+HxASwKaD5+MUegwbxkvCeGIMeb2Pxnwen7B1K/Dxx1lgCIHGqIXNPo9eFQN4KKcDD+RkIh/x3nvsDTe5nHr14qh6QPllnmw+EvBsesD3ZuuM+gfIffdd34sqKuLqzXgkM8DZ9O+9l4sDDvC92TrDU2ZmhiBRnow2BzQtd2/K/wNCAth0CCgPMC+Pt1HzpJj583kZhI4dPbiZGSJa2eTEAmDDv2ePtxtwa3DooVytGcupro6J0LhxXjyWLcQ2fSNH+l6UM0SP31zyAJct49n0ARHAwLfp06FzZ2DgQOS+/77vRRUV8aznZcsyvFGA2/S9/35udtg8X6bo6uFZHmBAYTmx/t/ekP8HhASw6dCzJw//BDS8uGoVTzxOG5WVHPJJd/JICigp4ailz1tuusOxx7Jh8TlfMxLhEbLi4gyN4dKlTCwCIoBHHhnwNn0mFBXx9oQ+R9R79+YITcbNVuiTz+Oy1dXcbLOCWABAURFyP/zQ94i6Z1kBxcWNEWYf8fHHQFlZJDvkZFnNKw8wwLBcQOtMB4aQADYlxo71aJzCHp4slfbee7zeR0DEYtQojl42Odq3Bw4/PDCivm4drzqRNubP51efIxa7dvHk6KzosIBGvZw3z9dixDKeGafvzp/PYV+fp+V++CFQVZVFcho/HpZYPNJHdO3Ks54z8tvEMj0BzaYHskhOAecBZtQFBjgtt65u78n/A0IC2LTwbJzCHjxLs9HI3Hrrrbj11ltTu8m8eY3bVviI77/n5RGbZP9fE4qKgA8+4KFgn4sBGuU0btw4jEuVcM+bBwwe7Pt4X5Nu06dD9+7c4/tMAAH+z9u2AStXpnmD6mrOKw1o+NeyEPw2fSaMHg2KRoG5c30vSqTv1qS7RvmKFZynHZCcDjywDvvs43tR7uAJM3OGJ8FGaVrur3/9a0ydOtWTZ1NBFNhE48AQEsCmRECzF3NyuAMQ3vCIESMwItX91ebN42m5rVp5/4ASRJQya4gFwA9TU8OrHvuIQw7hyIVQh3333Rf7pjJDtLKSnzGgYfom26bPhPHjmZlWVflaTMbpu4sW8TMGRCyGDEHTbNOnQ9u2qDv88ECI+tix3CSWLEnzBgEu07NwITBqVBMtpq6D52u02BeVUbBRCsvdcsstePzxxz17toULF+Lkk09Gjx49EIlYePLJx5KGf++77z707t0bLVq0wBFHHIF33nkn6T5urmkKhASwKeHJOIU7FBUBa9bwvvPvv/8+3k+FzGzbxttyBDD8O38+0KYNj7pmDY45hq1UwMuMrF+/HuvldWGcIMIdAchp3jxg+PAm2qbPhPHjOUr7wQe+FrPvvjzJOm11KC7mMSSfw3Ll5YH5Aymh9thjmZXt3OlrOaNHZ5i+W1zM20H26OHpc6lYvJhTKkaPziICaFkcOQhoIgiQJtdUwnLt27dHoYdJyeXl5Rg4cCD+7//+Dy3rjZ080vzcc8/h8ssvx7XXXovly5djxIgRmDRpEtatW5fSNU2FkAA2NTIep3AH0QnMmwdce+21uPbaa93/WDASn3sSImDOHPbcs2qWVevWPCMloO3GNm7k1Sfmz5+P+SKnzw3mzw9smH7FCmDCBF+LSR2jRzNRDyi6lHb6bnEx52W0a+f1YyVA7GKYbXKqOfbYxm0vfESHDrxoQVoEUITlAojSzp3L/sAxx2QRAQS4LYn19XwuBkizLYlpudEoNmzYAMuysHr1as+e7YQTTsCtt96K008/HZFIJCn/71//+hfOP/98XHDBBTjkkENw9913o3v37rj//vtTuqapkE3d7I8TRUXAPfewGzhqlG/FHHooBxznzEnjx/PnN5IgH/Hll8C33wK//72vxaSHsWOBO+7gsIqP+XXHHcevc+bw9nApYf58Dsv5PEwv+FW2EQu0bs1bx8ybB/z1r74WddxxwIMPciBr+PAUflhRwUPAV13l27MJzJnDu+lkxTI9EuqGDmUdnTcPmDLF17LGjwf+/W+u9pSaxdKl3NYDIIBz5gBDhwLt2jXhbjo65OQA1dW44nJCabr5ri6hzq4dPBi4664UfpiTg9LSUhQUFKBv374Jl7jJeZ89ezaOsXGcxfC0TP5qamrw0Ucf4eqrr064dsKECQ0jbG6uaUqEEcCmhhin8Dm6FIlwpzV3LkCUYgbrvHmcr+hzWE6Q06wjFgAT9bo6XsLCR+y/P+9ikDJR376dJxMFMN43dy6vWThkiO9FpY7x47nz3rHD12LGjeM29dZbKf7w3Xc51BFQZOnYY5kEZhXy8tjuBRCpPf54HlyRd0JyhYCW6SkrY98/K21eJMJ9k88zgYEMJlVI+X8rVqzAoEGDEFGm6F500UUN25+ajqFDh9oWo1v+ZevWrYjFYujatWvCtV27dm3YwtPNNU2JMALY1OjYkccpSkqA66/3tajjjgOefBLYd98D0br1l+5+9O23HJr7zW98fTaASU/v3pxflXUYMQLIzeVdDKZN87WoCROARx4BpkyJIDfX5fCLGKb3Of9PDNOPG5ela2GNHw/cdBMPL556qm/FdOjAAfE5c4Abb0zhh8XFPEzvc1huwwaeTf/zn/taTPoYPx6YNYv3PvRxK7xRozhP9a23gBNOSOGH8+cHsnp2SQmTCxH5zyrUT9G96297eLFPH6e+xmIcpW3ZkpuHK4j1/+p/UFpaisGDBydd1qFDB3To0CGj5xPD07rlXyylXogo6Zyba5oCYQQwGzB2LGdr+7zMiDAyO3akMJQrvHSfiUVtLRvDCROydIp9QQEwfHgg21hNmMCzF7/8MoU14ubODWSY/tNPgU2bsjRiAQBHHcWdVQDRpQkTeJ29lOYyzJkT6DB9VhILIDEp2Ue0aMHBxpQi6uXlHKk9/njfnktgzhxWhaOP9r2o9JCTw0TL5zxAEWxMKQ9QGv4FgBUrVmgJ4K233orCwkLbw2lWrnguuW/q1KkTotFoUiTvhx9+aIj4ubmmKRESwGzA+PG8NpjPU8O7d+dcwM6dz8JdrhIsALz5Js+C69/f12f78ENeEjFriQUAjB2LnBUreFa0jxCj7ZWVozBx4kTnHxABs2ezHrl2n9OD6Eizlljk5qbR46eHCRO4X3Q9T2fTJqC0FJg0yc/HAsB/v2tXbu9ZiYED+QEDWA9wwgSeVOV60mVJCXukbtpehpg7l9t7Vix6r0PA6wHW1aUw4izt/1tRUYGvvvpKSwAzHQI2zYPJy8vDEUccgbmKDs+dO7dhmTU31zQlQgKYDRg9GsjP507cZ0yYAJSWtkbfvoOdL66rYws1aZLvYbk5c9gLzKoFoFVMnAhLjIH6iNatecT5vfcK0a1bN+cfiN4tgA5rzhxeGaPJN6y3w/HHc9rCV1/5WsxRR7GsXKuDSBj0WU7xOAfWjjsuS6PpAD+YSEr2ea054VS6ltObb3JYzudh+q+/ZjXNaqc3EuEjgPUAUw42Stu/ffzxxwCAQzUeT4cOHdCnTx/bo6VhPavy8nJ89FEpPv64FPF4HOvWrUNpaWnDEi5XXnklHnvsMTz00EP47LPPcPnll2Pjxo246KKLGu7h5pqmQkgAswEFBewGBkAAc3I4KbqwkLD//sBTT9lcu2QJZyn71GHdcUfj3Jc5c3hf2eXL+XxWYuhQxDt0CEROXbtyXUQiznJqeB6fiUV1NSfTZ3WHBTRG2HyWU24uZ0a89ZbLqMWbbwLdunHOr49YsQLYsqUZyOmEE4CtW3nSjo/o358HMVxN2BHR9LFj2Sn3ESIolLXRdAGxHmA2bQsnwnLS8G+/fv1QUFDg6TMtXboURx45BMccMwR79uzBDTfcgCFDhuDPf/4zAGDatGm46667cMstt2Dw4MF49913MWvWLPTq1avhHm6uaTIQUdYeADoAmAGgAsC3AM6yufZ8ADEA5dIxxk05hx12GDU57rqLdzRcu9a3Ip58kqhlS7FxIh8FBXxeh4orriCKRol27vTleYqLiTp1Inr1VaJIhOinP+XPxcW+FOcJ9px2GlHnzkSxmG9lPPkkUYsW7uVExx1H1L+/b88jMH8+P8vMmcnfbdmyxffyU0KfPkSTJvlezH33cZ2sXq3/vqFe6uqI2rcnOv9835/p9tv5mTZu9L2otNBQJ1u3csO/4Qbfy/zZz4jatWMx2GLNGq68e+/1/ZlOO42oRw+ieJw/Z0MbWrZsWfLJ2lqisjKimhrfy9+9m6i8PPFcTGdra2r4mRwFmhnicaJdu4gqKnwtRgutLOoBYCl5wLGyPQJ4L4AaAF0BnA3gfsuyBthc/wERFUrHgiAe0hMEELX405+S55lUVvJ5HfLmz+exyJQXpHOHoiLg+eeBc85hZ+7VV/lzVm0Dp6B23DgOr/i4f/Of/pS8m5lRThUVHJYLIK/szTcbU+yyHiecwOFlnydWuR5eXLyYl6YJYJh+1iyewNq9u+9FZYaOHXkcfdYs34s6/nierOO4Ldybb/Krz3KqqWGdOeGELB6mF8hopebUkJPjcls4afkXPyHWmc6qjQk8RNYSQMuyWgE4DcD1RFRORO8CeA3AuU37ZD6hb1/ggAMaDZAPMCVBa89v3oyclSt9JxZFRbz0CwBceml2kz8AqCkqYsPjI1FPSU4LFnBvEgCxeP11zlRo3dr3ojLHpEnMolNeAC41HHggH47N9s03ubPyeZ3GHTt4Auvkyb4W4x0mTeIh4B9+8LWY8eO52ToOA7/5ZqMt9hHvvsuT3k480ddivIG8LVw2DAOL5V/qt3/zE9I8k70SWUsAAfQDECOiNdK5FQDsIoBDLMvaalnWGsuyrrcsq/mIzbK4Ey8u5mQrH2BK3NeeF5bSZwI4bx6wciVPCvzvfwPZbS0jUKdOvGy/jwQwJTnNns05pD5v//bVV8BnnzUjYjF6NK8BEkC+5gkn8Ezgykqbi958k5NcO3b09VnmzOEISrOR06RJ3KGnvKJ2aujYkav/jTdsLqqqYgMUkDOVnx/Itt3eIKDlYFwFG6Xt3/xGXV3jPJi9EdlMkAoBlCnnygCY4g8LAQwE5woOAPAcgDoAf9NdbFnWhQAuBIB99tkHW7du9eCRM0PuyJFoe999KHv9ddT6MM52zTV5uPLK1tizp9FratmScM01u7F1a+JexK1feQXRzp2xs0cPTtT2Ae++m4vzzmsNogguu2wXOncm/OQnrfHQQ7sxalSW7YtZj7KyMhSMHo2W//oXtn/xBah9e8/LSEVO7d94A7FRo7Br924OKfiE555rAaAQw4dvx9atyZ1AWZnaVJsebUaORHTmTOzweYH1Y4/Nxd13t8WMGbtw/PGJ8ikrK4O1bRs6LFmCyt/9Dnt8tjMvvVSIjh3zcMAB2/1qthkjQVf22w8dOndGzSuvoNxnZ3Ps2Jb4299a4ZNPtqFbt+RIVm5JCdru2YOyESNQ63PlvfZaO4wYEUdV1a6GdI9saUNxDcmzolFYAKiuDuRz1C0nx0JdHRCPN8pIfiarthYWgLjYq9gnEAGxmIW8vMRnCRK+8xIvEgnTOQAsAECG410AQwBUKr+5CsBMl/efDuAjN9dmxSQQIs5+zcsjuvJK34p48kmiffapISBOANFDD2kuqq0lat+e9kyf7ttzEHGy+tln8zyT7dv5XHExn89WbNmyheiDDzhR/JlnfCvnySeJevasIyBOubmGCSAiYf2ee3x7DoHjjiM65BDz99mQwJ6Eu+/m+vniC1+Lqa4mat2a6IILkr/bsmUL0VNP8XN8+KGvz1FXR9ShA0+mymYk6cpPf8oP7nNC/8cfsxgeeMBwweWXE+Xn+57xL5rt3Xcnns+GNmQ38UA7Q8MHVFcnzu9ImgRSXs7P4jMCmmdixF49CYSIxhCRZThGAVgDIMeyLHln58MArHJbBIBsT69NRKtWPHTlY1L02WcD332Xi5ISrhptAGvRImDHDtT4vCjf73/Pw7+jRjU+R1ERn89qDBvGY0o+y2n9+ijuuMNCba1hhHfmTH71OXKyezenGjabYUWBgJaDycvjSQYzZxoCEq++CnTpAhxxhK/PsWgRbwndLPLKZJxwAj/44sW+FjNwINCrV2OzSQARy2n8eE6p8BFiGLrZycn1DI3MiwEMw8DxOD+Dzwvei/IDmGfSpMjav0ZEFQBeBvAXy7JaWZY1EsApAJ7QXW9Z1iTLsrrWvz8YwPUAXg3qeT3DSSfxwr6rV/tWxMyZM7Fjx+to185gDF95BcjN5RmvPmLdOuDjj/kvNytEo5wnNGuWrzPjVq9ejYEDvwbAOUNJeOUVnu7pc8L63Lm8MUKzI4AHHgj062dQcm9x8snA5s3ARx8pX1RXs56cfLLvOUuvv86dZ9av/6diwgTuZbVK7h0si8Uwb54mX3PlSuCbb4ApU3x9BoAJYP/+jZPfmg0C2hUkEuGmUqvLAgpoVkaA80yaFFlLAOtxCYCWAH4A8AyAi4loFQBYlrWfZVnllmWJ1PhxAD62LKsCwCwweby1CZ45MwgDNGOGb0X885//xP/93z8wcSIbo4SoBRGXPW4cqE0b354BaLT3zY5YAMDUqbwlnI/b933wwQfYvPlt9Omj4TA//MBTCU891bfyBV5/HWjXjlcEanY49VRO7N+xw9diTjiBOy5VTrnvvMN7ywYgpzfe4Ehxu3a+F+Ut2rcHjj3WV5sncNJJvDJQ0vZ9r7zCPb3P3uju3TwxvdlF/4DAl4PRbsEWUFhOBDr31tm/AllNAIloOxFNIaJWRLQfET0tfbeOeK2/dfWfryairvXXHkBEfyai7JxJYId99+UhxoCM4ZYtysjLypXA2rWBEYs+fThI0+xw/PE8y/Tll30txrKYIBcXM49owMyZbKF8jljE40wsJk1qpsZw6lTuNHyOLnXsyARZJYB5s2cDhYW+73H47bfcdJulMwUAp53G08w/+8zXYkaP5mWMkhyqV15hAXbt6mv5zTaaDrAxys1tuuVgRFguNzdc/sUjZDUB/NHi1FOZlX33na/FTJzITl1C3zhjBjeuU07xteyKCiY1J53UTEPsrVpxBc6Y4fvSCCedxEv9JewnPmMGsP/+vm8rtngxBxubZcQC4CV7evb0nagDLKfSUmD9+voTsRjyZ89m9tyiha9lv/YavzZbOQUw8gFwvubEiWzzGprtt9/yvosBDP++/DLQoUMzjaYDjcvB+Lw3cCTC/UICAQx4+Ld+m+G9GiEBzEaI6Nsrr/haTIcOPAEjwebOmBGIJ/z665we5TPP9BdTpzJJ93kv02OO4c1YXhUZrbt3cyLTqaf6bqFeeIE7zWZLLCIRrqc332Svw0eI0UNBxvDhh4hs2RJINP3554FDDwUOOsj3ovxBz568K0hARH3TJilfUzQsn41RVRXrxqmnNuPIknhwbYKed5CDjQ0Qw782ubS//vWvMXXq1IzKFkPPAcwzaXKEBDAbcfDBfARgDM84A/j0U+CTTwB8/TXvJB9Qh9W9OxPQZovJk9kg+iyn3Fzum155pX6N8Dff5DcBDP++8AKPdje7vDIZU6dy7+vjLjtAY7N94YX6E6+8AsrN5QRBH/Hdd5wOesYZvhbjP047jVnZN9/4WswJJ3Czfeml+hOvvAIMGMA7gPiIt95i361Zy6lJdgWxXM/KuOWWW/D4449nVK7gtjk5wMKFC3HyySejR48esCwLjz32WNL19913H3r37o0WLVrgiCOOwDtKXribezQVQgKYrZg6lbOFt23z/NZPPPEEnniCJ1OfdhoHSZ57Do2hQJ8J4O7dPDHy9NMDWczdP7Rvz+vWvPyyL8bw1FNPxan1spg+HSgrq98wYcYMoHNnYORIz8uU8eGHPJzZrDssgL2MTp0CydecPh1YuBD4bgNPpqodNcq3vbQFXnyRX3/yE1+L8R/C7vg8DNyxI3DcccCzzwK0dRsLLIDh3xde4FGXbN/u0hG5uYEMA4sh2Lo6uJ6V0b59exQWFqZdpjz8G4kA5eXlGDhwIP7v//4PLVu2TLr+ueeew+WXX45rr70Wy5cvx4gRIzBp0iSsk/btdLpHk8KLxQSb+5E1C0HLWLKEVwt97DHfixo3jqhPH6L4qFFEgwY1nPdrYdInn+S/9u67vtzeVyTVyf3385/55BNfy62p4bVyz51WTdSmDdEvfuFreUSN6+KWlTlfmw2L2NriF7/gequq8rWYzz5jdXj89yuJANr997/7Wh4R0YgRCc0262GrK4MGEY0a5fszPP54/Rrh1z7Cb5Ys8bW8PXt4sfBf/tJ8TTa0IduFoAXicTYKe/b4/jyVlURlZXGK8xsu24D169cTAPr888/TLq+ujouprk7+rlWrVvToo48mnDvyyCPpl4pQ+/TpQ9dcc432/rp7mBDEQtDNNRNh78cRR/CM4BdeAM47z9NbP/fccwCAadOmAeCoxY0XbAC+eg+48UZPy9Lh+eeBHj2A4cN9L8p/nHIKcMklHIYZYLdNder45JNPAAADBw5Ebi5HTMv+Nwuo3sUffIQY/p00CfB5NaBgcOqpwMMP8/ofPg7JHnwwMHgwQE88CUSjqD7hBKQfj3DG+vXA++8Dt9ziYyFB4rTT2AZt3gx06+ZbMaecwvNy4o8/wUO/Pi/SLYZ/m2WU9ooreHaTDL/34x08GLjrLuTm1g/J1jrP/i0tLUVBQQH6KkP5t956K2691X5FuNmzZ+OYY45JGP51Qk1NDT766CNcffXVCecnTJiA999/3/kGWYBwCDhbYVnAWWdx3tL333t66/vvvx/3339/w+epU4FzI0/BIgLOOcfTslTs3Ml/6Ywz9pIV1rt357UlnnzS82HgpUuXYqk0wWTaNOCM6sdR1bYr71jgI95/H9i4cS8Y/hUYP54TGZ96yveipp8RR9Gmp1B5zPGgLl18LWuvGf4VOO00bkf1TqpfaNMG+GnRevTZsADxs87xfTLV88/z0HOzH/4VEPXlcx5gNArkWnWwQI6zMlasWIFBgwYhonQsF110EUpLS22PoUOHJg3/OmHr1q2IxWLoqkyY7Nq1KzZv3pzyf20KhBHAbMZPfwrcfjvw9NPAb3/rWzEd2hMuLvgfltSOwtDeB/i6f96rr/KSJvXBx70D550H/OxnzJp8zMsbfeh2xPA63uzyG5zs8zTC55/nCEmzXK9Mh/x84Mwzgcce42RKH/Pyzuu1AN2wAa92+zv8zdJkOQ0e3EzX0tRhwADg8MOB//0PuPxyX4u6tMPTiIDw/oFnw89VWfbs4dm/06c305mld92VfI6IQ5q5uYCPeW2WBeRZtYiTBUSithGr0tJSDB48OOl8hw4d0KFDB8eyYjEObKa6YpOlOA9ElHQuW7E3xGD2XvTvz+uY/e9//pbz0UfYr/wzPFD9U7+348Tzz/N+nEce6W85geK003j/UJ/lFH3xOeShFn/99lzs3u1fObEYR5ZOOIEXzd1rcP753Bs3TNP1B93mPoHyaBvcusrfZUW++Yb3/91ron8CP/sZr8u3YoV/ZRBhwPInsCgyAo8uPNC/csBLXpWX70XRdKBxnZbaWn+jgESIxOtQi1yeDWyDFStWaAngrbfeisLCQtvjnXfeSWn4FwA6deqEaDSaFO374YcfkqKC2YqQAGY7zjuPDaGfxvDxx0H5+Xgt7yd4QrvTsjfYuJFzYaZP38sW2GzdmnPynnuOCYZfePxxVBx4KBbXHObrRMlZs3idtLPP9q+MJsGwYZyk5+cyDJWVwIsv4tuhp2PxypZYvdq/ae4PPcRDVT5nbQSPM89kcuGnnFasQOTTVfhs6Ll46SUelfALDz4I7Lef75vBBA8RzvRza7jaWlgAYlau7dKDFRUV+Oqrr7QE0M0Q8BFHDEVtLZM/t6lJeXl5OOKIIzA3YYV+YO7cuRjRTFb6DglgtkMYwwzXNjKipgZ45hlYp5yCCWe0wxNP+Lde7sMPc3Tpggv8uX+T4rzzgF27pNWaPcaaNcCiRSj41U/Rr5+F//7Xn2IA4L//5fx7n7dFDR6WxVHA994DvvjCnzJefRUoL0f335+LnBzgySf92QGkthZ45BGepLPffs7XNyt07AicfDLn1frFzJ54AsjNxX5X/QQ7dvi38szatbyDzy9+0cyXvNJBrNPiJ3uurQVFIojmRRqGaHX4+OOPAQCHHnpo0ncdOnRAnz59bI/c3JYg4kXvZZSXlzeQxHg8jnXr1qG0tLRhmZcrr7wSjz32GB566CF89tlnuPzyy7Fx40ZcdNFFru/RpPBiKnFzP7JyGRgZp55K1LUrUW2tJ7fbsmVL45IDr77KyyC88Qa9+y6/ffDBxuu8Qm0tUc+eRMcd59ktmwTGOonFiPbbj+j44z0rq6KigioqKvjDddcRRSJE331H//oXy6m01LOiGvDtt1zMn/6U2u+yYQkLV9iwgf/gddf5c/+JE1kPYjGaNo2obdsYCRF6iRkzWAdefdX7e/sNV7oycyb/wVde8f4B6uqIunUjmjKF6uqIevcmOuYY74shIvrjH1nd1q93vjYb2pCrZWBkVFXxuimxmPcPE4sRlZVRfM8e8da48sz9999PBx98cNpFlZcT7dqVvMpMSUkJAUg6zjvvvIZr7r33XurVqxfl5eXR4YcfTm+//XbK99AhiGVgmpx8ZcOR9QTwlVdYVDNnen/vKVOIunQhqq2leJzo0EOJDj+cG4KXBum11/gvvPSSZ7dsEtjWyZ/+xNZ+wwZvC62tZVJRz563bSNq0YLoV7/ythgiouuvJ7Isom++Se132dB5ucbEiUT77ut9p/XNNyz/a68lIqK332adf/hhb4sh4r/Qo4dnPmGgcKUrtbXs9E6Z4v0DvPQSC2bGDCIiuuMO/vjxx94WU1PDPHPyZHfXZ0MbSpkACmbmx/qae/YwAayrIyKiigo9ScsUfv6FTBAEAQyHgJsDJk3iMbl//9uT2z322GO8Hc1XX/H0tJ//HMjJgWUBF18MLFsGLFniSVEN2GuHFWWcfz6PUXg0PiuGDfDSS8C6dcCvfw2AdxOYPp1HyHbt8qQoAJzK8/DDwMSJPFFnr8X55/MCerNne3vf//s/TiCqH/455hjg4IPrcO+93ubJf/MN59L+4hfNeE9ZJ+TkAOeeyzMoNm709t7/+hfQu3eDMfr5z3nm5333eVvM66/zcoYXXujtfbMKkQgPBdfUeKvkRHzPnBxQfcJ4Xh6f9nobYjGC3SxnaGeIkAA2B+Tl8ZIIc+cmL8iZBhoI4J13sqG97LKG784+G2jVCvjPfzIupgHffssTC375y728kfXpwyvM3nMPT/vLEKWlpShdvhz4xz94sVqJPV9yCedqejlpR/S1v/qVd/fMSkydyous3367d/csK+NZGWecwfcGp0f9/OdVnjtUDz3Er7/4hXf3zEpcdBE7VLplSNLFhx9yDugVVzQk5XXsyA7VE0+wGL3CAw/wgveTJnl3z6yEYGZeTgYRLE9KyhPr83nJNQWhTGXyx96EH+Ffbqa46CKgsBD4+989uV1bkUV+zjm8mHE92rThU88+C+zc6c1U3Qce4Ndf/tKT22U3/vAHYMcOrlsP0HXNGmDpUuDKKxMs1LBhvHnB/fd7Zwzvvx/YZx/gxBO9uV/WIjeX6/Odd3jtRi/w0EO8LtpVVyWc/slPqlFY6F10ac8ejtLulZM/VBx4IC8Yev/93Ka8wJ13spH72c8STv/61+xQeTXX7rPPfgRRWgHBnqqrvTFGIvoXjSZUnmUxH4zHvduGWKxis1cHJmwQEsDmgnbteCzhuec4pJYunnoKzy5ahFfef597E80KshdfzF89+GDmMxi3b+eA2Cmn7OXDigLDhwOjRgH//GdmYxVPPYXTr74aE2+7jY1rfn7SJZdcAqxaxR1NpvjgA2DOHOA3v/kRdFgAeyMdOngTBayt5eHfMWN4EWMJhYWEn/6UHapNmzIv6j//4WHF3/0u83s1C/zhDxxN94JBr1vHC1xeeGHSApdDh/LapPfc4w25+MtfeCTlN7/J/F5ZD6+ZWV0d30udkotGoubFxGPBMyORH4nN08GLRMLmfmT9JBCBdeuIcnKIrrgivd8/+SRRQQFnPIujoIDPK5g6laiwMEaZ5iVfcw1PKvA6wbqpkNIMRk29uoJLOVVVEe2/P9GQIZnPZxg7lucClZen9/tsSGBPGX/+M9ftqlWZ3efpp/k+r72W9NWWLVvoyy+52V50UWbFlJezjMaOzew+TY2UdeWEE4g6d6aMp1NffTVRNMpT3TV44QUW4yOPZFbMJ5+wzfvjH1P7XTa0oeXLl1MsHWMSj/MMjXQNiAxlSq76PPVzQ6h+bkjaqK7m+9TUZHYfPxCLxWj58uXG7xHOAv4REkAionPPJWrVimjr1tR/26tXIqkQR69eSZd++ilRJBKnK69M/1E3bWLectZZ6d8j2+DKSMdiRP3785TqdKaspSCnxx/nr555JvViBObP53vcdVf698iGzitlbNlC1LIl0fnnp3+P2lqWc79+WhYu6uXSS5l7rF6dflG33cZyeu+99O+RDUhZVxYu5D9+993pF/rdd0SFhUTTpxsviceJjjySZ1dXVqZf1E9+QtS6deomOhva0KpVq6g8XRInloTJZGp6bW3SlFyVAMbjfEkm/kA8TrR7Nx9ezyr2AuXl5bTKxjENCeCPlQB+8gn3JOmsAWJZemJhWdrLp0/fQ/n5HHhMB7/5DT/qF1+k9/tshGsjLZjZo4+mXkgKcqqrY/5x4IHpebLxONHw4dzpmdbYcoNs6LzSwmWXsZKuWJHe7++6i2Xz4ovar0W9fP8984/TT0+vmLIyog4dePmX5o6UdSUeJxoxgpW0rCy9Qs86iyg/n+jLL20vW7CAxfm3v6VXzIoV/Pvrr0/9t9nQhrZv304rV66k8vLy1COBchQwHVZlYGW658iUa2Zr9C8Wi1F5eTmtXLmStm/fbrzOKwJo8b1+3Bg8eDCVejC7NjBcfTXnmL33HpDKljP776/PH+zVi9eWULB8+XYcfXQHnHtu48xDt1i3jieu/vSnvBXS3oKtW7eiU6dOzhfG48Cxx3I2+GefAV26uC+kVy+uQN15jZzeeAOYPJnTpC6+2H0x8m//85/MZv+6rpdsw7ZtwCGHcNv44IPUtmvYtIm3lhs+nJeU0exvKNfLTTcBN97I+/cedVRqjyl+u3gxTwBqzkhLVxYtYlt38cXAvfem9tu33+b8zOuv5+Q8B5x0ErBwIa+SlcpjEvEGJu+8A3z9NdC+fWqPmS1taMeOHdi0aRNqamqQMj+IxTiHLzc39Wm1Kf5W5AFqUgV9/a2fsCwLeXl56N69O9rbKJBlWR8R0dCMC/SCRTb3o1lFAInYQ9pvP6KBA1NzYa67LjmqZMgBJGKP9PLLeW3bd95xX0xdHdGECbxYsSHdptkiJS991Sqi3Fyis89OrZCzz05JTvE472TQpQsPu7vF1q28HnKfPuwRZ4JsiF6kDZHDd+edqf3u7LOJ8vKI1qwxXiLXy65dLKMRI1KLXCxZwmqUbvQw25C2rlxxBctp4UL3v6mpIRowgNMnXI4ZfvIJ27xLLknt8R58kB/v739P7XcCzboNCcRiRCNHErVvn5ox2riRQ+Qnnpj0lalennwyvUGWX/6SB1MWLEjtd9kEhEPAP2ICSNQ40cDtWEV1NdEhhxB16kSb8/MpJnLKbCYqbNmyhXbuZILQvbv79nzTTfxoDzzg7vrmhJSN9A03cGW8+aa76zdsYEM4aBDt7tiR4i7kRMSTbFq2ZCLoxieIxdjW5uYywcgUzbrzisd5okFBAdHXX7v7jUicdNhSTq2Xp57in7mdx1VWxsP7PXuml/abjUhbV8rLedZT377uk/TENh/1u364xWWX8c+eftrd9Z9+yu1v/Pj0J2Q16zYk4/PPebj91FPdDQXH40RnnMHOlCZfyFQvsRinr7Rq5T6DQ0z0SXWCTrYhJIA/dgJIRHTaadzQZs2yv662lujMM1ncr79Oo0ePptGjRzveXjS8FSvYuB17rDO5mDuXvatzz83O5NpMkbKRrqoiOuggzl+yiRQREffwgwZxZX/1FT366KP0aArurSAXl13mfO3f/87X/vvfrm9vi2bfeX37LRPvESM4VGeH0lKOcPTp4xhV0tWLIBePP25fTDzOcxai0dQi8NmOjHRl7lyuvAsvdGZazz7LobwpU1I2RtXV7Ey1aEG0dKn9tXv2cLPt3JkDWemi2bchGbffznJ66CH76+Jxnp0NEN16q/YSu3r57juiffZhH/mHH+yLWreOqF07nuiTbbl/qeJHQQABXApgKYBqAI+5uP63ADYDKAPwCIB8N+U0WwK4dStv3JuXZ94VvraWaNo0FvVttxERpUwAiYieeIJvcckl5uGr5cvZCA4Y4M1qANmItIz0ihVEnTrxxqArV+qv2baNaPBgJvRvvUVElDIBJGocJbOLvj7/PC9LMnWqdyR9r+i8nnuO2dbQoWRc/2jVKlbynj2J1q51vKWuXmpqiMaMYXLxwQf639XW8pbCANFf/5rKn8h+ZKwrv/89V8w555h78tdeYyU/5pi0p4t+/z1n2vTsyURDhx07iE45hR/HyQ93wl7RhgRqa3m9IoDoH/8wX/fXv/I1l15qNEZO9bJ4MbelUaPM+/muWcOT5QoLHecBNQv8WAjgVABTANzvRAABHA/gewADALQHsADAbW7KabYEkIgt0JFHsrG7777E6MWnn3IvD/BQSD3SIYBERFdeybcaMoRI3qe6poboxhv5Ebp142L3VqRtpD/9lMfRO3QgeuONxo4rFiN6++1GIj97dsNP0iGANTWNdnfKlMQZ3Dt3cmQWIBo2jFXHK+w1nddrrzEJ79+fPRrRKVVVMXPu1o0Pp2huPUz18sMPHLXIySG66qrEZvv115xGBfAKNZmu8ZhtyFhX4vFG4jBpEqdNCGzfTvSvf7EMhw1Lf9ZwPZYv58yAdu04Wi47vx98wCPSOTmZLaEksNe0IYE9e3hNHJHzoCr55Zc3EnkbJXdTL888w7fq149jITKXfO45XpanQweiOXPS/zvZhB8FAWx4SOAWFwTwaQC3Sp/HAdjs5v7NmgASsZE75hgWZ34+G8VBg/hzJEL0z38mXJ4uASQieukl7v+iUaKjj2buKZatO+usvSdPyYSMjPSXX3KPARC1bcsMTVRe69ZMDCWkQwCJmATedhuPJBcWsmd8xBEchIxGOS3R6yGQvarzKilheQA8vjR1KvceAFHv3iktHG1XL1u3El1wAadMdO/OTfiwwzinqXXr9NcRz3Z4pisPPMD2DSA6+GAOxbVowZ9Hj/bMGH3yCdG4cXzbvn2ZnB98MLel/fc3R3FTxV7VhgRiscach0iEDdGECaz00SjRL37haIzc1ssbb7BcAA7iDx/eaG6HD09/ObNshFcEsFksA2NZ1i0AehLR+TbXrAATwOfqP3cCsAVAJyLaprn+QgAX1n8cCOATr597L0AnAFub+iGyDGGd6BHWix5hvSQjrBM9wnrRI6yXZBxERK2dL7PH3rQDXiE4909AvG8NIIkAEtEDAB4AAMuylpIXa+rsZQjrJRlhnegR1oseYb0kI6wTPcJ60SOsl2RYlrXUi/ukuFKjd7Asa4FlWWQ43k3jluUA2kifxfvdmT9tiBAhQoQIESLE3oMmiwAS0RiPb7kKwGEAnq//fBiA73XDvyFChAgRIkSIED9mNFkE0A0sy8qxLKsFgCiAqGVZLSzLMpHWxwH8wrKs/pZltQdwHYDHXBb1QOZPu1cirJdkhHWiR1gveoT1koywTvQI60WPsF6S4UmdZPUkEMuybgRwg3L6JiK60bKs/QB8CqA/Ea2rv/5KAH8A0BLASwAuIqLqAB85RIgQIUKECBEi65HVBDBEiBAhQoQIESKE98jqIeAQIUKECBEiRIgQ3iMkgCFChAgRIkSIED8yhAQwRIgQIUKECBHiR4aQAIYIESJEiBAhQvzIEBLAECFChAgRIkSIHxlCAhgiRIgQIUKECPEjQ0gAQ4QIESJEiBAhfmQICWCIECFChAgRIsSPDCEBDBEiRIgQIUKE+JEhJIAhQoQIESJEiBA/MoQEMESIECFChAgR4keGkACGCBEiRIgQIUL8yBASwBAhQoQIESJEiB8ZQgIYIkSIECFChAjxI0PWEUDLsi61LGupZVnVlmU9Jp3f37IssiyrXDqul763LMu63bKsbfXHHZZlWU3yJ0KECBEiRIgQIbIYOU39ABpsBHALgOMBtNR8346I6jTnLwQwBcBhAAjAXABrAfzHn8cMESJEiBAhQoRonsi6CCARvUxErwDYluJPzwPwTyLaQETfAfgngPM9frwQIUKECBEiRIhmj2yMADrhW8uyRITvd0S0tf78AAArpOtW1J/TwrKsC8FRQ7Rq1eqIvn37pvUwROR4XneN7vtUz6Xy6sd3qVzj5tXpnN173WfTuVSuccoi0H2vnpM/m97Ln/14zfSadO9p9+p0zm196b5zOp8u3OiY3Wc/27h49dMeZHJtKv/f7r3us+lcKte40RWn9p5q20+lbaTbnnW/8cMeZPIf7d47fed0Pl1kc1vfsmULdu/enfEfbk4EcCuAYQBKAXQEcC+Ap8BDxQBQCKBMur4MQKFlWRZpJElEDwB4AAD2339/uvzyyxGJRBCJRBCNRhNexXvLsrTfqYdlWcbPABruJc6L96YDSFRucZ9UFF6ugng8nnBeNeREhHg8nvCdfE73Kg7xORaLJX0njlgsZvysey9e6+rqQERJ5+1eTd/p7qdep35n+i/iOlG3oh7Ed2p9qu/Veldlo8rPTUen6oepY5D1T/1s917VZfEq67zcRsRnU7uxa3M5OTnG60yvpvemNm3Xnu0OUQdyO9e9yvWrnrNr7246PhVOhE332dTuU2nzpraRqg1wsgN23+vabapt2u6Q/4+p3btt47Ic5HYvf6e+N8GkJ3JfYWr3Jh0FkNCu1fava/duD7U/1fWpdm3Z1Be7ua/bw9SP6+ohlb5cXCfLKtX2PnXqVEedcINmQwCJqBzA0vqP31uWdSmATZZltSGiXQDKAbSRftIGQLmO/KkoLCzEyJEjtUbYrYciPWfSe5PHrDMWwqBkanztDN6jjz4KIsLZZ59ta2idCFiqhEz+jc7oq88h/zf5v6j1phph9b3JEIvrnOSnwk4PdI3bzsCajG0kEsHOnTsRiUTQoUMH10bMyaDakSKVcMnX2xEs9VUlbep3Ts6TjkyaCJXsTJmIVDpG1q2nbneo7drUlnXfyYfcZuwIkBMZcuMYZeow2bVr8Z1od6od07VpO0Klfu8kPxV2USYdcdK1Y5ODlJPDXatfDpJT2zW1dy8cJ9OzmYigqS2L93JdqnXs1jnSfdbJPtU2LOuWXX8ci8VQV1eXkjNhcnrc9Mk7duzQ6nSqaDYEUAMhWSH1VeAJIIvrPx9Wf84R1dXV+OKLL4xK7KTAsoKqCgwkGw7d9wI5OTkJ35kUWLxXFVlnHFUD+sMPPwAA+vXrZySXdsQyE+V2850bL96po7E7dP9TPZeKF68jk6qhkSHKUWUvdENg9+7dDddk2iHpiJTJyzV1TrrPTh1DKt647noTQbRrq2qHm0qbNXU+at279dTla9R27+QYynql0zmdjto5Rqk4j01xqA6f+ux2zp9aF6bPar3btVn5u1Qht2v5OeXvTG1XdRRV3VTPu23fbgma2tZNbdF0D/k+bp5F10517VWuJ129pNpudbJyA51eqO1X/S/ydzqCqetfTO06Ho8jLy8vpWc2IesIoGVZOeDnigKIWpbVAkAdgCMA7ATwBYD2AP4NYAERiWHfxwFcaVnWLDA5vArA3W7KjEajaNOmjW2noVNGQE/u5Ff1vQ6maIPOUDlFGtwQHOHJb9u2LSUi5xTJM3kwbj0dN+ROJYK6TkzX0ZkIndr41PpWzws4dQ6ykVf1wKkDEO9zc3NhWRZatWqVYDCBxmFH+b0TWdMRMJO3L36XSgRQPq8755Y42nUqdh2F7rOpvjNpp6YogqwXTkTE9JoKOXNyipyigKb26MYJc/Msps+intwOn6brdLkhcGo71dl2+bzJkdARMjdOiqld6tpNOm3PbZRetRlqBD8VEmgid07ETa1vL/tSWW9UnXFyHlRdNbVNu5QHXbtxE8U3fVdZWemo226QdQQQwHUAbpA+nwPgJgCrAdwKoAuAXeBJIGdK1/0XwAEAVtZ/fqj+nCMsy0J+fr6tguoMgPit/CrfU4Ub5QT0nYgbr8ANGZKVuaKiIkl53Rh8t52JH/k4dg1SjQiYOhC1vmWZCe8tGo1q5eYkZydyp37WvRfGc8+ePbAsC+3bt3fties6EJUI6jobpyEg07WZdhBuOgldm1TrXsgoFoul1GGo8jU5YCbHS/3ero26cVrcdCIqoXJLFN0SNJ0DKX9OJRKntkeTcyW3mUgkonW6gGRSJ9qbDBOZk8sQ51QnwaR7gD4fTo1yievsCKBd21Dbqt050+9N51IlaHZ9odoWZflYltXwqsohFajt0tRnOh1CZ5ycDFXf7ZyzVNuym+t05Zieqba2Nq06VZF1BJCIbgRwo+HrZ2x+RwB+X3+khNraWnz33XeuOjhdo1cbltww1BwlAEmGxQsPRz7EOaE08jXxeBwtWrQAEaF3796uCKOps3Hjtch5EfJ3cj6RGiWUf5NOnqH6jLpOza7RmYijXQemknc7yJ2WakRl/RE5gLJeuOmETJ2GiQQ65Q/pXt28d3Mft6TTTaep68DUOrUjkql0WLrOSNcWdfrkptNJhdCl01bcvLc7p35neracnJyk85FIRPu/7Eilm3Yo28ZU2qGJMKpkUdYn9b2uPaaat+smv0/XVp1ydtXfuGmPMpk1kViv+kK7tuimDcrv3faFJgLYXPpCuQ/JBFlHAJsCBQUFGDJkSJJSpgKdAgKJXodKONwYfl1EQFYo2YswGWj1c25uLgCgpKSkQQFNnYHunK6jsYsGqs9qMv5uh4TU+laNvRo10EGVr87gmzoAk9dvZ/zdDOWohnj9+vWIRCI48MADG75Xr0+VlDmRL7cOkMnY29WjG2Ova3d2hl5tczqPX+i3U3uT25Jb0pUKUXJLruyi6KbnsDt07UomV6kQLVUGbtpYum0tNzfX6PDI7U7VTbvhVDfEx6+JFE7tyeTcyPbFbWTOVO9uoJO3U3uTddTOwVHbma4duiFXpvdOE5Xkc3btPJVIucmuiLo0tSc3AQWdPACgvLzclSydYLnpLPd29OrVi66//npjB6vrbHWN3I3HZ/KW7DpMwL1n5BSR0CmfnRdkOuyiDSbSqCOWuqOurs7xe7t7qV6T+sw6I6F2uDqjJXekpkiPaijlVx1U8qPzjOVDpzd2XrqJfDq9V3VeRB/cfG93rVO7SqeDNRFTXV25bWd2bc3UxnTtyqmdmTpBE5E0kUS7c7r2ZGpD4rz8G117MpVp97yiDZleRdsytS/Vdunal66tpdrGhM4A7pw9Xb6cUztTI3hu2pZTu3K6l9pHOUUEdW1N/H9d+1LblPis1rWubYnPqvzs+jNZH9wQT1Mb0zlZdu9T6cvSbYdO/emiRYuwa9eu9MbWJYQRQADt27fHlClTUgo7mzp+mfmbDH5tba1rg29n2E0KJO5vd05VRt1v7MqxM/oqsdIdJkKlGn+5ruX6N0Fn7NMhU7LBNRl7k2HXGX3xO52BdntOjorYGf1UyZQpGqESKbljVB0XO+Nu14bUtpSOg2Ii8rp2pQ7DpGuw6+rqXLc99fdC903ESnVO5N84OSe6NpRJO3JDlpwIkq5NmZxnOx12Q5TsrknFiXFqQ07RRqc2ZHJIdDbMTTsS73UkWbWvbslRdXV1QrTOjhQFSYx07Uh9byJ3unaj1pPcloJy7lX9cGpLQs6ZIiSAAHbs2IFXX33V0Wty6lTtOlbxXszsdBOZANxF/kwdqskY/PGPfwQA3HzzzY7GQCV4mXaouuvSNQBuDJOpU7UjpnKnG2SHqsq/srISlmWhdevWtp2q2hmpRFUXbRDXpBpNcBtl0JWh6+Dt2o3uAJDwHE7ExG0b0rUlnax1HaqbiINOB3XOk1vHz23n65Te4capk9tDqo6daiPUdiN3ZHaRPDtSpNpME9lyS1JVndQ5fnaE1YlMms6l68DZOXV2ZFR+tWtLJvtl1350bUltRybHRW1LOr1TbXkq7cquDejy8dy0E7uyTP2p+h9lGyHahmxr1OfzAiEBBNCmTRuMHTs2ZYVXld1NdFBWCruOw7RgshslduoYFi9eDCLCU089lUDAnEiX2lDUZ7XrOGTlNkUxdJ2rqX51MlDlpItO6ToLtVNwIiEm4+vW2LuNBC5fvhyRSARHH320I1FTy5A7LbcdhKkuVE9VrlM3UQu3nYJKtNW2IXSpurrasSOwayOZRCpScUrcdBK6/+CGWKlkSkeu7NqJ2j50r6kSKTVi7oZApTMUatdmnJwX02ddO9FF+XQkSiVUdiTKKbqXTp/iJrIn9E/tU5zIkRtnwxQNT6XNiPatI092UT03xEnXp5gieXbtRG0jpj5FtAH5vZPNzcnJQV5enlYXdbq7efPmpOdMByEBBLBnzx588sknSYZKNlg6IaoGwC6yJ3eeYpV4cV6GqbMUr2rjB+xXKNd5G08//TQAYPjw4baeky66pzZUtwZD9mB05NDtLgO6z04N3qnxi/NuvCqZAMmvdp2l2nGqumMil+vWrUM0Gm24v100wM17t9/rnsctebTrFE0dpKhHOzIpOmOndmLXVtLpOHVOmI58mpweO8JnRwTtdsxRo3Fqe9A5V3LnqLYFWe91zpeuzagQ5+vq6hJe5bahthfRlmRdkb+T9cVtR6prRzoCanqvI33qd6Zy7Nq2/P90zpUTeRT1orYJGfJnnZyi0SiIqOH/qXJ10150euTUhtwcaluya3fpHnbtXvxP8f/sCLfaVuR6VNuNCUKWstxE+bEYp5LY6cReuwxMUyA3NxddunSx7biAzPKegEQlSSX64Yb8mDokHTGrqqoCAKxdu9Yx0mfnuZlInVNH6PQ/dMZG7rDckDkT3BA48VlnsNVzOoJkF/FIJfpRV1eHSCSC/v37G69JJ7Jh13Hpoh2mSKDaDtJpCzrSJstW1w6cOhqTvolXdZhHPm/S/VSucRv5k783OTTiu0wcG7ftQSUbqUT/dOTIpP+mNmFqI076nm570Dn8avTP5NDo7IWpHTi1BztHX2f37NqB6kSrtthOJ1PtA+RrnCYH2Tk9JpKXSYRPtS1+tQUnB8WN82Gn16ZzpaWljv/HDUICWA+50YnPQOLiwPF4PEFJTN6w7t5qOeK9rrNzauA6wmdqXLoGL8o3ETu1c1IbsWpoTCRW/u9ODVA2pOL6nJwcEBEikYiRAJrqWb2vDDvjDdivtacjSXYRg1Rzh+T3YsJHixYtkspQh3fdEDxRH2qkQNRnJBJpkLP8f91G60wwdXDye1mvxXlV3906Qiby57aNmDomNwTOLmKh/kdRfyIyI3ROro/c3Fyjzqt2xU7vTZEkE4HRER6796bDzjFyS8Z0+mwXkZbbqInAyVEXVTY6Xbcjdbo2oJONk/67Ifqm9mB3Tm0vbqJqTlFm9bNarsl5kSNssv7rbLzuvU7X1XYh9NskJ7sIq52za3KG1H7C1Dbs+g/1Ors2JdqKFwgJIHgh6K1btxojJU5C0imHqkCAe6NhZxx0RsENOZTPHXLIIYjH4+jRo4ej1+dHvocpQqIzPOpkDNlIu4kQyvWpvreTiR1JlAmVLgoi64tTRE717OSIh/h/W7Zs0X6fynIrannqc6h6LwiJXecv/387kuiFvgs5u+ngVH23c2rs9FXWWzfX2N1LfkZBtE3P66YjVd+L+jHVrZPOq6TQTadnR/ZUPROdlp1+utVn03Wq3umcM53+mzpiVedVO2DSeyd9l3Vdp/cySbLTeTuHx+T8uz3UZYCEPZKfTY7MqffXla07p97H1K/JdsDOxrvVd1WW4rNq10223uS4mJx5p9Eeu1xW9fnEvbxASAABtGzZEv3790+rMbslazqiZhdhSLXRqp2U2oDl9wceeCDi8TiKi4vTmgCie1a7hqwaNbUxy6+qNwc475whG2dTAzZ1VnZRODcdUySSvDRLKgRNvb9dJ6X77BTh0HVYJp12o9sqGZPJlVPEQEf45c9+T87QlWEX8ZD/h12nZOqQ7HRa1W1VLqochdztdFvneOgImOm9ncOQiXNheia7CIfsTNk5125stRu9Vo/a2toEu6XTcTsb7mTP7QiTk921ey8TMrWNOfVHqei0V3ot7B8A5OfnJ9k0Nw6HEwlze87pWrU9qc6FSZdN9lnVbVFPbpznli1bGus+FYQEEMDu3bvx9ttvJ3TaqSy6addRq16mLGxVGYDU1n1SiZTauE0RQdloqNER05IsTq/qe5V02v3GRGJ1nbfO4zR5j3YGXq5PHXQNUtdo3Rgpuw5V1iOd7slrm8mvdu9lUmp3bzedumrwcnNztQbOzph5odd2kRAdoTR1qjq9FLpl0lE73RXr/pmuUduVaQKVqs81NTVGp0rtpNX6s4MuSqsjWSaSKZNGOSJh5yypuqfqp1u9dtJnu7U2nTp6uw4bSN1Wq/IwyU0lYipZMzncdnYzFdubrn7rytP1KbrJfephqhu3ttpOr1U5yrZMfrWbpW7SJdXGqroqf5bPmXRf1mE5qKB7Bqf6cIuQAAJo164dTjrpJMdOytSYda+6xusU3bBruLpOyXTOjpDV1dXhvffeAxHh8MMPN0YK3XiZ8qvOk9Q1YFVxdR68qQHbdUgtW7ZM6pDcNFq1k9E1VLXBqkTLrqNSG7NsWHSdkPx+7ty5sCwLkyZN0pKsIAiWmw4oHWdB7mBM37vphOwWXtZF+uSOCbBPKHfSXZPeAvqcOpODIDoglcC4JVQm4q/T51RJlUqu1OfS6a0uCmKKTut017IS86tNkSiT3bVzequqqmz1WGcPTXZY1ktVn+3agIlIpUueYjHzzFWT3trpr05ebvRXvJdzlnV664bIOxEp0++cnAFdcEanu6ojYBd9doIpCGEXsLGzveJ7LxASQCQuBJ1qJ64qlhwaFkZXR2J0HXiqnbhsGFPpxFevXg0iwtVXX50SCTURStXoedmJ64ygOCfKdiKgTobQRELT6cRlEiq+c9uJq8Tz888/RyQSwcaNGxu+1xHYVL1HWV91RlDWYZ3+6gygqTMXda7rwE2GUOiCyZlyQ0bdEFFVx3UdutvOW44k2hltlYTW1NQkEVC1jux0V9ZhO/3VRfdUe6Xr0HV6o3bObiLOOn3Vfe9ka2W91UVuZB120t1MHKh0OnKTI6WSvlRJqfqdamuddNbJaRKfVcc/Ho876q9boiLbD50TJeQK6KN4qjOi6oobh8qtfTa9d3OoxFM8v/xZ/I+8vDyj7ubn57uqVyeEBBBA27Ztcdxxx2lJmFA6wH6TbF1YX/YITYTMTSfmRMCcoivqdRs2bAAA/Pvf/3Y0DCoBMxkDUT8yIVUNp1xvAm4jgDoC1qJFC20H5tRpmQiTbtjJ6bPpPnYGQI2mmDzQGTNmwLIs/OQnP7H1PJ10VJaHqqPyUJNKtO3IlptOyeQYyN+5IV2ygyB/Z0e0ZL1V/7OOZPmlo3KnlJeX56ijdp1OJvqZqnOg6qiOYKnv3eqoqqeyndBFY3VOgSr3mpoaWx016amqf06Ore69qqNOREvtC7zUUZ1+iu9UguEmmicWJzaRHyf7maqu2jkJOiKls6EyqbKLQutIv9BTHXHVkX47x1XWUVU3amtrUVVVleA4mvp63fvt27cnPV86CAkggIqKCixbtsxRyVRDaPJMZGUThh9w3j5H52mqkS3TUICdssmf6+rqsGjRIgDApEmTEpTLFKFTlTAV71KOiqjRO5VEqv9ZEEtdtFM0IjUyovPo5UYvPpu8SVXGulc7D1MXvVDPufVCv/zyS1iWhUWLFtl6kTryqOqozgCKepLf5+SYTYJdJMStnpoiDDLBsyOfTkNnJmdKbQOqU6NGanTPLHRP1kO1oxbnVYiyVQh5yDordFF+r9obXectrlGjYjpbJnfyTh2sfMjX20Xj1GfSkUf1VW2rOuKtqz/xf5xGSdLRVVMUzOR82L2X9c5JB+VXEwmWP5vIsy4S5yaqLH5XW1uL2tpabVROPafK0o6UqZ91fazOxtnZZTuHRWcndXZTfi+3P9V+Cn10iiJbVvJycbLOCm7gxqbKcm/RooVRdqkgJIAA8vLysO+++2pJnfzejcBVIyQLT+5ETIbHbcdo6hTtktLFa0VFBYgIpaWlKQ0XqMbLLkfFFBl06ihV6MibU7RFZyzsOkHT8JNThM8pd8opEmhntCzLwrp162BZFgYMGGCMsrjVRbnudURblZvcuegIlEzo7fQxlSFY3W+diJ2TQyG/ijpQHQsvdRHQLxdh0kNVF1X9sRt6cquXdvpo19maOkk/ddFkG4V87ZwDJx10o3fppqqYSGGqTq5Xuijeqw6uLm1Jp5Mm3dHZSlP0zmn4NFXbmIouynqo6qMaRTXpotuAi5vDSR9N+aRy/y+/7ty501FH3CAkgGAlqK6uNnoEJg8VcFYyWdkiEV7sUm60ArLy1tXVNbyPxWIJ7508l0gk0nBdLMYL+tbV1SW87rvvvojH48jPz0c0yus75eTkNCiYeO9EAFXipyMSgPM6fU5QCThgv1izzptUIxSqIZSvU+WpI/VCHrpr5UPUp5OHqpNp27ZtYVkWKioqtHrnpsPVPZN8ZOKUqAbQjbOi6zRlyEY9Go02PJt8TudwmPTOFAEy1ZX6LHY6aLIT4r0p4qHTOV1EzvTeybGRoxTq/xVycYp+OHWsct3o9E+uVxPpMznJTp2vW92U36s2yxSB09kx8R9zcnIQj8cb6lvWNxOZVf+3/NlO/9T6NUWdTPLS6aZJH3WfdTZU1Rc14uvkOAj9E3UmR9dUXZN/o/5ntU3awRT5tDtUW6jqo6qbaj+X6SE7OuozAYkjBJkiJIDg4Zldu3bZGlTdASCJNKjkTkckxHs3ymfyOlL1fmXPYurUqUnn7PJd5HNq1Efu7AXBlTt2QWDFf06FFMr1pWv8JkJod+Tk5CR1pk6er8mrdfNekBgiSjB48v9Sjax4HTlypJFkmIykrq7sOmKTkZN1Tu0c09U73ftIJNLQGcvkWjWE6v1Vx8QuGq0jh27JoEoCdQRQ1j9d9E9nU5wifuJVEI7c3NwknRHvTVEaUyQw1eifiQy60TlV33SOhyprnb3T2Rtx2I16qJE1cZ0u0qKL+pn0Tn0GVfdMEb9UdU7VOx3JUw9TVE/VP7voskoc3do6U7TQbdqAqX816ZudrUu1f3XTt9rZOjklSdUnL3Kd5WcT27lmipAAghegPPDAA1M2bpkQOLeKpXaYus9O36n3Mhk19fm86EhNXpv8mm4napdbl2qCvFPHqXaibjtPHVlTiZsJat2qnaSJsOnIm52e6YyR3dCE3fV2nbXcAdsZYZ3Xq9MxHdS6laNsdvJxE1lzyu+061DtnAw7vTLpli5iZ7Jfqp45ReaE3OzsmRNRc3uYnEnZZpl02Y1uyUTTRMRUkuhWt8Q5kTfrZiFjHfExOQYmAmd3mO4hl6nqky4aaCKdcl2oeiVDrU+TjolledSol07XdFFbne7JJMrNdfJ73avdYUfw1aivgKxjchTTFEhS7ZiQpRcICSCA8vJyLFq0KIEouPWi7RpXqh2/aoh0kRq3hNIu6vKPf/wDRISLL764wTtRSaNI/hUkwEQ4dWRT9WREQxSNWP4P8me1IZkakIDa0csGC9DnYsnysouc6MhjTk5Ow1pqbj/rzulIqY4czJs3D5Zl4cQTT7QlL270S0ekTE6LjkTqOmk3DomqU7r3Jh1048i4IZoqCdAddrqlHqaO0ynKZ6dXmeqY6VAjMWJpFB3ptIv6yR2+Xadv0i+39ssuipyKfqWqY05OsqxL8ns10qdzXFLRLxOBVO2WeK/K1km3VD2KRnmSou68rGe6z6YIoJNuqTrmZLvs7JfJQZFllGr/aKczYra50/dOqxwImyWvgyq3BZN+if9bWVmpbYOpIiSA4IWgJ02a1PBZKKDJQ1YJi2zQ5GVfVAMiK4AseF3HKL+K97Jy6a7VKaCu7M8++wwAcNdddyURMpOHYyJjapQhVUMmd5ZuOkhhhGRjpBoy9Rr1WlMnqSOF4rllj11HwFQyZkfwZSNmR77EGlt79uwxRt5kPZL1yk6n3OqO+qoznCZir+qQqkuqHqn6pBt2VHVI1R+hB+noU6rvnTpEu6ixE5m3I1l2+mQXqZPJcXV1dQKJT8U+ORF50zm1DNVJdEvgdREluT5UHVIdJCfnUNWn/Px818Tdicg7kfdUdEi810Xv1MCDSZ/UtmhyBtWRBx2h2rNnj2tSpdMVk83Rver6VrvInmqLhD6ZRq90UO270B83/Zt85Ofno6CgIGVdUo+77rrL8ZndICSAaFwI2o4oOHk8QvhiGEBnbNIZWtaRTbuGqDPqqjG/6aabQES47LLLjGTT9NnJk9YRBNWLFmTDKfKXqucsG0QdQVBf7Qy7HQFwSzbtDpPXLBv43NxcWJaFjh07GqPJTtEYIDHypSNoJm85E7LpRDx1pFP2lO30SNUpUyTGRBJMTot8yDqkDtmZnBe3Rt0uoucU7bOzQ+K9rEOWZTWsP2iK7jkRTieSkOqohE7WbsmB7hpTtEXVX/VZZP2PxTivyolwyvVhsklq+1TJgh3pFHJMN6KXKpHQjYCYnBZhj9T/o2s/drqkC6jIJNMN4dTZJ53c0xnFMumPqkcmuxSPNw5ty4fahuygG92R+cSWLVtsf+8WIQEELwQ9adIkV9EbNfys60xTJWVOHafcSXpByjZs2AAiwr///W9j2NlN9E+uKx0ZA5BkSCyLt22TOy07Y+dEvkwEzE30T1e+yTibon7yf3erM7rIsTAc8gKhZWVlICKsXbvWsZNUCbspkpzO0KtKuHTEUTXmbiJ9uoixicCL94LMpEreU9UdOcLntIWartOU9V3WG8CevKtDXWq9qhEy1e4IeTpFX+xGFUw6pF7r1GHaRfdMEWK53TjpjG6kwW6EQchM3qpMlrVJb+ycvnQcP5POqLYm1SFSu5EFt+S8rq6uwf7YEXKTftj1SypZ10X0ZJuj2phMAwaq7dZF71R9UQlyTk5OQlTYKShgsi3qtW50Rn4/ffr0pP+aDkICCF4IWuQAqmTE1EjVCIEcHQDMszJNw8puPGrVmMoNyU24XRwPPvggiAiTJ092TRrlxqozIHbDf8KjFo3ZbgaTk+fjJiqja7iyXFP1rO06fznqYqcvThEYAA33F58LCwsBAN26dQOgT6h2O/Rnpz86A2zyqN3ohvy9Wp76bDKBNEVexKvcOQidUNuaaVhe1h03URiTHumibk7RFKeO3y7FwEln1A5Nni2sG+LT6YzaweqiwiYbpDoJJhJoIhzqOVGmruN3Io9qZEWN/IpnVW2yaXhPN7yq6wdkHVJlayd7J/1Q76sr142uuBkOFvZU9F+mfkqtczVqp9ofVY46R9IuwmeK/OtsiWxHdDoi2xfd/9LpjIBwzmtra426ozokupEp9bOTPpl0IFwH0EOIWcCyYExhbTsyp+vUTI1CZ0TdEjnZk3IbxZHLyMnhVfM//PDDJMPuJrJjMrKqYdGRNztP3WQU7aKDdl68LiIkrrPrsHUdtHhvN/ShqwO1E1ZJsc6IifcFBQWIx+NYv369NorsJsJj+pxKBEf3fKbO2E4/1Ppx8sidyJldFNAU9XWbl2Ui/KZOOhXCpuqHrCd2zqCOhOlklap+pDvJSyX6alRS5wTK5D5V/VDJvOoAis8mQp6ujjjph2kEQXYOZZunBg5U3XATMFDJjV2ET564IOuHKaXDpBdOOcI6vdAFClSyJutHKn2MibjLryaC7hQcSKdPcTtJRpRpsiFuOMgLL7wALxASQCSuA5iqQQeSJ0IArIzi3tEor+eVk8MLiebm5iZ0pCbvR36VG6edkXdKwK6rq8OwYcNsPXGTBwckrtulNlQTTA1VkENxH7VzlMuJRqMNzysaVm1tbcOrzsibIjSmTl022Ol08G4cBfGqG9pTO/7+/fs3eJ6q0RdliOeIRqNJhlLueHJycowduNyJO0XtUo3CyP9b115Sjb7Yecg6kig/g9rRyO3PFJ0xRV1Uh8aNTqj/3aQTpoiLTkfUjt8uYqJr56J8UXfivdAZHfEXNkEuX0dcdf9L1Qei5JxMWbfV6K4pwqI6DeJ7mSS60R/ZaZX1RbQRXTnqcznpgqr/JqgkyI2O6Iihqie6z27eRyIREFEC2VX1QDy3Svztnj1VONWrbENMeiKuc4rQ2QUAZBkR8bZ5Jh21e15xL1U3xDlZBwQqKipSrjcdQgIIrtjq6uqGzkOQDNXwC4iOxSRIcU9xrazwdkZc1/kK4pebm6slfDU1Ndpolap4pv8diUS0HbbaiE2dP4CkVx2cvHmT56wjbqJsEckUkO8vDJb8nS6yZCKNbqI9pmigKE+tU10k0BTlkTtwXXRYjhyIulc/yx22nYMgJuTYRQIz8eDtdAEwz6hTIzw6j12QFp1eRSKRhFwbk0ef7oQvHWnQee6qPphIn842yI6YXPc6507IXdzDNEnHlBivflbLSTcinKlt0OmBeK9z9GSnSP7OTV6wbpa3qg92zkKmtkF1pEy2wS5gIB+qDXCasKXTEdVp1NkFUbZqE7y2DbJO6PoM+bzc5sW9hO3Q5ffqlsPRRYzlcnQ6YRc0sHMGUrEN4V7AHiIvLw89e/bUCglwHvZVPWGdN+4memdqlLpJIDrDburA1fyszz77DESEPn36NDwbYL9nr0qmZNIrkzhTpEaNsqkG1W5NqkyGZtw2UBNhVj101StXo3OmyIwu4mqK0Ipj8eLFiMViOPTQQ22ju05LJOhIpc5Ll+Uv67oMuW5U46oaapUo6WThJlprJ2PVCLsl7zrDLJNqO6dJlr0dkXcTjbMjWmo7tjtnur8uoqMbQlSdExNUcuO0+LHODqjkTH6vI3Ym2bqRtRy5UaM4ujZvR9LEqy4i6xRxUwmS3aESLDk6r57TOQcmXVSJuS46a5K92jaEnHRRNlP0zETe7Ei1nXxNsja1cfk/6Ii5Knc1Uq32+bFY48xxtT3p5G96tbMRJhsSzgL2EBUVFVi+fLmRbOgIixyhEB2h2qEIqOFiQK9Quk5D1ymopE+duaeb+Skf69evBxHh8MMPR21trXZ2n0oydc9CREnLudgN+cgGxC48r9axXPcmEii8Ot1n9cjJyUFeXp7tTFCZRKqTgmQj5pZA6mRvMhiijsvKyhCLxTBu3DhbZ0Gd4WuSu5ilp563iw6qBEPoha5TUaM+OrmLV1X2dp69euhm1Knyk+Vrpwem2Z92Hr6Td+9W9jIB13Xkcn2b2qVOlib5q3qg6pDOudARTDeyF/9VbfPyYXIY1SifKQcrlTavHqreOEV6nCI7sqOok7uoDx1ZVDt4HcnXtVOTzIV8Te3dbna3yTHRPa/4j27tvVxPcnvXRfnlV130Xm23btq7G3tvF+lV5a+SSln+quzVdmIigaZAkSr/2bNnwwtYOi//x4bBgwfT3LlzjaF5U7RPFp5qNNVGpjPC6nunc6YGLF5V5dEZbSLCli1bQETo0KFDUpRHNdImj07nscsNUzawukP+zvTeruHqGqw6RGTnAYpXXeTDbSNVD12k1tQB230W8vzyyy8Ri8XQvXt3x85ZEAh5uEBHxu1kbTfsZheVs+uAdcZZ/awacfXeOgfMLpJrGl5xatNujbGb9u2GhOt+b9cR6+Qs9FXorl3UVq4fE/mS27WJeKVKuk3Xyx27E+E2RfBSlbMctTPJWSXcug7YiXCrBM2OZNfW1ib1JbqhVNlGpSNnnYOlti9T2xbytXO2hZzt7LQsZ9Ve69qyU1TebujcZLvdtmudzNVr3C6NJMvYyWbLMtb1zwDw7bffYs+ePc6rxTsgjACCF4KeOXNmUgelKrcpOiBW95YjGToDJZMOVXFT6YTsSKU4X11d3UBKVGL57LPPgogwadIkV9EBXTSouroalZWVxkiA+J8ydORSHSaQDZTOcOjWccvPz0/ohMQ14rwTwdR5lCrhEPdziv7YORFqh63z+mU5z5w5syECaNfZ6BwHE9FUIwMmoyXkXFtbq13U1E1npMpZJRwmWZvkbJKh02c3nr9MNvLy8pIifXL0QrzqZC07EXbk0tQBuXUi7JxDHdHUyVst340TIcvaKaKvkg7ViZCjOzp5u4nq6Gy1nbMo65tYU9JtRFfXrt1G9OyiOk5k0s5JNAUFTHKW833VKLRqr5zatHgvO4u64IAbRyKVQ0dITSRTbs/qs6brMMpRe7ft2kQkneyzSb7ff/+9Vi9TRRgBBHDYYYfRnDlzbBVA7fjkYRvZeNoJ2y7CJ7+avkulscsGSO24t23bBgBo3759wn+1M+Tq8IyuQcuG1y7CJz6r7+0iRLpGLnuw8nPKHq9Tw9bJVdSZ8NrcNGJVtl7IddOmTYjH42jbtq0rubo13KnKVe1cdbLyUq66SJ+qk24MthrtkYexTXJVDW86ctXJ1o5wq4TBaWi1ucrVrr26lavJDmcqV50sM5GrF+01XTucTXLNxA6HcjXLdcGCBdi+fXsYAfQCu3fvxjvvvKMNe8teqm64RHyvGi/dEKPdsJNQcLshRjvvzykKII5hX3yBqdu2oVttLbbu3o1H+/bFvC5dkiIBaqcknru2lqOL6n+T/7M8FKE71DwfUb8mhVc9RdUD1EUBnMiFSjJMww+i7HTkahfNra213wmm9wcf4MiVK9F+926UtW2L+ePGYfkhhyTIX/c7VXfUdAA5wqMarXic9x+W5SsbbfFejnKrclUjPm6HmdQokJrzY4rayZ2QjjjaDRFHIjyJIT8/P8EeqLJVozxO3r+cBqJ2XCZ5mcih2unIZZiIo06uABquF/KVZSraq27oUI3uiLqW69zUccnyN7VHXZtUz6kdpU6mqnzFvWT5qu0VsN+PWzd8aDdkbGp/pve6++r6BvFefV5ZX8XvdW1WVzdOqQC6NqVGcJ1eTbZWZ3dNNlgXpbMsq8E+tGzZ0rbd2qUA6Po6XXvWtW+1r5Z/b/qsk6tKgE06KsgrwJsqeIGQAAJo2bIlDj744CSPFEhem0dWMiE0oQyiY9U16lRCwabokPq9IBJyByKfU5X7+G3b8IuNG9Gy/j902bMHv1m5Eps7d8Zr9btOiP8sXtVOQY3QCCNh8lhkgub2sNuuyxQlEocpV0j+X0J+usamMwSq4dYRMCdZmQi5zts8Zv16/Oyzz9CivvG3KyvDCTNmYOnSpZjVpk1SfpD8f2TIuqvKUTX2cmdtiu6qJDtVuaq6YdfRq+RD51zp5GjnXMkL4prk51aWunZoihyYOgmTHOVXnRx1h4k8mQi2kIEa8XFqrypBt3OqdFG+TJxkccjE2jShxc4JNslT1QP5s2zndbZVN5Saihx1zpMcYMjNzUWrVq2MUT5ZPiL1xSRnVQdMhN2NE2XqG02Ok9weVRIlZKELdqjROln2JtnK38lOt0rcdY67Sq5NQQ7VGdaRZ7v+UScfXX+onvvmm2/gBcIhYABDCgqopF8/FqpQbCDxvfgs/1AOaQtFkT6T9EpE/F76bHvI3ovLcwnn5VB0/eshZWXI08i72rKwsqCg4XltoakPNRdIrjfVWCQcakTG4XvjoZYtnskkO81QhCxHkwxV+UGuZzcy1chLdxywZQvy4snLMdREIvisbVvtcwGJnU2qMkzSe7kOXcgTbuSkk5VOXppXAK7lB5jboaMsJTk6ydf0vfbeUtkNclLlp/wHk+wa3qp1Y5KfIl9TGzVeo7mfsa3pZJaG/NT6SKonp/o1yNYkG9N7u1f5WRKeV/NfGqDKT1NX2rYpvRrbSprXmXTI+Iwuoeqz9rNDvZrarKN8nM5p3muf3QY6LmCsL7d1rcrGcG5ETQ02bNiw9w0BW5Z1KYDzARwK4BkiOl/6bhyAewHsB+BDAOcT0bf131kAbgPwy/rLHwbwB8qA4aoCtjVgQohCqSyL31sWQAQLaDhva+DrjQ/qr9cZLW30ygXByCXCUzgTf8KtWIf9sB/W4a+4FmfRM40ej3gGzf+zxHeSwlLD11bDbxu8wnoDJA6V2EV0nw3faQmiiYTIz+skN6nekwyJkKG4RJaRJB87OcTV9zafG+QUj+vlFH8GtTU1DQRCVm2t3BQjpHqvot7IZGzcyqz+s/E7jSxNxMNEJEwyk/+7trPQdeompylNmdk5XSrxcCs3K+GjJDel7sS5iKbzT2o7qcrMzgHTPI+qP+nILanuDHK0k4uTzHTyMslOyMsVUde1I0lW8ns7+yVeHeWUqszUdqbIKm25uZBdXPNdWu1ObX8Av1fLV55Rfu4kmOwfzG3OaNfctC35O1071eiE2ubaVlaa5ZQCso4AAtgI4BYAxwNoKU5altUJwMtggjcTwM0AngNwdP0lFwKYAuAwsKznAlgL4D9OBdb07o0NTz5pHAKWkaDADrleTsO+TsuBOC0BI4e2dUMUaj7QRZ8OwR/oP6hEKwDAt9gfF+JB7LCiuLfXUlc5e6YEVbthiVSGBXXDg055ekJOQlYJhluSFVHqa67ZDS+pwxDqb+ThQV2Opyl36/yyE/H72P3JcopE8djBnzX8X5OsnIbndfl3OnnY5WyZhuHVISPxnAlGTQMhJznPSR3G1bUxXZ6dfOiGfZ3y7Ozy68SQraxXdtDVg5rPpsurU4ePTENJ6nlTHpbdkJ5uWE8nJ7ldqflVdrlVdnlUphxHdYhQ/s6UtyXbZFk26nCeDJWc6Sal6HIQde1MlyvnNg8u3Vw4E5IImDIcK8tM1XOd3Ey5irq2oms3qlzU9m6Sjywn0Z4ayJKS1qLKzCQ3nZ2UZajKQPde1RVT+3FqR/Ih2z5VVqot3PX3v9vK3y2ydgjYsqxbAPSk+gigZVkXgiN+I+o/twKwFcAQIvrcsqz3ATxGRA/Uf/8LABcQ0dHaAiS0bHkYHXDAvHphCgHqhCoEKr9Hw2cdGquX6t/zK9e7wVuKi/dx6XO84VV3znxN4+eanfujgtomPWMr7ES85RrpmRqf2SAdWU71/z2xjkQ9qfUpf+b3EZtzdte4lZMsG+/k1Fi3cr3rZOFWTo3va8uClZOuLkW9y+/VV/N3ye/NEYnEZ0pPTmZZ6duSe5noZJksf00UCUhZTo11IdeJKitVRu7bkE5ezjbPJCf5mTOTk9qWdG0iNXk1lZxkWaUvJ5281Pd2cpL7qEzl1FhP9nJy065017iRUaJ8vJJT8uFU76n1TeqEM0uSS+ZyqqgYhk8++WTvGwK2wQAAK8QHIqqwLOur+vOfq9/Xvx9gulk9obwQAPLyDkW7dskdrlrpiYZLMHXZE3bbCASjd3ttKg2DlGdvVKoaaqOtiwq0RasE4+JE1uxe3TcM50YBKAPxsnQa/qNcD6rHm2rnnyqx1skmUV9kz9bJYPFrlY2c2uXnZSSfZIPm3PGrhsosG1n3zB1K8my3VDt9MwEwkfTkNpyoQ4n/QSbO8n/W1YmFaFSuP7Ns7AmYfRuRnar0OxA58qCXTaJ8VNvm3Onbk257Gya3k2S5NCLx/6pDq4mOTWM9uyVkelm4CQzo24lZLnryJcvFJBt9n2OSk+46nVwEybOzX6nIJZl4JTudkUgU0WiyXPQkTPfZXiaq05I+KdY5mLJsxAiTUxtIvY3onKdY7GuzIFJAcyKAhQDUDfDKALSWvi9Tviu0LMsiSlZb4kjhAwDQq1cv+uUvn0J+fn7Dmki6dZF0Q5S6Ia9GYxCtF1i0ofE2hnGt+nA5UFeXOOyomz0qjurq6qRX3Tn5N+I+77zzBKqruyVVbE7ORnTufEZS2D5REQHAQizGDYuI/y/Ar0QRRKPJQ1RyPYoZanL9tmjRAnl5eQ3nxbIc4hpVJia56IYl5dl18mxgALCsCIis+v8WQV1dHYgi9XUAxGL65TtMcrGTj0kmuplttbW1WLlyJmpr90mSUzT6HQoKTmyQTb0e18uD5UMUaXiNRKL1BjZxOFieDarKRZyT5aHKQpabSSaybEwzRJk8RevlYSn/Aw3yiMctxOOEWIwShgJ1szVl2VRXVyfISZaBaDe1tbUJ5+XrVdnIh2kWaKPRliE6okYiEo06p1SIOlVlpLYJUxuR5aXOCNXN+tQNcTW2F5YJEwSAiGXCcklc7kJdnUC1aU6HKidVrrp0GLuZ1jrZNNoCmVToh+Xl+lJnZqr1bjrkRellGZlSYnTtRTcjPrFPQ72MUC+b5GVNdP2MKhtTn2M6THJRZaMbsje1mUSyp59hq7YZ0xqGap+jay/yd6aZ0+psaVU2KglttNHJsjGljKn9jEhjUeVyxx0dkuSfDpoTASwHoIZG2gDYbfi+DYByHflT0b59e0yePDmhUckel5rnV1dXh+rqalRUVGgJm67TFx2OStzE56qqqqTOSpdvpuaS6YycQKOXxcrZsuUtqKm5A0QF0jV70KPHfejatWtSp6N2MIKc2X1WiYJq6OTlI+SlW3JychKeV5WD+I+qEZEbjlyHQg4yGRD1rBJn+ZzO6Mly0eWP2RFnWadM+XqqIdtvv//i66//iHi8RcNvo9EqHH30azj44ElJdS8ImU4WdgRNR850+ZUmWYj/reZtCZ2trKzUdvqmNiB/tiPMat6lmi+my9WToeZ56ToWeUmUli1bJtSfzmlRZaKTgx0pc3JeRHsWcgAac4Xs2oTqtJSXl2tJsa7u1VfRvlSyoC7H4oYcy5E7U76xmh8s12PLli0TiJUsEyf7ZCJhck6sap9kYqxCtk3ivalNqPVXXl6e1EfINsnk5OscHFN+qy4PT7VPcj/h1CZUApybm4uCgoKEetbZpLy8vATHUSXFMumyI8KqQy/IlqnPtpOFqEfRp1dVVWHXrl1Jda7Kwy7QossH1+Xmi2eVIRNIXX6iqP/t27drmEzqaE4EcBWA88QHi3MAD6w/L74/DMDi+s+HSd/ZYteuXSgpKUnwtNWInxr1y8/PR8uWLZM8MlUZ1c7Szkin44mpRsDOG6ur+wBbttyMzZt/g9rabsjJ2YQOHf6BnJyZ2LJFn9Au/z/x33VrHKlGVEc67DwvNdKhi1aYJh4IUqmbuKN2ljJZ0yWkm+Shiy7pvDPT5B3TZAOOPDZGtmpra5Gb+zy6dq3Ali2/RV1dd+TkbELnzndix47Z+PBD/o92stDJRO3sdJFZtaPVyVVtB3LitDjEfU2dpcmxMk2gMkWTVPnYfa9GDOXJOaocxDMK2apOldouZCfGRGJUW6KrX7UT1NW9aRKImuwuP5+82HViZIKS2oWoA7WN2MlElo0qJ/kaWQ7yqyp7VT+EXRIdsQzZ9qpkTU32N7UTuX7tXnWTpewmeOiiduI7sXixaqPEqy75XzchRkf41Aic7r16qHZJNzFEtqOyk2fqM4Q9tptEo+qwXM+6+rY7TLJQ+y6ZQApbp9qq5GF3vc3SkUzZluvOmepedWR1Tq1oo2vXrk2q93SQdQTQsqwc8HNFAUQty2oBoA7ADAB/tyzrNABvAPgzgI+J6PP6nz4O4ErLsmaBk12uAnC3mzILCgowaNAg43AhkKgQsViswZg5hdd1RM7NcIdMMvRkLlHh1M5LJXPiP+Xnv4jevV9WwujttcZQR9J0JM4UbdJ1aLrGKkc73EaehDdVVVWVNOQkOhvTsJOOSKvRQ/VVvrfaqN3WvdwBOJHovLwvEY1elhDtyMsb20CkTWRaPlSPWiVwJsPotu6dhpXsdF6OlJsifToikWndi/+sEoEWLVokOS920XCTHOyGwmXdl2f9JqeOpFf3IkphV/+ynstykF9Neq9GMoTtA5BA1FKpe7mTF7ruZmjVyZl047g41b38v0TdE5G2Q9fVtzr6YJKDzqFU720a4hbPKL861b0uuirXmy5qbWf3ZXnJTqU86iPKkwmg3Nc61b0uwi3XkdxXqv2ond1X5SXuYyJraqTXqe5lJ900dC3rqqhT0Q5M6R6ffvopvEDWEUAA1wG4Qfp8DoCbiOjGevJ3D4AnwesATpeu+y+AAwCsrP/8UP05R9TU1GDjxo1aQyF7lWp4NhqNJiirTMR0RtrUSaoRPHXoUo00maIackRDHQoTCkpE+PprTiA94IADGpS6rq5OOySm8750HZxqfNVOVGeQdcOQak6lfc5L45CSbFDEvdOJJunkY2cQVM9cF7kwDc0DSPqfQmY1NTXYtGkTLMvCgQceqI0iqXWqe6/Ws26IS5fHqg6xqHWu845lUiZkIrxroTe6Dk3VYTVCJPRa9Y51kRI1FUI1zHL9i/8LJEZURb2I/1tXx9suiWdRnRhTJELtcNW2pRvSsqt38Sp3Osm5xY1ERbR90SaEHNQIqNy56erYFIVQy9fpujrMqEZQZZ1TI3fiVdS9sHk1NTWorKy0jbyp0SY1/UKOTqkE0GRrTPqvixDJ8hDl5OfnN3TyBQUF2miSLD/5e11Z6rPIz6hClYF86HRQtUtCF2pqapJkpJOf+nsd2VZ1Xa53XQDGTg5ycEZuJ/F4HJZlNdjAli1bJkU05XpVnUndPVX5m57RBJ2eqXUjH6KdVldXo7y8HJFIBDU1NbZluEXWEUAiuhHAjYbv5gE42PAdAfh9/ZESRChYNdo6EiKEpiqiKQ/HFBV0M8SrG96VSYlbz1x+jUQiCZ2jHPFRPRTd8KHJGzcN8eoiIjIZketbNiJqIzENqasGVyV4ThFYXRRWR7h19e0mCqXzBtUooDinEuodO3YgJycHHTt2dIyEqF64Kfqki7qqJFs3RKgOC4o6EJ9N+u3kddtF/eT61nWUTvXtFPmQ611NQXCKNDlFnHTDUW5siW4oViXNct2Y9NtNtMNkS+Q61xFrtb5lMuUU3VZ1XBd1chpVcNJtnX472RKnCJPOljhFmnS23m4kR2dLVNutsyVCx3VOolxfas6dGs026bcc1TPpdzq221Tfsk7KkT21jnUjZqrdl4Mlqdhuk7OoOnSqbrvpK+3siDxyYxckmTlzpkt2Y4+sI4BNgWg0irZt2yZ55ECyEqvkw24IWBfRc2uk1WEYkxI7GWfZCIrPOTks9g4dOhiNhWo47BRW/Y1qhNQIiK6OZSJtMszy8J8cAbWLqupeddfLESeTgRCkWtYbUZe6aJJd3pGOXKv1KMoYNGiQtl7VTk+NfojnEjosR28AJOiOTp9NUTo1KqobqtURCp3uyq9yOxORK2E05U5FJVOqgdRF5XSRZ1N92kXvdNEN2U7IdexENHR6baozUz2aItG6aLRpmFwenlOjM+p/1kXdTJFP9b2OFKtRP1O0SAYRNdhPXSRa1StdnatEQEdITNFPU72qkTgZkUgELVq0SMgb10XH5Ei0+l5XbybSK//WFNmX36sgaszzM9WxXV0Lx1AX5ZTbiKk+dfZAfJahRhCFDS0sLEz6z7oIsy7ibPpevZfqPOv0VfRtcr2q/0vosl00WQ147BWTQCzLOhI8lDuCiD5oqueorq7G2rVrjR6P2vhyc3MTCIyAjiTqOlKTNyl7NvJ7kfxsiqjoIibykI5MYgA0hI83bNgAIDF5Wu1AdcREJYTybC/dci46b1714FUPR41KCcgNRI1ImYbY1fpV61Z3TudZiqEQpyiJDJ0BMpETNffmu+++Q25uLlavXp1Qp3Yzr3V5OCaiqDNYqeiwKYJtqlc7HZY7HJXgqARcrmPx7LIO20WfTNHrVHRYvWcqOqySbx3xSFeH1fPCoZF1WEck3eqwSgTVQ40wyfljppnSOr11a4dVR1Knw7KNSMcO280GraurS1qmxhThkztvkw6rxM/ODrvRYbnOxRC0X3bYToflOnbq58Q5UbfqaIKTDtfV1SXVb6Y67DTD3DRioAuKqE6lHDhIxQ4/88wz8AJNHQH8GsBwNM7cbRIUFhbiyCOPNApAVnB1+EVWTtVQyB2f7lVdXkG+n87TlxVChp1yC+WVlbq8vByWZWH48OEJRkNnQMQ5NyRDp9huOj/xP/fs2ePY8anLuMh1rLtevZ9MjGWC7DSUqJI3MWnAjcEwLUuhG8KVDfKsWbMQiUQwdepUR9ImDLJM+EW9yst3qJFpdUhF6KPdcItdR6fWZ6qGuFWrVgmRUdMwoW7JIVXX1ciqGpVSIyPi+WRdUD1w8T9ra2uxZ88e7Nq1y/XQt12qgTrcqNanIBDimWTY6arQpRYtWqB169YJdSO/OkX5Vd00RfjlaIkucud22FUsIaRzNEwjK6Yov5CXTATdphGoQ3+qYxGNRlFYWJhEzoRt0A3vqTPuTakDaiTKTZ2ahlblei0rKzOOkKhBBVk35X5PJdV2IyWmOs3JyWmI2onASjQaTagnobMmvdW1dTvH11SfcqTOlIqhq1O5fnbt2pVUd+pn3aiTLoov16ksZ4H169cn1XE6yNqt4IJEr1696OabbzayenVcXvbQ1LA6kNgo5aEE2cDLBEXueFWiqB46cmnXcNXQPBGhqqoKRISWLVsmdBxyZyznRomG1aJFiwRPU36VD/mcySPVNVjVMKh5UqpXLxqKbJx0pEbUkVqHTnWq5pTovHod0ZENndpxyIZfFyWR63XXrl3Iy8tDr169kurWpKc6wqPm6IhnlIch1DqVDZwu0mdybORD1mk1eqWSHtUAqkM/auchD3/JeqRGRuQ6Mumn6gTpnB25DFmm8nCQDDuSY4qeqg5NdXU19uzZo7UNalRV1/51hEeNQKnDkKYRANXB0emrqLuWLVtqnUodwdR11LrhSvHM8v+QybjbejXpqylyLd9PjTjpiKROV3WRf5NjIzvcOh01Rap15NLJ2RF6KurWTSRPF70z6arJQZcdIF3EX5cHqatXXaRfJt46O6DTXVM/pQt2CIKqDrnL9SrXqY6Uy32VsLGmaKiqq+Kal19+Gdu2bWveW8FZlrUCwDIi+llTPkf79u1xwgknJHWKaqSorq4uaXFbHXmTjz179jiSONW7NQ0dqEZGHlpUG0JhYWFStMRE2EyH3EhkQyUagSAZKhmWoeYvyMQiFouhvLxcq/xyPenq0NQwBKE2kQs3xloQfLmTatu2bZKRdlufdkNedh2gONyQX6GTlZWVjp2dqS7VQ0d+1Y4P0JMJWS9UByo/Px+FhYVaAmFXhyqZkJ0SUz2anDMd4dURiN27dyd1bk6OmVyfpsi+ieyach1l4iCTMlEfQj+d6k8la7rOTiYPalRPrkcARsdBrUfRjnfu3KnVR5NTpjoNJjJmR8RM6RdyXco2sqCgAB06dEjSSd1nO9KgDvtFozyjWdSlGnFSnQV1pEklYMJ22rVrHalQo1G6tq0jX3bDp3YOQmFhITp16qStO9VZUIe11YiemptnchBSdbrEAtBu2rVK2OQyRJmmlAo7J1YehlZHOWT7J9q6F2iyCKBlWXng3TuuJqJ/N8lD1KN3795022232UZUTJ00gCTmbxdNkSMqKnnUddi66JRuSMSUE6Em0MqGJz8/Xxudko2iqoSqZ6rrmO2IjmoQdQ1Z1KVMwuUheLmDMeWWmDxQXSRKZwzlyIkc6ZMhEzVZN9RIn+qVqkby/9t79yBPs7LO83nzUnm/Z1ZmVlZlZd26qhvoZkB3GJ0ZNkLAWJkJEIFZx3A1dNcdJwyNcNfBXQPRmTV0CQnXdbBZZlEHBBQURBBvjCDM2LiCTY/2pe5VWZWVl8r7/f7uH1mfU9/z5Hl/mS3ZXdL5nohfZFVefr/znvOc5/J9vs9zUtF/XV2d5XluR44cidIg+0WiUsFMkWL00WgqbVn0tWgNNY2Ziux1eA5UKo3pXx5N8sGO/3cq9ZZCSTy5W0fKEdfUok8J+XR76tx6pMk79HulL326rSh9iTPnz2IqvVYpBZxKrVfij6VoCyqX3hlPOZKp9fTIdAoFTa1jUZqtUpHBXmie6jXvoKcQ1KKU5fNJW+paoi8r8fK87vQ6tEj+PN0jlVbX4FoDmr2oCv68p9bUr1MKlfcOtw9i/Hp6JDQFWuiaetnk3HuQISV3Ral0b2+K1lMzTCqbTz31lC0uLn5DI4AvN7NaM3vyAc7BzMyamprs1a9+dSHyoocqteH7SeXsJ5qoFOH6dKMaJ4wWgl5XVxcOgyodHI4vfOELVlVVZW9605sKUwyVuH97pRh0qKHSQ6R8v/1A4KCAmnbwv59SUhwubyxZw5TToRGody5w3vZKJZIKKzKgKe6Ul72Pf/zjlue5fed3fmeSRqCIpyItqaCh6Hvegft6ZC+FCjQ2NiZRgVTqNYVOKdqH05biShXJnufveWTFy1FqDfebKkwpdY+WVpK9lOEjANDgq1I6uwiV8nyzlKNmlqYG6DkqCr4UjWJtVlZWdsmbP9usmSIpXvaUB+VlrxKyp2ePq8oqpVRTa6jvk3J0i/iOqVR1au3UbiwvL1e0FylZ9ejy+vr6LifCO2J6bvVZ9gIAGhoarL29fRfSvFdquihw9ciyz3YUIcupDJyieJUAFH92dT+KUtEp2VO9nUJCi4L9+vp6a2trK5TB/YJQb33rWyu5NPseD9IB/Ae2c2PHUw9wDma2UwV848aNQgWpnDQ2o1Jarog7gcIrQqm8UUkJqEdWPNJHIQCoTkpJrq6uWlVVlV29erUiipI6zCkBTzmEXjl6BalzQrlUWr/9oCfeGGvk743K5uZOtVhKQWqKhqiM9/Zk5f2iKD7y92mN1LrNzMyYmdn4+Hg0Px9h19TUhHnX1u7cppBSmOo4ptCqFArq05UeaWA+ZruRPKUnbG1t2dramm1t7VSlrqysJJET7wD539HUpKLJGBPdvxRSoo6NGpo8z8NnEAQ0NjYm1yP1vaL1Klq3FOKkc8Yh86gFMry5uVPc45GTov+nZMw7gD4IKUJAU4Exa1pVVRUC0Lq6ul0IftG/U6icOlEe8SzKXKkMKpLL83GWNzZ2inh8Ks7LU+p7fs38Z/niAr+GqbXk+XT9mpqaonVQO+ORqaI18/bBy17KOWSk5GFrays4ojQlVlmttEZ7rZsichqQFK1laj3RGTTa9g5l0b+L1ix1br299XpQZdM7jth4/Z4/e7qePmXM/6empgr37fmMB+0AXs3zfP4BzsHMdhaaSi6NxlU4U1C7h9eLEEGNUFKojCIRKSdGjYsaL4TPHxyN7LxBJaqtqqqy3t7eJA+rCEnwEZ3nCvnUeBF/LcUVUkfOO8R7kYuL0hUpPgZje3s7OmA8A/uecuZ8Grxo3fZCr1JUAkX+mF9TU5PleW7Nzc0VeUFFgURq3fT3i5w+z01j3XzKW4OKVHq2iMNSJGMppPn5Ilbeyd8vXaAIJfUIvSLNe1EuGJU4P6l09l5FFkWFFSmn2Qewnnvmg1ccdA0W9spuFKEsft0r0SuQeZ8m9MGrPquXr70oKqAxe6ErKmfIGPPzKdZUoMW6acDv16qIn+fXi6/e2UvJmJklgwCfgtb1amxs3BMF9fKp5z2VWvWp/hRIUsleertYJG9ePiudS03rpmgSqfRzik5StFYp/V9JxirZy1TWTPX0+vq6feQjH/k6PJ7740E7gA88/Wt2v0mnwrr+8D8fQa5kjFPKUgXYGxhNI+h8PVncp+GK+FIIZlVVlfX19SWdvEqG2KfesizbNccUhJ9arxSU7w20oqfq+Kji9SiCWZyaZM30xfyfD5pXCQEt4kOpLOn8GEUHfnNz08bGxmxra8ueeeaZJBqq61fENUk5dmp4QRzq6uqieXleoT6XPqfn5/ivKW6OGqiUMszzPDwTa5RC7vx6FSF1RV/3Qjp96pv5q14oclg88qayVsRTqoTUsQceadre3g4ORQpVSvGYUmldXcPUz1Jopn/pQKYqIXJ+7/0ze4esCKXbL4q5vb1ty8vLtrS0tOvs+XVKoW6qj72cpFC4FH8rhVzqWqWck5Tu8vK2H3TSy2slRG1ra8uWlpZsYWEhrF0RYubR9NT3KiFovL8fHgXMsixki1RHVUIXPd8whdRWWg+/NkVnbHFx0RYWFiquB8/p0ezUevh1YS1Yj/n5g8HNHogDmGVZlZk9amafeRCf78f6+rrdvn07RIeK2KCwFSUyS3vrpAvVwSlCG/aqyOTf3sj7NHBK+apCSKENy8vLVlVVZRcvXkzyrxoaGipyjFIOkBq4FHKqylH5eZUiwP2skUaDq6urZmaRY8g66YFjeB5MKmJOIX77rfj175dyeoqiv83NTXvqqadse3vbHnrooUieUqjyXuuFkfIoVhGlQGVJUT/WCpny8rDf6vKivy9CY1IIqQ8wioKKvdaIVH9qfffL61N5SjnLGmApj7Toxd+m0JgiBN4Hhh6xSq2T10+VZCiFZinSp4iVd4YqyZM+i68E9ZxHr59S/NJUcKYOZRHinspQ7IVOpc5ZUbZCZVNT+UVOdCqwVxTUo5+6ViB7KT2uf+d5yR5pL5KnVFCfWifAD/1apMc9GKKBflGwoRkvj+R5JM6j6fvV4ykKTxHNyQerPjgtynTpeqTWycvTysrKvv2bSuNBIYDnzKzZ/p4ggI2NjfbKV75y1/c1witKvfkiBf3qv6cbqagWB8g7LCinFFxdW1trTU1NUWq3kgFuaGgIivPChQtWW1trr33ta6NiD29cvJAzl5Rh2djYaTLqU21FTgqEZ1WkRemjlPE1i6MjXZuqqqpdHDxveIuUQQrOr7Q2KB8dGv0xdyW8FzkoPm17584dW1tbs+vXr0eObmptfOSpwwcEOCRaXazPWpSC5GeeDlBkQFIObko5YjSXlpYqpmqLCjZSSKhHhjXyZo9S5wqHBA6gl6GU4fU/K0r9pKgSe6XL1GFDNjRbUAk19y/VYyozKefDy00KwWxoaKiIkquMeGcj5ejruijioefdI3KqP2nKXfT8/pXiCnt0r9J50uAxRblpamqyzs7OPbMJ+80iFNFrilL5GuRtbGzY0tKSzc7O7lqDojVJpVN9Glo5bnqePJKra4Nz1tDQYG1tbZFceDnxuqUoc6Cf7xE6j2D7ddE1WFxc3LU2a2tru34f/YLMaAbMy4vXM35dPECjOrmjoyMpLxcvXtx1Xv8u40E5gP/g3tevPaDPj8b8/Lx94QtfiJwkNYQsPLcU+DSxWVz1pQKmKUx1FHEMl5eXo6/8O+U46kFdXFyM0hIIu6ZcNBWlkSOG6/Lly5FzyLM3NjZaY2Nj+B7RJD/XaJOD7A8mAq8HUaPeoohRnWddD/891ganM8UF8YrcG32vnIrQGV0f1kPXStdOZaauri446ciNoshednygoYiUyoFfG5UXXRvvWPPvSkiWV+Apnpp3mr2s+PWi15f2/Eohfv5caTrKO0O6NvuVHdYptTbLy8tJRFSNiU9fqrEvWptK54rv67lSmVGHANlhj1gfH2hokKoOsw9MU2u0l87BKfApcoZPU3q0Cl2BLKTOVuqlOgenXBH1FALqHSOvkzWAKDpXGqj69dFgLcU/UzRfdbI3/qlMg54r1ih1riplHjhbPhhTB8k7jeiGIkR4L7nR86UBmyLDPhhjfVL2KnWuUrKjOsjbKq+TfQDinUiGothFaLBfm5Qe9kAQukaBjhTlq0gnowfGxsa+Do/n/ihvAjGzV77ylfnnPve5KA2nStVH26oIlpaWIgHglXJciqBu78h5RyWVTvIHwjsoamy88pifn7e6ujobHBysaIh9ioQ5eiOcQkG9g6LrpC9P6lVFoZy51JqkUiLewPg18F9TBljXxKOg3qlVBYECTTklGBNdk5SS4PfX19fD90gJp5Ass7RhUWe2ksHVdWhqaio0LOroeLSGoan21Nmp5KgVOfreoHiEQhWmyohP7X89Tpp37is5sIpeocQV7WTefk2KHDSVGe+8+sBHnY8i5yzLsuA8KdKQSh+m5MSfmb1kRFFgzrHKCOgve+qzBd7BKHLIvIxwFr1DRpC8ly5RHVsUCKrM+KDRI6AeAfbcRJ9NSTlieznyqeBP38NTYzw/0WdSvIwUZZiKgj7WbC8KQwow8FkCT1vYyzktOjO6JkXOlz83qTS8p2bomagUyLAeRU5ppXOjMvKWt7zFnn766a+7D2DpAJrZ0NBQ/gu/8AuFCJdGm6kD7An8qTSoP7ze2On/UwKr8HwR/8+ns4qcga985StWVVVlb3zjG3cpsRSixd/xHkWpUI0wvVKrxKcpSp+n1kLX00eWRZyjFKKlab0iZZ/6mkqHqpL3aZsitMZzIFOI1uc//3nb2NiwRx99tHAtVD5UyetneGIxDorunzoFKeXmuaApVK8oylbuFeui6J4ixF7Zp9bFc2aK1qMSOqOBhT87mtZT/qZfFy83fr2K+I2q6D0h3ZPLPYfIp4BTLwII/Z46ixrA+dSergnr4rloPmXpU+ApKoVPl+vfphwkH1ykgq4iDprXMalXJeqATwWrk8SaFK2LOpHKaUzJjX4/lf4solQU8c00w6K60a9J0dro932gtV9Z8WcIOo5HylVWKq1PKk1exFXkpY6t2uWitK9Hy4vOjTqOuiZFyKbKiqeZpLIHPvhI0XH4/rve9S67evVq6QAexHjFK16R//7v/34S0UDg9SDslT7YT2rFR6lEZl7Z6MH3BykVfaRQL5+Ke+c732lVVVX2+OOP7zLWaqjNdqfh9orGitIozzdiN7Ndzq2PxFJ8rL2Qrr0iMZ9WSkWmOs9Umj+FXFSKTvVvUdhbW1s2PT1t29vb1tzcvEuh7IVuHTlypDAy96kSb6w9ed47Kp4MnkqteZlQ5CaFjHsHXx1AdWSLUo7snTcu3qGvtCYplG+vyLyI+rFf1FOR8UpIRQrx1LORIsGrcS1CslJ0Bv1dRX980OfTZnul6vfSl/586LlIOfNFXGktfmPOPnBLycJeKGcK9fXOasrx8IBACs0rorlo5sgHN0X6MuV0qCz7gC6FZoKE689Tzlkl6o8WtKWKj/aitng9mcqiIV9FDnvKbigoovovlVKuhOJpMMNaeEAEmdDg39cTIAuVsmheHj73uc/Z7OzsN/RNIH9vxurqql25ciVp/HAEEBKz3V3eizhtRakM/Z4qhCJoWgsfeN+iCtZUJKHpnfr6epufn7eqqir7q7/6q10RhpJvNe3s01sIe11d3S7+mjp0qcjbI3kp5ebRzhREn2VZcAzW1taspqbGFhYWdkVXimoVRZtFEaciNp6MrVF4lu20KMDYNDc370L4UuiERy30deXKFdvc3LSBgYFdUSby4BWdmQUHEuJ3aj38s6b+78nXKVK6DnWS83ynbQqBS1NTU5J8revj/+3J1qmiDpAIHV5WQXRWV1dtcXFx13lJoVq67165+0yAJ+frWuhecaYaGuKm5x7h86lAffk18BxXb/z4yn5tb28HhHBxcTF6Jq9L/Pf093zhhq65yqKXDdYCXdvU1BSheimEzxcMeVRHz4RHYVIAB/Pb3Ny0paUlW1paip5Fv+r3/bOrHKg+9mi3rodHNauqqoKjpfKC4+S5en6d/M/82dBgTddf1ybP8+BczM7OmllxixVFPf36pOTCf02tC2uCfero6Ah21hd0+GdLyUJKRhQl9Qi7fgbrQBN+3TM/f59dKpKR1L9Ta8T744Cm5IX9++pXv7pLrv8uo3QAbceZ6ezs3LVBZverrTxhNmXQU86eeu0p9GuvyHZ7+37jSk8eTiGBRVwEjVwaGxutqqrKLly4EBwfn5ri+VmDF+v5Pdrjn99HtPvh6/goNhXNVnp+s91ITypFWRTN6v9TDnDR88/Ozlqe57a0tLSLn/NCP79P1aY4Oft5/tS/9/v8uv8aeGgUv9fz+397XhJ//0I8f6Uz4J/f87MO4vlTcuBpHUUcpBfq+TXwPajn92nnoizAC/38iuDsVZjlkawUPw+983d9/ubm5q/7+Xn2FKpZRNHYj/73oMd+nt/Tm/az/6yBR3T98xOc+dRy0fOnQI4i2V9YWPi6np991+efmJg4AM+ndADDUMTAp3j4qgoglfoqeu0H2eNzNcUEslTE6/NpvyIj4HmN6lApZ485pVAMT+wvem7v4Pl1WF1djbhYRJNmZrW196/YK+JOpJAs78ykUM0Usmd2v9prfX09QvXY8xQPK8Uh8TwRn75TPg4OfnV1ddgTNXZmO9EmCNrJkyd3Pb9He/XZfPoyhWRub2+H+aXQGn32FFpVhOCleEMevWKva2pqQqSrZ0Cd/RRCpc9T9NUjV/p+KNqVlZXomYuQBlX6ReuRek7lZPHeVVVVwSB79FYRtEooVCU0zqNRHm1BFmkkq7Lun70IaSn6v0fgPE+sunrnxqXm5uZIz6aQIT93jzzvhSh5FFLRHb/XqX1PrYdH6Pz7VBqcy/b29l1Iaeo50AOaTix6NtXX/itzW1hYsPn5+V3PW+mrooSVni+19jp/0us+g+L3zSPpXi/5c5p6Dv/a3Ny0ubm5QKdJ7aNHR/d6Ru+QppBAzmpTU5O1trYmkb7UuqX2T20w//7FX/zFivK231E6gLaTIpqcnAzGWFOgqmzZIFV6GDnP+dFIsCiX76Ni5QX4lKc6RWrcKvEBU+05Ghsb7fWvf70dObLTEJq0NoKpxlMFUw9NJa5TEQ+Sr1VVVba6uhreR6NJNaI+lVXE/4PTUonTg5OBA0VaTzkcRZweNWbMTZ095W7452bd1td3LmhX3qgnFHvkN8sy29jYuQnjypUru7grlThdOBrKf9KXrh1roQop5fhX4jrqM5tZ2MtKnE9ffZdy/JV+odWqnrPDc6OAQTmLeH2ptL7Z7kif8+hRrhR3izVKnW3Pa0xx+Yr4a5W4vlRtNzY2BmQ/FfipjNfW1kapPJ47FeTt52yzz6nWVXpO9nO2eW49mwR0lc62ZjZUxvc625rZ0aBG97robPO1qLVQJVRb9a1H9DVwLeJrploJ7cVdVQfDB7aevlSJk+e7OVQ62ylOnj63D1pTvETlKyPvqedOIXnqYKlO8zy8Ih57UTePIhnfy26rTq6UvStqq+XRzIMYZRGI7RSBfOYzn9llCDza4Y2APxi+5YlXih4BK0p1eEGBjF2kCItaVyjqpwZfDwfPy8HAUfH8PRX8VAWzT2/xvHrYvNHzkRPG2ZO1ixw8NXb6rN6B16iryLnZi5ycgvArOTW8tw5FZjyKp05dyth7Ja9OkTrG+qwqyz595Ys29FlS//bpWv5e19EPz4VJoZb6vKoM/XOmipXUeWOknBkNrFKFKinEXhV6kSFXJ8YjAL5gK/XMHsVX2fU8vNSzekOuRPsihDr1VWXXcy39c3Ju/b56WoJ/Lv/v/VR1+j3VQKzSsxah8OqAe7SW92do8Ou5kEUIvHdEKj2nOqM+46ToVerMpvjm+j1dF91Tz3nzz+nlVx2VomrVomdNpVNTe1qUXaq0p15uU+e0yAnzZ1XtrGZPVCdrMFGUXUmlzov21GcP9XlSmUP/O5ubm/b5z3++LAI5qLGwsGBPPPHErsonlHRLS0vScdJUiEdI1DnCKdTX4uLiLqdxbW0tamy8uLgYCOykU1IooDpLOA1NTU3W1NRkjY2N1tTUZM3NzeF78/PzVl9fb+fOnYuiZpCT9vb2gBRwYIo4cKmoKfWs+n0fSWGIVbmb3U+Bc7A8OqBIpz4r/25paQn/5mceIU1FyihHVUx6GNUBXlxcDAEAe6rPrFEkjrTnfKjxUVSAZ2bezFmfR1/Nzc3h+77Cs7m5OSgxTS97VNujXuwR++b3V5/Z9zdcXFyMjJMaW5VlNawe/fDPq3Kse67BAX+vil3TUqy3Gg2PaqbOrZ5ZL8s8q0e8UntLsMPcfMNfv7f6zD7gUwPlsxacITOLDI86/ZXOrT+7/N7i4mI492qwNZXmg1k9uzwrcurl2Muy31te6lAhTxrMKpLp+Xm6vyrD/D+F8CnvSx1kPludYo/U6555GfbynLJB6kCyrupEqfPkkcv9yLLucYqbnUIwlZKRykoU2R//rC0tLeFvPJKH7keW1THmWT3yvl8bBDeP9VKn2aPznoKlgasis/751AYh721tbbt4yLq3KaTW+xfPPvvsgfg+JQJocSPoFNFVD5M3AIuLi+Ew+UPloWIETHP5KUXpIeHUQdKvqihVcXCQ1KEwM3vzm99sZma//du/HTk3zFUVpHdq/EHyyJhHwXSk0jyVDF+R8fPGIIUKgRZg6H2KQxWjGoKUovCGQJWtRprKVypSFN45Tzk0POOf/dmf2ZEjR+y7vuu7IgQ3VaDiHdWUAfDPpspf0WyPgBWlrzQtnUpZeQeNZ1Xj7x02nnO/wQfP6ZF4fUY16Bp4pJDM7e3tXeiPPuORI0d2IfCp4CMlq4rGq7wyFOFKBZQpR1wDkFSj5FQKls/yHNsieoGeTf3qm8175wwjXpRtKHK+vdPi/61ZB9WtOGfKP0zJqzrNvu1J6jk5sxo8+n2EU2x2vztByo6knG6/f6lG8SmHrNIzMj8t/GKvfFBcFFQ0NDRESJeniaTOpNc9qeyYf06fUUGPISc6PBJbSfdUktdU+lhBHj2T6nDqmUzZEQ38/TOmziT+wPM5k42Njfaf/tN/ssnJyRIBPIgxOztrn/vc56KbELiOiQXv6uraJRyeK5QyvGp0faTpnUV9j6WlpUI0rMiJ2su54PuLi4tWVVVlt2/fjtLLIJ0IoELoGunvFWEWHQQOAQdgeXk5EJOLEE4fXSp6p1FVEfrlI63m5mZrb2+POFBm99FcRcD0Ob1jnDJOPJ/C+BsbGzY3N2dTU1Phc7a3t8Pn+8IeXg0NDTY2Nma1tbU2MTGxS4n5nmW8WK+Ghgbr7OxMcr1wXNXRS3HbPILpDa9yGdnPFMfLV29X4nf5Z6uksBsaGoLMojhTqaWi9L53Cvd6xo2NnfuuFxYWdhVwmdkuA5wyUGqo9NkUidfnrK2ttZaWFmtvb4+cDC+3mgor4jSluGz+GQlwZmdnd/GZkCNFGTU96DMJ/qXPruvC3zc1Ne1Ko2VZltxPT8mp9KxkVfRZ4e8uLCzsouKwlymUq6jiOvWcrIPqn6amprCXqXRhqtLY25ai50RHaXC0sbFhs7OzNjk5uQvZ0udU2pE/n37v9Dk975KvZFdSz+lpGprWfr5yy35iS1KZhiI9hF1RnetfXs+qg9zS0hL8Al+k5DmHKT3k93I/PMvp6WkbGxuz5eXlvR2bfYzSATSz1tZW+5Zv+ZZdKSIUjQqcRm6VoGYf3XgEkIOoSAdOQHNz8y6nLoWOKQLoDaVyN5QEnOd5KIro7OwMinR2djYIZerZUuimF05NeykqlnJa29vbk8gfjivOq3d41Giogkml5VV5zs/PR07cXmlMUvLK8UuhYaytIgLsXUdHRzR/fa4U4qfKqLa21n7v937Pqqur7W1ve1vYO2RHjQP7MDk5mUSofWqLPVZl5AtRzCxyxDUaZb5tbW37SvN4B66urq4ipSKVuuPc3b17NwoyitKUPqBSjitDU3ZKyFbl397eXpiu86R05Qql0ldq3DVIUMdzenq6MG3lucWKCmlK0jtqHolWlKS1tdX6+voq7l0R6qVpZuVMe1TPo5Y8YyoNqYGIonqpghnPk/ZIF2eut7c3kk8CRn02jwSp0+LtAcFhUQp9dnbWRkZGdiG0avD3aw80yC/KljQ3N9vRo0d37ZtmhNQeeE60BhGe2pNCtxYXF21mZiZJhdBMkC+KYO94Nl+klqJ88HxdXV3JNLkPfCle1L3z1BZ1HlXnq65cWFiwsbGxCHXWv1MEu8geKHixH4Cms7Mzen5vDzh3WZbZG9/4xgPxfcoUsJmdPXs2/9Vf/dVdkbemabQcPlUpV4Se+APinUl9H5+6MIv7Pil6ooocwUohKN7w1tbW2o/8yI9YlmX2gQ98ICiCVLWrLxKoFH16ZzCVetpPZW9RAQjOn484lTeihhdFwFDeV6owwBc+pIohPKlcHV6/bwrj+6pOdTY8cqKvL3/5y1ZTU2Ovf/3rdxHIfdsAz4/R50tV+RWRyD1xvKjoIbV/RaTxFFncF3XoWdMUt0eifRsWTwT3RPgUKV6dXU8W1+fj/Ok+arGSzp/vkf70BHHep4j8r3voCzt0P3R//DP5YhVNa6f2UOVUAzUN2HzlvC+EUCfTP59/Tn1Gz1/zz5t6Zt03/5zqyKRGqq2M7/Lgn8vLpspA6jl1+OdUapHfV18YoM+t65PaTwafr0iX6kL/PL74wZ9j1aEaqO0ls774ystqqkDF760+K5+jz+ifzxdzaLDqi7H873mdWqlYJbVvqWIVfaWKVDyH1OsdbzsUsUSH/tZv/ZaNjY2VKeCDGEeOHLHe3t4oOsLwpKrNUtFfKu0JWVpz/1rJA7+B6EgFEqPpEYlKfBwf0Wo1rEa0GNiqqqpCDqBHAitxcFLEd55JlWXKuUtxxf6uZHeidCUIe7J70TMV8RnZ81S1dioVvxdvyqNGGnTo/mdZZnfv3rU8z+3ChQthbYsI/Kk0vKZw/V4VIQ8+elXHu4hDVIQWEZmzTr7oBEXo08igYkXPVISmgPShXJHxFDdKAyilD6T4USkqAUakCG0oSmmlOIoeVeeZ+Hs1PDyTp0koP9Fz2hSBTp0rX9nodeB+iipWVlZsfn5+17nSFLsPDpXjpefKI86afmPeLS0t0XlKIUOpwFADiqK98vy1FJdUz5WmzhUVUr2eokAop0tlTZF1TxXQYMrzSL0OLOLk6f7Mzc0VcvJ8IK8AhaewKC1D5a++vj7K5hRxuVmTFKfS8/AqFTHp2ZqZmYkyAkU8Q68DfcCue5XSD01NTdbR0RHpfd/FgHUys106UANXf668jlhaWgqp7oMYpQNoFlJqWiJuZskoSz30VKTlES3fZgCSeYr/ocLvS859dJYiVnPotQhic3Mziny3t7ft+77v+2x7e9vm5uYKlbp3XLXKj4OPAeRZPb/EP5OiQJqSUoic7xN9sjdmFhwgRfcqcYQ86pX6ijIw21FqFCPU19fv2jPPT/TVnKrI1FnwBTl5fr834OrqalIWtre3rb293ba3t+1v//Zvdz1XKvJUI8Sa8ZkNDQ0RoVoJx77SWhWgj559+wN+f3NzMyjaFELJ/qWQSo8UeJRWfz/LsmBY2B8d6pCpM808PeKTQnZYCwwNTZN5f0XTkLsU0uP/77/H39TU1Fhra6u1tLTsehbfvkLPsgZ2RS/9++3t7ZDm0n3R5/HPpmcgheCl9KSZBUOoz2FmEbfPz0/PNMOfC39GOMvT09N7PovKvh/+M/28qqurraOjwzo7O5M/L5p/0Zz82qoOW1hYsLm5uV2/51Hc/ciJR3f13wQFXqb883g5KZJ3RbbUYSNDpgGnPldqH1Ion7evKdS2vb3duru7dyG+KXtpFvf03Q9qiX5aXFwMPNmUjVc5Ul/Bo7A+I+KRS4Id1V9ZltmXvvSlwnPxfEbpAJqFQ6dRIxuHk1NbWxs5WTgWjY2NwVtvbGyMCj5wApaWlqJIzSxuMMz7qvArlI1jRDTT3Ny8C8Uxuw//47D4tA0RyLd/+7dH6VDvAGLIlT/IXIk8FGVTjhyOotnOQVPira++I2JStEadSk/M9RE9e6QKpajiTh1KiMIoJm1rsbKysot7pHvDHD3xXaND5CXLdu4HVr7YXtwOxubmpg0NDe0iuys6iwO5vr6eRP403avpwdTeaLWZR5uzLIu+r5HvXjycSrxFAgzmvb29vQt1Uf6YIhIavTOUW+QLhzxiCSE/hWCq856iEyD7W1tbUTCRQi0p6EInKIfPc2fVQTeL6R++uKIIXfZoku4Na+N5l35vipAVX8Tmi7sUiVVHQZ0SJd8rAqYoZYqLyPnyKKxHwHgWzjdrrMjdXtxmz/Uq2hv0dKp1URE3NsXX9ugrzhfnJoUQFXG1lXeo6KueG88X9XujqKt/Fn2Otra2XfxsrQJXniiypoGd3xs9+7o38/PzUZZG+bOpvfG85VTlfkrOFCEv2hsFUlJFZin0OMXn9Wg/Z0dpNz4drODJQV0FV3IAbacR9Kc+9Smrrq6OIrSUwdJULxvr28CoQFdyJryjp6mOVFGEHsIicraiSYoCqiPx9NNP29ramvX29iZTUkrIRrkrj8FHOT5to8+SSkWlUgB7FXbslVrT1LQaJiXMa/pdHVX/HB76946oKvCU0+CjNZ6Dg+25I6oIdc5TU1O2srJzewq/p5wSHBEd6tT5Cs0ixFVTS34fUmizRv04l5qyLOJR6jOk0mUoPYIXRcPV0KrBRbnr+nvUXIMF5MnzXT1i7JFjXoq+avGFN0KKvPg0WepZUjxJ3QMfIPAcfD5r6VFhnbc60B5t9YhM0T74NCbOnP5fAxucaM991D1XWU6h937u+gx6lrWAKc/zyGArjzElT/oc+lInvAip95W7fv76DP45PC/MBzWKhHk58tmUlCwpDUjPgupW1k1lSPWsPweqT70sKf2CfdBn8KlVz4FO8aH9edB99TopdZa9fvW6SZ8FOVT0VZE85EizO57SpLo15Rj7IBlnHxuhdJ+iiuH3ve99JQfwoMbi4qJ97WtfC06WIk5UUKniUu6S8ua0SmphYSF64SjyO8qj4wCpM65cQM8VaWpqspaWluiFk6iNJ9VJ4QCZmb3zne80s50+gKmqL3Vo/XMsLCzsqkpEIXD4dGjKUJEy1prUF8/AvzUy429UITO8Q+WjSda86DlSkaWPwjAgHFxF83iW5uZma21tjb7qc/C7Hr1QdFV5O6urq/aJT3zCGhsb7Vu+5VvCMywuLtr8/Hz0f3XeFZHVSF8NoRoORV6Ys38G31BbFRqKXVPxyivV/dBzwDPw1TdGV2Op6RV11DXYSD1H6nwoIqMGRlOqakw8Mq7n28uVnnF/vnkOAkyeoaqqaheKXHTG/XPw3D7wQGZx7HgODZaodPTnAx4f30tVdmpK0qMtPoCt9ByNjTuNcj1SyXMw1MlVY67oisqTfzZ/NtThYmh6TvdD17voOTQo5+/UcUSvq4PieaG6D3om2JcUQqnPoelfdRKVI5nSuV6ufAUqyBfPgWOkgd9e+tafFw3QNZj1z6GBhvJ19ZWyH62trbtQSc0sKTqtjqKCBypHqeeYm5sLZwn7qalgj6xyRj0y7O2eyhTP0djYGDn0VVVV9slPfvJAfJ8SAbSdRtB/+qd/amYWRaKKInkDPD8/b3Nzc7uUvzpFOBMIBQKhEZASmFWYW1tbdwm3HlCNAD3KpM6popYI9C/8wi/Y5uamvfWtb7X5+fngDOGcKuqn6IYqGG98vUAzf/2eOqbqCKUI5xptagpKD6QqSjW8qiB9Stqn1ZiPGqRKSl6Vo6Ib6gBpBKrOfsrgFgUGGxsboXdXS0tLcEYVjfGpZ4yUVyy+bUkq/ZxCvn26ySt4nbsi35p2VlRDkaBUIZDO3/+bZ0TmiKZ9elZRGJV/j9gj8xoI8JwYNuaPjvQp85Tz6Z/DtzNKOTqKxvgUmZLBdf667r7gQon7mnVg/VV3KBqPrKiB9YEYa8/8lS+mDomiLBpopeav7Yk485oOM7MogPH0kPr6+opz9y1ftIiH91VEWJEvX9SXevk2L96pYRQVTHi50a9FaUm4vamUpKeMVJJ9T1fQ+RMEo/t1/op2Id/MGb2va6+6B/uniCrz12xCau1Tese3odFARYsRU4GKD+KLwBTkn3Ovukz5kL5AJSU3qvv1/HoaBTZLA0bW/uLFi7a4uPh1I4ClA2hmQ0ND+bvf/e5dG65et3KaVEkrj8lHcThXfFVj47lzm5ubUfSjqTt1UjRa8JGcKgwQTAwlh21zc9Pe9ra3WZ7n9hu/8RuRktbIH0c35eCqssbY+rSFRtMH7WSRruDzcbpTikLXXau0MZQ6f3WyMJQoC01de0XnDU4REmAWV+rxDB6ZYa5f/OIXbW1tzYaGhoLC1hQxykZTeMiQ54ykHBWPiqnsKAJQyVHxxkbRYUWLPQdG0y5qLFOVeClHUY27lx3PGfWpbO+oe76o5yBV4olpSp799Y66Rv8pDpKXHY9ecH5ra2ujQoBUZ4JKPDc1NMqp1PSdzh8Oq3JDFaX09JSUs1LEc9XCniKOq5+7r8LFWVGHRYd3WFIBk1//Ihkq4oB51L6I/+V5eqmqVHW40KMqQ+giXeeU/knx8pSWwmdwBhQhTp3jlMPu9VAlGVKnVRHJomApFXCwj54apHqoKOBQW5Dir/K3vJ+mfTVlq3Lhgw113H1vXl8EiNObyjSojikCDJaWluxP/uRPbG5urnQAD2I8+uij+Wc/+9mAQiHImnfXQ+CdO4WLPcFbORaKAKIclWTb1tYWBKitrS04eD7tQ0pXHQscGOWVIUjeqXv88cdtc3PTXve614XvayrUp3rM7itTJQj79CfOHM/hnVIUsR4E5WP5Q6zpHXWk5+bmooORIm0XOUNaDKDOp653KvpWZ8LMIlnBkVPl79Finb9H/DT1rGgZ/L+jR48GZejTH8w5hbaqEdbWCiorfLYqTZ0rSLeutypP5f9ooYyS/dVYeYTYr7kGADjgyt+rhHBXCr54rhTKhOPJS/lI6iToWutX9kP5oMpXIjhSjp5PxSqq7WVF90Y5xTiCKWQMVKxIVrxe0WfGcFdXV0dGiqBJHQQ/Zy/jOAseWTK7n1FQWVHnzGdEvJxjiJWsj5yQykc+PYd7r/PJmisVwSNKKYqO14epNVcZ1yCR9daCO6UfMC8NzFNZKE1NaoDI+fSyovqwqakp0oW6B2qr1DFWfaiywtwr2c6i7BkOGTpRq2g1oFInUue8l+1kDbw+JHOQonv4rJ+2PfIBiS+24/OUS65AQup8qg1Snnx1dbW98Y1vtKeeeqp0AA9inD17Nn/ve98b8YLgN/FSHornDKgyVEEvQg1STopyHnBUPFqQipJ8tJ1Ki3nuyY/+6I/a9va2/eRP/mTE3fDFIOoAPx+kw0dKiv55hAChVqdQ08G+0ECjVJ/e0whcFTdOg6aTzO7zLHE0NDWgqJkn9qYqEeEseXRACwZUuenapkjJGxsbdv36ddve3rb+/v6oUlpJ4crp06IVXV8/Z61qw0lhpIojtICoEilcZSRFatf91YBCKRE6z1RxhBpLRWQU1VBkRh10Pbu+yEALEPQ9VD9qS4dKpHz/4vm0clTXQgsX1IhqSjLV9kdlK0XE17S+FmD4lhq6B3qOde6K4qWKg1Lz9wU2nAHdB0UxVW6U98nam8V9RVWWdb39/NUhx4CmipuYv85d19oXA+lXzeRoEYGi2io7fs31jPrzqki8LwryxRzq9PpCCEW79PzyO/7csvYpVD5VAFGpuEyLUXxBkwYZqTlroJfS8X79tVWO1zW+SFEzI77Az89fdY4WifiCGQ021D557r+3UV5XKvroi0w+85nP2MTExOF0ALMs+4KZvcbMwPxH8jw/f+9n32Zm7zWzQTP7SzP7/jzPb1Z6v0ceeST/2Mc+FkWQZjGfSDdVU4oaCfD9FAFcN9fz0NTR82le/Z4KqRoVVWIIEyiDOnjM79lnn7Xl5Z12MimHj+f2/BUOgi+nrzRnjXhS6UTvnCoykiIUK5LDs/G8HCKzmNStfCEP3ROte44lUZfnOu0lF3wtkgte+5GLLMusoaHBenp6dnFUPC90P3IByurlwqNQPlWivDJfBV5JLjxx/oWQCw22DkIu4OJWkgtPDXm+cqEyrZSE/cqFrnGKUnEQcqE6w6+zBrVfr1yk+FbK1Xs+cqEZA6879Ox5ZMxsN0csxc/zKDuo2N9VLlJrzPxVLhRZ+rvKhc6/iCZxz35GrXS0AlVTwH7OvlClklz4NVYOYRGH2cuFpoOVf7pfueD/CiaoXJhZQB5fSLlIpa9Tts9zxZ944glbWFg41A7gb+Z5/v+673eb2VUz+x/N7NNm9u/M7J/kef6aSu934cKF/IMf/GBE7tT0R1F6MkVqVii76CD4SkZSo/vhpviq3koVysorQLFrNOLJs74KVnl9XtkoWqZRFHP0PESN/hT1ULTAR1Ea7aWQMq2u9By4VOSnfLJKCJkiBYpImt2vOvbtBnTu/qUIiEbqDI2wU6hM0UsjRN9mg7mCBCmipIhR6qUojI+o752zXYhGClXS/+scU3NlvtpsVteq0ktpFopcON0QITH+5RFFRVgICn0bFj9nfWmlbOrF3xYN/ayif+819tLtvJd+1ZeZ7donv2f+81JrwNlM7ZM6NKpvdI66d7pPqk8UGdPK9Epy5uelZ0TRMKUKKLqqZ5ihn+/Ps55r/b8iqyqjDJ2nRye9DvKosGabdK0VDfbtljz6XoTEq470SKquoyLuRUikIqqsuTqOyslL8SJ95sbr9qI2Mqo/dB3V/ihyl7KXzFkzBsy1qqoqymyoI4sz7rm/njurQRsy8AM/8AP23HPPlW1g3HiLmT2d5/nHzcyyLPsZM5vMsuxCnufPFf3R9vZOR3mv/DmYvqxbD6hPe6ghJZpSZUJ0wcHTA3pvzgGl0CpE/b4/nJ4jhXJg/lrduba2Zrdu3bLl5WVrbW3dRRwvitw03dLU1BSUH8R05TZqZK8HUoVZiexa9YVziCMKP43oTUnUKJFUpamHzZub73e8r6ur24VYapSJklMnQBWa5xOx74qkEb2p4tA0l3KV1DlVcv3a2po1Nzdbd3d3IYeooaEhpGaQVV7qTGvAQhBThPixrmo4NGjx66romY/iPW8IA4OsK2qtwYoPqFLFSL6VxPr6elhTeHHKtfU8RK2812BLqQmcIfSEJ/37ohetTleUT/m1a2vxvd+aStaAyiOoHmlItYHR4EqdBE1HeRTSIyNKTfAFOhq4ogsUwfF8YOV2pgpblF6zubkZpfyU86YIjufpFaE3KYTMV3z6efKVINZzrZWfB6Ln+WL6Uv6sLx5ibZEB0tq+4Ck11/b29l1FNx4ZU0dMg2qPMCkXb2pqKuK1aZqedUXXY4v4fL+uerba29sjHp7SOZir2qj19fUwD838+OzKzMxMhDoqgKF2VoN/j0Qr2s/Xjo6OiF/q7QH7l+oWUnS2FhYWQm/X5eXlyJlXWhJrowU9XgaWl5eft3OUGt/ICODLzCwzs4tm9lN5nn8hy7JfNrMjeZ7/sPzu35rZu/I8/133Hj9kZj9kZnbs2LFX//mf/3lwljzqpwZJN9ZX96oBRTjM7jclLSLGFymjIgIo6KSWnleCkFW5r6ys2Be/+EXb2tqyRx55JEng1+rLVOpUK2G1RB6HVKNgz+9Qw+nTkIpOKtpXhEj6ebKuenBU6YCcplIIviIrFQVqWkadD20Z4pE9P099ebRUkcja2lr7/Oc/b9XV1faGN7xhl0LXyN9zZXyFoSpxP0eUmjr4e3EJNaXhUV3Po1KFrtxBH0FjUBV1lLMa8TVTnEHmmuILYmQ0ivZzLEJx9fsgE+pkK2LmOVLKSdOATdcap03TnEVBpc4vxUFLcQB1nxUV17l5DprfX03DqrHWKlK/z54vqs/gOX7K71OHi/1UWdSMiXLoitbQc/k0KCpCodQw+/RlUWVuJQ5cCn1SFDRVza1Vtl4fqrObCii9ztHiN0WaUtXafq9T1c4aqKU4bqmMkg8iOMvsM3PyTo+iYxqYsedF1AB0oa/EVlvjuXieJ64Br3LbPYVIufm+8tenfXWvdf18UKY0My2OYd+vXr1qq6urhxYBfIeZPWNm62b235vZp7Mse6WZNZvZXfe7c2bW4r5neZ6/38zeb2Z2+vTp/Nlnn40aSPJCcSrBFiHXDZubm7PZ2Vmbm5sL1UJEKcoLRAEiEJpS1bRve3u7tbW1RS+NrFE0ra2tQVjN7kPEvnpMexd+7Wtfs83NTTt//nwU/WlVKsoP4fVtCHBa/fza29sjR5ZDqw6XmUWHVQ+BzlPXUxFA1lGRVq3gVHSKSNSvZVtbW3Rw1clWI8JnqJLTOeortZbqeHmlotVgVIHp/BYXF62hocGqqqqiYAAEhaGIhOe86DxnZ2ejCjx1aNXJVhRVjYVWqyGfzLm1tTXIr6KomspSJ0aRvdQcNbhShxuDZHaft6XKWRHI9vb26BxpdZ2vHhW9EDmoRWupe+6r0dfW1iIHUR0ajJvfc11P7aPGOcfoaeqUz9KWEak5qmz61h2KnPMZikCm5JJ5dnR0RAGXOm/qZKtDwzyL5kiVpVbgakGLFj7x2VrlzPza29vD97q7uyMHiDmi17e3t4PzpcE+e57S65OTkyGg1iphZEgdREVwitaypaXF+vr6IgdCC7Q02Mf+KBhRtN9jY2O2uLgYBTOq17WYA5lL7Tl6HeQR/aXIGLrIZ0n20uuzs7M2MjJiS0tLu8ATAiut/FXudkqvNzU1WVdXV9DrBP6KOCt6x4v5MCfVRew5doC/x/km40BwojbS60zd86NHj0Ygj1IXNJuI7UEu3/GOdzwff6lwfEMigH5kWfZHZvYHZnbWzGrzPP/X8rO/MbOf8Qigjle+8pX5n/zJn5iZRVGOeuMzMzNBKGZnZ21mZiYyVIq6KM8HQ+iFAuOkLy0FV6icQ6BpSCW4qnJifqoINOLZ3Ny00dFRy/Pcent7QyRGhJUyTDo3DL0qU5wmlL5Gq15J+blpZKZIkKICOMgYeF1DVQKetK+IJEPRAI2wVCExz1SrGRQ9+6tVWpoKYx/VSVJSs3eM4RlqmvmTn/ykra2t2Wte85qoBY46RxjLVMpOq041raQOOi17NF2jqUX+3ixOgbIeldqvpNpS8HxmFjnt7K+mZiq1ovBFAuyHOpl6RnwLIQ3OMDw4RcrjUTSPtfFpWb5qOtSnOkGZtRhAAx+fNtTiId8ag5cnp6f2V/dVZQ+jiLOvmQ9FUFLpYk3HMz90SypdjKxrVsM7u7q/6vRqipD1w0FX3bGfdi4Ybc12oCO87PmzATigusU7P163eNlTRy3V+gRqgKfdKHdM9bDqaU+70YxRSreknB7VgRow8OI9NEj0AUPKyfV2rbm5OUIc0S3b29tR+xh/JrwjrsG2tx3YTOXXK2iBQ6ZOmdJWOL9qOzRToNk15uVtr+pn9Q38/nrnmzmpb6BOY0NDg333d3+3/c3f/M3hLALxI8uyPzSzPzSzVTP7vjzPv/Xe95tsBxF8VSUO4NDQUP6e97wnRDcoco1oPQKo3rg6hikhgFfjIzDlfNTX10f98zo7OwsFgEOO8mIoTK+cFCIZ5vabv/mbtrm5ad/0Td8UzQ8HwkfbtbW1EdfLHx6+Njc3hwvCMUjA/cwPdFL5Hd7xYv0UCldkEgSV99b0b8qBVWfR7y97rCkjTVPz+SmkQp0c5fZoilVTbZo+V8fQo7vs72c/+1mrra21t771rSFthAOB0a2EUKmS8vPb3NyMSOpakafOA/NTZyKFpsA/5IwoJYE18gZGe/RhpDkjOjQ9mXIQi3o4ahpWU1qev6VIZMrJxsjoGQGV0jQzMq8IhTfSiuCz5uyDktKVgpBysn1/Rs/hVSc7y7Iojer32L80/ZaqElXCfMrJ1vOhFBTPLzXbMfx6DpUDq3us55fvacrV6xlFyzw/T8+Id2ZVz4Du8N6eQ+ZRKN1rDQYIIpgfRVkEHV7P6DnW7EcqEOX9ihBH5C6FPnkkT9PToFtaPOgRMj9HTQMrHUHb9ugZ8RkkP0fljqqziH1SilYKaACkmZ2djeRQbTEyrWdEgzy1dfpSXa3ZI94vBTRgi9XGzczM7NpnpT7hGCvtpampyS5dunQ4q4CzLGs3s39oZn9uO21g/oXtpHJfZWbTZnbFzH7AdhDBnzWz1+5VBfzYY4/lf/RHf2RZlkUIIIZVEcDp6ekIHkYJa18iBgR/dU4U/evo6LCOjo6kULHZOCccSkXWEBrmpl+9QCGMWZbZ1NSUmZkNDg4Gg6AwdUdHh7W1tUVOqCIIyq/SyFxTEwj1zMzMLvQUhIO5EVmpslVEQ505v2aaykXZEvkqd0XRFhQXc5ueno6UGkZNUQOt7FPuoyovnRvf09/V1JO2WVADpXP74he/aMvLy9bb2xu+j0LGyIO2YEA1LYbRbG9vTwYUiuQqlw8nU1O1GkConKFsMU5E4ziDmlpU5405+P1krzWIUE6SOm/quOncmJ86IuoAg+AqOqoIAXupe6oGnnl5hEB5jpw9NUb6NaXwSXuZWUD2fMHSXrpD0QutfPWonjeUekYVecEpV2RFUT11dCudT+amDrkWK6E7fAouNTcMOYitOmrKsSYgJV2t+6pzUyeDAiUCYU1lIkup/cSZRK8p9UMdIE8B0DOAnHEO1AHSQhTOvQYwGjyrnWK+ioYqF1hpFNpUWREonRsvLT4B6dUOCcrpVoRM91MDVS2MwPFRrqU/n0Vz0/PJ3HBqtSAKGao0N5xaZEAdMh/YYwuK5sYZ8eg750ALIRVZZB+xCezpX/zFX9jiYbwKLsuyHjP7rJldMLMtM3vOzN6Z5/mf3vv568zs35vZSbvfB/BGpfc8c+ZM/vjjj4cUT0qBamGARuTKW/KoEIoAR8JX+qjh8TwWDqGv+kRJsW9a7alpEUU0FM1YXl62sbExW1tbs7q6ul2RrramUbRM0QslvqaqupTgrKRrRQt88YyvPtS2DFqVrVHaXi1zUsUzncJHrQAAZRZJREFUrJmumzqIKAf9vycLkwZR5a7Eek15aXscJWArAZ/3YG6s2927d21jY8Pq6uqidjg6JyWzq2KnWk+RZi1IQBFpys332YI3oxWQKHl1EvcqQlFUSotQVOZS65ci1evcQB71nCpNwhee7If471s5KErq109l0RehKOlfOaUalBQV8SjKow6YovMYSC97qaIEnZ8n+6uBRG5SBUb7acek6WndW011+YItdfRTsqfnws/NnwfltGr/PC1E0HOhRSScVy1E8OdXC7T8mdUKVoI634dOnSJdP3V6CDQ1APAVwVqt7CvXQfI8GuoRZa+H1XnVPUbXbW5u7kK7PZqsqJnaCD0rSnfxfEECAI/madWvR+KRW9+lQgMAjzR6jjo6x2cJWDPNsqjjyr/xBdhXeP4MRWf1s1PIolIiUhxlKFbf+Z3faU8//fThcwBfiPGyl70s/53f+Z2w0BxGbeFRiayeihR8iwd1CFKEZc/jUGXD0ApVT1T2HAmNlD0/AmdInQBNp2nKWaMqlCAKkDlB9NZUgUbLPt2iClB7U2nFFQpO0z+aIlAFo2kqdVKKCkx8mlkLIlQhF+2fXxvdP89j0kpjrUTUIEIDCE8dKErrqUFNcW8UTdMgQp0Tr4QxTipTiibzUgOh+8d7a9W4pmg1UlcjhuOirZWKuLgpHimBDQEXMqkFGOqA6/7pOinCx9r6tJiij1p04feQvQURxQlhaErWI3ypYiUMmvaOU4etqDBAkTPlK+MMq8PGeysfLlUMADqla5UKmHG6VVf5YoXZ2dmIL4fjrk6ktkbx9ATVVRhPDbK0a4IS/z1/OpXSLEq5priDHp1K8ZIVZcQJqpTKVHRK+avKqdVAlP1TB6iomEMdIF+kV1RUlirc0WwO6CJZMN5PA07lV/piHZ8614wJOlmDdaWVqF5QWU9Rc0D+QWTZnxQ30NNy0LsKwODIK583ZZNZK21dpO1qSEOn+J5e1n/qp37KLl++XDqABzHOnz+ff+hDH7L6+vrAxdFUGA6XV/pe2FI8HA6BOjdqHDVKSRF5UWIaNZEK1mpkJbYrsqa9nDiYc3NzlmWZHT16NCoQ0PShImq+XQBKVdsEaPTr2wOo0HvCLkqQlJzC/sq58YgBc8HxY04oaSXcV0JZ9tMmRdOYvmWGvjQKVeTMLEZ/fGsPj/TwdWZmxjY3N625uTmskW/gqnNTzqZ+T38XI63tPHRuiqDpS9tBaCUqQ9uhgEBoSl9bA/F9dY7VedA1802F2RuVG/9v/ftKw3+monX+eXSOft76M0X7Us/gX9pqhDXWIjJFI/lsRdf4ytnRCm7mqSl0XTvdUxwvzo3/v/6uXzNFrZA55V8q0sbv6Nx0D59Pax7lmen5YD4e4Uu9PBLvz6ye1RTSrS+dG/tJCzCP6qmhV6RR0VBFapEBXR/9bN/qRLMEOED8rWZUVM+mMj7eBqDnWOciXrLvi6kBLfQabGQRJ16LlzRI84F2isICWOI5vh7AwW6m+Km+iClFxfDOIuuFXaqtrY10qq5NiuqgQQj2ErvNOtXV1dnt27dtZWXl0LaBOfChlZ2q1Kh4QqGqATO7b9gVNlYHUPvMaTRqdr+/ma/SVG6WL1/f2NgI70FVkQq78u9QBuoAVldX2/DwsGVZFqJSbUIKGkhkxuHzkT4OqRadcJhBbXxqXFviaKm/HjSvbDQiS80H6J6hTuj8/HxYmyKUBgWqfb9S84H3olGrRtO0HFAki/mghFE4rA/omiJZyoWZnp627e1t6+zsDMZUUWRNbxTNxyOj6gwruXxxcTFwTFJoEU4AqSCdj0bQGqVqSkPnQzsT3k+NmEcfK6FXnFtNce9nPvwOHFsoFTg5BCv7nQ/riT6gvQbnyRPKPXKs/SqpXDS7z/VSJFvRBPiramh9NwIGa19pPseOHYu4oY2NjQFtxvnQ+bA+yvetZFjVmfWGPjUfGqCD6oEKoYPVUcSoKlKlHLiRkZEQGKf0Myhx0XyQnaNHj0ZFPNqDMDUfz4FjPuPj4wE0UMdRnbNKqDXz6ejosMHBwX3pZy00wfHQ/ZuYmAhOo1ZMF83HI2agVQMDA0n9rMg++tkXUqp+npyctFu3bu3Sz9grnLKGhoaK82lubraenp4oDV1JP+t8PPo6MjKyq+IdHaudAjyKn5rP8ePH96WfU/P59Kc/fSB+T4kA2k4K+BOf+ERIiyH8Cn/rIdYUojpZOFrKHdKqp1Tql++D+vm0L4UCKF1VcsqR4KXcJpxT5eE0NjbaX/3VX1l1dbW9/e1v34VAFlV4ahTjo051IrRqF5ibg4Ji0n5J2lpB07pKMlZOkNn9yFwrETWFqRGwcoF85ZwiZtr7UXk/vrGnRr/sD/KiqRztXZdCCBStUiRPeVxXrlyx2tpa+0f/6B/tQiyKmsqmuGUp3hsGUPvVgcookqnIryIA2ucPo4US8+grn69oDgiOOpZmxVc+8dzITYprpwiwVjJ6lFU5k8yDII6iGpVVz/8rQn01OFSUL9XIWdFnRbQUYfVrobKhyI2uiee7IhvsdxGSpTKiqKAim7rvyi9U1IqzougzQ9dCP18zBJ6/x5polkBlU4vFNHjWIJKsBeup6UTmoLpD9b461IqA8366Dxp8KIVFkSrmrkUwKpOqTzXQ0EwK66dDzwafvZ8KdE9xSPHefGpcwQWcRbJdyhFkLzQl7oN5TY3X1dVFOsQXuaj99QVoKjfImm9BpA50Z2fnrqI95VNqRklbv7Af09PTNj09HYKw6enpKJBX+dUsiHL8KMzr6uoKL0UUlb+rhaArKyv25je/ueQAHtQ4c+ZM/qu/+qshGkdoNM+vwqhVOWy+OoYcIKJelDkKSbkZHR0dkTDCk1JhVCcMR0NhZK1mVShZK/ngtlVXV9v4+LhlWWaPPPJIEEb9fOajUZUaPDVsyrHj+fVwKAcChwjkL8/zXW1wfNWqHgqF2BUZ1fSz5/npmszMzERtHzCI6iQfOXIkHFKt0GNNOjs7I6Kz9gPDQKiDrApLFYZWkCufTlsSLC0tWV1dnZ0/fz6sS1dXV5gL66LkdXVOlZuiXCe/P1ynhOOMY2hmIUL16Q8vs6rUleuEs761tRUFDPrZeoZYF3VYfcsfrXJuv1dt19nZGWQGuVVDZ3Y/haaV9KyLronKLVwjz7fCyVGejsoI66IcMHWMtFBFW7yorDIfpZrgtOCoah9PkBn2Q+ejBHhtjouO85W4/vxg4DC42lcUJ1PTm75yn73hK8af6nhN3/GMnFXm4c+zUm+UUkLwDUKErKR0HHsHQg1ihRPu9b7Xcfo9Tbsq2plyQrzMsme+Ml8rWFN63+u32XsVvzgh2sVAOYKV9L4/y+g4Re21jZemMKenp21qairiwCmPkoBCC0k0pVpJ78Nh3q/eZ3+QFS3MJMDxeh/d7s9xZ2dn5LSm9L52TdDK4uer99l/zTR5vf+Od7zDLl68WDqABzEee+yx/I//+I8tz/NQzLC0tBSEempqKrwmJyfDxmrlqvKzUMbNzc2RAHV1dVl3d3dkvJXTxl5sbW2F6NO3oGEe6oT6AwZqgGPAZ6FoPvaxj1lNTY39/M//fDAKRNNwckjlaurJC7RyFrSwg1FVVRUhoBoBqjCjABRt0khQC3F8CxffkFsrExXFYR4Ky/v2I2oI9HCbWUBgV1ZWdpHYScNpWhCFbXa/mtSvhW9RoQqmrq7O/uiP/siqq6vtTW96U+Rww/v089DiERQdyA8RKL24tN1DiiBOZK5VaDhAyvFUJDpVmKH8SuVC6RnR9JY6Kr5wRZFolU0tDlEZURTHp5BwEJQs7wuNNOAAddUsgXJ6UiT5WVfg4A0PHCwQb//5WjDDWqTa9Shy5OWBF44sBgdEHkOW6n3mg0BS1Yr8KsKqyBW6QjMn2q9QuXvK+dUigUptlZS6YhZTPzgH6pgUOWpaBEMwqvKgTrTqCnSrVraqQ6LnYnp6OtgN5qRVt4oWg+RqmlXthzpsyE1TU1OE5CmayP6r7VAdrj0umQMBjnfku7u7A1KlzisOpaLgmoHQtZ+cnLS7d+8GB21ycjLSWZqVUA64BjXd3d3hxboofx7ZxJ6zFsjB5ORkmIfaduRXCzm184TajJ6envBiXQgoCLI4q6Cqa2trkaN89+7d8GJOClIoJ505NDY2Wmdnpz333HM2NzdXOoAHMYaGhvJf/uVfDugOAq2kcC244BDjEE5OTgaBnpqaCkpuZWUl6jmmEQ+C5AVZDxWGB6cO+FcPlc6DORCtq7LFoaqrq7Px8XGrrq62b/7mb94FQXOwUTDMw/MmUgiXzgEh17UAKdCmqlrly0HyCBeKTvktmkbSijkOszqpmkLxCgY0BCPH8+s66FpghFXZEpmrc+rXAcPDWmD8tAGpJxiPjIxYU1OTveENb9iFDKvh0aayylnzqBbOsq4F6+E5WR69UaRCi4Q0BawtdTQir4Q4qrJVLp+Sv1PIGmuBs4xjqQ6JVn7r2WAO6hhpQYFSFHRPUmi9R7IoIlNKAArdI3sEcnDpNJ1mdr+qWqu8Oa8eqcdpUZSRjAFr4ZEjj0yo4YG6QcpS5bOtrS1CapAPDR60GEqrpz2qpy/O6tzcXOCdEsgpesXn+HMKaqQ8Ya14Bw3TtVC9rfLBzzWAUToAhh6nBP3NeuBAtrS0RAEMcqa9P/0c+KqVo+yJ2f3bh3ASW1pawueqLkc2SENztrToR6vrFeRgHuh30GeQVg1gNHjis9Hl3d3dUUCl1BFkHX2xsLAQzUG/okuUw6n0CPa8tbU1+vyuri7r6emJUHBtw6VIvPIhsev6Uo6rFrFo2ps5dHR0BNuuTqKimlpQo7QzdJb/fBzW2dlZe+qpp2z1AO4CLh1AixFAnLylpaVdyJ9uANETkQ7CWF1dHRkNPQi8NLLWvlzK3dLIzQsCBwJjrtV5WrGEkeIQ9PT0WEdHh62urlpra2tIAauTqWX2qqR5fpQDzgRokPLIlM+nB5HDoAdB+2spz1AdCFUGehiJ9JUrpEaTNfafzf/VeKtTh5OtKTk9hKociaBRzmYWIvimpqaw/p2dnUERIANEjKCvWlW9tLRkt2/fDs4JcsgeTE1NBWRF2y9gKGmlQ9Sq8sfzK/LJ32kzdE1l+DPA/4ncCXZw8Al2FMFQZahOpTbKZhC1Ly8vB/mbmZkJETNIhiLxoM/spSI5qXOIUWhvb4+4jdrjUJ361DnEWQC9INgCyeEcYhzVGCAXWvlP0KlVnoq8+3M4NTUV8W61sAG0ubGxMQqu0AWcw46OjkA3AX3HeVQHwZ/Du3fvRgifVuYqt5ZzqOgNa9HV1RUh38pf1FS9Bpn+HCIDVJcS7HIOGxoaokBG5VDTe/B/lVerVZtqD3QPcBpBeSi2g6+oDpKXw56engjtVT4pzqcW27D+ExMTQR6QAVB3bfIMkufRKz4bp1FBB4qQsiyLCpDUWffncHp6OkIToT1xDjmLKvdHjx4N5xB7oJxWLarBHqTO4eTkZMRR5O+QARpJgySnzmFXV1fUf4/9U847AcPs7GyE3GkAAzBCEIdNZm0V6NFziD0AWW5oaIi6MyhNZHJy0v7Nv/k3Njw8XDqABzFoBA0HkEOjfdK01YpGzt4Z0Qh6c3MzakOAokMZKtKlKJOWtdOwWEmoOEaer5Ti5phZROb3/et8p3J9frP7bSy0sEEPm6aaUJTazkTbUpD2wznTKJq0iu8BpaRtnBLf149/a48slBDIkhok5qFRut5WwFrx+Rqhaeox1X7HN43Wlh5KoNdeXaniFy0w8D2ntBedVvdhBKElaINepQakGsxqk1nlzuk+aEGBFiZpmlPJ4dAS2D8CBOXD+sa7RXPQCnptupuag66DJ/Cb3S+6SRH49avKgqY9QZOU76ntmLQHoFbBYpS2t7cjNEnPhbaH0rVQfhpZCQ0Y9dn1PKhjhEPBYA2onlakUc+FIvCsg69aVHRPU/I6B/QSc8BRVznciw6gqXgt8uEzlHvmdRMv37uSFLgWTfj0M8gRSJrqBQJGHFWfBUBP6rnQYiNtweU5ecpVZA7KxSboUFTTI4k+UNEzqbaBZ9WAUR0WpURopbE6SD5g9ugZZwJk18yiFjRKldIUq2Zi0BtmFuRJ090ECPoiYIZfTJCnhVUKmBw9etR6enrCVxx1wB0FDKDlsPZ8/vj4uI2Pj0cBi55HZIhAEQeZz+vt7Q0v1oVA5fWvf7399V//dekAHsTQKmDt0q88Dp9a5EBpSo+B0vYkW6304UCroUeZbWxsBMcmlSqBc8ZhUh4LaJKS5DU10N7ebs8884w1NTXZ6173umBgMawoMlLdGuFpmka5EnDMNG2mKUQUiXL+lOiMMVHHStNlqsRwdPUQazWvLyTx6TI+GyWGElJunSIu/rNBOrSoRlsS4NBqakw/G2OqvR01VcjnTE9P26VLl2x2dtbMLKQeMLbegOA8eOOh8kZ0y1ppulR5fJ5rqmn0Ilmv9NnsiVaqYrhoiePTxZom1QIVL+spGoF+Nt9Xp15lXYtSUnuu3FLto4bhUGdFn1tTxIosmVkIqDzXOPXZarDW1taiqmN1ljwvC0TDG2wN5pQXlZJ1PvvvIuv8HK4ezrs2907RNtRxU1k3s6gICGeJ51UkCUeukqyrXvcyp6h2kawrJUCpO5rZIbtTJOu65/6z1VFlzUH1kWtF07yso1u1mIX39Z+b0us4Vr5IQrMqlWgyShlSva7PrTrGy7qmmfls1ev62Yqi89noVo8iI+te3tCtnHMv6+i3FEVIq6sBO5B1r1txEJUOgy1XefOBkdqwrq4u+5Vf+RW7ceNG6QAexDh//nz+wQ9+MBhmnAIia9IwvLQqjmg3xY8A/iey5ZCqotAWATgkKrj+Zg0ESdEGX81KZI/C0krFlpYWe/zxx626utp+/ud/PvBkNKLV3lGKKuAYKok6FdEToWlkpy+iWLhbZhb19dL0F5/lG5vCUdJWFYpo6BwUTUIpg2Toc2uBAcgGfEdtJcLvgSJgXHXftWWGtiwhLeR7SSrazDp8+ctftu3tbXv5y18etUzZqyGvbxLtm0Hzu+oA+4bFOEk8p7ZJ8c2MU0MbFvu5aT9Nztte89HnZp10vUB79W/0ObVRsjYk5quuj2+arEiLto7RQEA5hLomKhfIQaqVDPLBXM0sPI82Rdb2Kb61DzqAefNc2rYFUr22SsG50LYtrLe2h9FWJPxbUVZtbaTcQQIuRThVH3Be4Oql+kP6tihqNLWAwfdg1J6Qiij6Xpk4S+he9I1mOVKIorZT0lY9qepw1fuk3Mm08Nk4aSnOKDYHfayV6XrbBjZGQQd1lrXwUFvR8L4E/kr1mJycDI6z0h3M7tOONBhRBE8DMu3nyGeDni0sLEQp/omJiZBmZf21oEsriTX4Onr0qPX29oYUc1dXV9Rvk76829vbUSZrYmIivMbHx21iYiLiQYKgb25uRu2HlNLQ19cXUDvQS0Ww2S8AJpxC0MKxsbHwVTN8amcbGhrY/7IR9EEM7ZZPlGy2+45H7VulLzhgCKbvY6YtALS4ob29PXJMMG5sNFWfPqUAlOyjVK265XD4SLGtrS1wHIaGhkI6AwdDU4gaqeH4QpwnncPnAmPDZUpFaihe5VjQWBbOHdxD5RpqRSX7oEZdCwZAXbWYRNPL6uBrGhVOo39mnG7t5YYTCbcG596jMF7ZYiBZZ9IWqYh8YWHBrl27Zmtra3b58uVgWD3qpUinohCtra3BGEHEJ2Xpe1mlDIw2WzazKF2r6IdyWJR8j+ORioSLonCQNrh8nkPkif+8tNWK9kfUIEKj/+npaRsfH9+FdCnKhjFPIcpwaZW/CGfHzAKxnZSkytTMzIzdvHkz7AHGlDOMU6icJUXRjx49ugvV1FYUvuhE93hsbCxKy+JAUImr7SeUt8g6Dw4OhrOE06Y9H30BkiI8Y2NjUb825Fk5w5xdRXa6urrs2LFjUXEJukN1sqZe9XOnp6ft+vXrUR9OnPJUYYuit6w3+6vBogbnWmSFw7SwsGC3bt2KUq5a8awtYTxi3tHRYT09PXbixIkQoKtDju7QAi+PInLfu1a+E3ir/dH9RZcNDg7auXPnojZOmmZW5FQdVHiSw8PDFbMEimTxuVrA8bKXvcxqamp2FZUpH5mzxLleWVmx4eFhu3TpUggsa2trowAgpTv4+dGjR62vry9CyRW1RJaU8oXOwnF97rnngs1XipF/XmhXOMODg4N24sQJM7PQSkY5+Cmb9MQTTxyM71MigPfvAlboVm+P8BERm4CzVKkiyXP92u9VtSrx3xOOVehUyLWNgqIvGtV7/gyfp8UOP/ZjP2ZZltkv/dIvBVRBuUPayoNoFCUAuRgFSmSjLST084jGNeJT3pB28NcmrKAr/rYQDKS2EVEOGU4PaIrZ/WvhKMdXZBGEV1EUbcSrTnyq+a3etqFpXeUtKpLoURutSlaU7MiRI6ER9Dd/8zfvQovU0VF0TBtB62djpD16yLwVhSIg8U2OCZAUHfSfp0i4NjY2swgB9M+j6WGPzirS55spa8NV9o794zyq3Og+anNp5Scq2qd7p81m9XYLkDrOBVxTbWOBEdRUNGuhfcT4LEXZtNE5CIS29tHPA2XzyLvuL+vD83mUTRu76xqrzGixmZ595RLD2WMvoTvgxKBjFF3TwJb91ubPatDVUfVtnOrq6szs/m0qmslQx0lTgOyvp1dUSgGC5lFIxd8peqkOGlwwbaGljdlVvymKp0Ub2BOVJ+RibW0tsh0gaVq4pGvMGSNb1dzcHPHQlI+GbaFYB9lFTmfvFUdMTk4GRGt8fDwKLjmrZhYVqICi9fb2BhSNZ+7o6IgoQ1rNzT6CmoGg8czYND4zy7LAdW1vbw9oXV9fn/X391tfX19EWVI+PnZyaWkpIIVjY2M2Ojpqo6OjNj4+Hp5fwQrtsKAFSAMDA3bs2DHr7++3o0ePhuCOM6uV61qMeefOHfvpn/5pGxkZKVPABzHOnj2bv//97w+IHEZI04Cp/j0aBWl6UjlpRPG++kwrAFGWmv5AOXpCrUaYOGh6hR2Kv7W1NaAz+rltbW32Ez/xE1ZdXW0f+chHAgeP+SuJGGGemJgIClrbAZjdRyyU75iq9gR5pNJRy955b61w1ChPK6twRLQdhFZ2apUtxkmr2rTLvVb08VXbL2jPNBCwhoaGqOWCr6gkskOGFD1WGUJB8Yy0D0LeqqurbWlpyWpqamxoaChCBrSSEq4XMkQwoZXUc3NzkcwiQ1oooDKEE6HVs6RWfFsHrdrESdH2GkrIVn4X66IypDxCTSFp+grCPkUAyJASwEndKN9GZQhHj8DFt45Q2dUmzgxt+OrTZLwwPMpbZO5UpfIZ3d3ddvTo0V3V8cpfw3HaSw9pWlYdUpwkRW35CsEfhNfMggxpUKj9yjQt6GWIayahvqTWVp02L0MUlPBcKRmanZ2NggycCXrGacXx0aNHI+QpJUPa6zRV8Y6OJ9ujxUzaQsrrIV/lrTKkSJ5+ZkqG9FYnggnfYSDVYUE5t8iQ0phSMoTjz/nkPRRUQBeofkjJ0NbWVsRnT/XgU8df6RO+etivrcoQAVWWZVHfWNVD6Fx1/L0MaeW+1/HKd0Teamtro9Y+KkOsrWY7imRI28do6pqvXobe9KY32d/8zd+UDuBBjEcffTT/7Gc/G1A4FJ5yAhAe0q+gYkRQ2lgXgaGCyCsCvftPI2EOv28MyeFQ5EYjYX8wUAKK+plZ+Lwf/MEftK2tLfvxH//xqNcS6Kb2D4Sn5hW6FpaQhtOegciVVkV6wjXRKBGkNtMuSvsp6VeVjZlF0SipGU0FgaLiqPBZ1dXVUUNgLdzB8fLl+Sg3rT70qAJrCWrEgSdtjaNOehEHkkDkz/7sz6y2tta+4zu+I6SOtfJYPw+Z9aku0D2cOt8A2xdokNbTzvbaM803fNZbZng2UtRKllf+Ez2w4ICCaGklKek8kBKcWdBMjCEG0d9SoqT4lpaWkHrTvnTar1BTWYqAg1iQvgOF0mpRDXJAUVhLs/vVuqnGvIoE0UGACkntv4dc4GRoyk777ul1gHozghp5RdtAxrURsi/g8j3MSAFDW/GOBciTtorBgWJuypfTNfSVn52dnVEFsjoyqku8jkZPgxhrs2k+C+cQPY0uA0Wsr6+PkHRF8UC31JFZXFyMUB/9PNYRdEsdKD6vsbExnN2VlZWg/ycmJgLCBC/u7t27ES9akXT2i7Rmf39/9JkEjDwfZwH5GB8ft9HRUbtz507Eh1PeJ/LW2NgY7EBvb6/19/fbsWPHoudE12mrL4InPu/OnTs2MjISELzx8fGgewBVOOvsH882MDAQ0Lu+vr6IakSGhc+bmZmxsbExGxkZsZGRERsdHQ3IIbqA4IlgGDnks44dOxaQu97e3nAOleajyO/o6KiNjIzYnTt3wkspKFBe8CPQl8eOHYs+b2BgwHp7e62jo8Pe/OY325NPPlk6gAcxTp06lb/3ve+1np6eqGpPU4fqtCAwKB368uFYaCEATgvKpr+/Pyg4DgfoDYZQ0SKF07WsncO4srIS3WygituTUXt6eqypqcnm5uasvr7eent7w+dhKPg8Vah8HsqGiJ3Pa79XhceBVyWuKSicJj4PxEYVG5+HE7q2thYhNtpPi9SERr84Onp1kd7eQSSoe6eOqN6moqkCPk+deo3M+DycbJwm9kvXUtMw2g5BgwiQtu7ubjt+/HiIQJULZWbR5y0sLITP0c+Dn0OPLIZHUTEQPCOf19LSEnr0ZVkWOfXaD4s91IpCTR16ZNGnmeBrEtGzD0pFUBnBEKsDzPNtb29HCIL2XeP5tAWSpu/UqfctJei/pp9HMKdcNtaSzwOFwlgo6qVBC4Gfyqi2EtEUPmdL0X4lwPN57e3t0efp/ar6eZxDdfSVn0gQ5M8Dn6m9LbWgRPuK8nlKesdBRD4JrJVzypnT1hj6edr8Gn4e+lMdNiXX83wELzhFmjUhPXj06NHgeBBQkE7n+bRPpRL6NdjFnsDJ42YHng9HBkRYPw8HWPvy8Xma/lTgAIcbagc9ITlzfF5vb2+UldKemASxWpxB6hMdStqTzwNlra+vj1qq9Pf3h5Qnz60OvlIg9MyRZtXPo8XS+vp6oHU0NjZGaeu+vj47duxYWM/u7u6oCFEr4lVW7ty5E2w8AIkG10rt0M/TlC42QqlC2m1CZeXOnTvh+UANKT7c2NiIbpHq6emxr33tazY9PV06gAcxHnvssfwP//APbWtrK+KIcKhGR0cjqFybHwOPQ6jt6uraxSfAmJMC1SpfTUOOjY2FqAuloY0tibgQchQikQ9KH84EvERt7YKiV4WojTSV+K9EZaJJjey0eSZVdED+KHXWkM8hnYxDaWZRuhwlpJErawhSpcjDyspKWCtVhLqG2klfixm8IsSZZA0h2FNQgNOjxlmVBGsI3yTP86gCUY0XhlORYfh829vbEQKmxgQ5pBIRHg+IiqYuVC5YQ9A3omNSPZrWS62h3sygHEx1qJCNnp6eEIiAupHS9muosqiOh6Ld2i8ytYak+5ubm6Nm2prq4nl0DUmvLS8vRxxT5V3pGvI9UsIgKJxl70xpJSFpaNZQ+XqaMVD+E2uoPQgVkfVriHODQ6zpNOUF6zOxjmQMWlpaQiCzubkZ3o/AF13IZyufjMC3rq4uSk2m5FAbT2s/R4ztxMREMMLa9FrbhCCDLS0tkRFG92pBh1bes4Zzc3PRPiH3ispqpT/BQkdHR3gmrfrUCmOt6tcCEdZQ9SEBztLSUtCFIIceydMAW3u2wtNcWlqKAjLWUJsWa39O5Y7z3qxhf39/VLgAF5OgDK46a6homvanJUCqrq6OCl/8Gvb19UX9YbUIUwERtZPIvfaaVN62Np0GnVSHFG4hckjWw+vCO3fuRJk55XDjeBKI6X719/dHVCjmZmZRWx7V8aCvuoasRU1NjbW2ttqtW7dsaWmpdAAPYpw5cyZ/3/veZ11dXdGVOUr+Vo4GgqfpRSVna5NfTc0q8qCpKZAOlKn2C/LdzjGi2uZCG0zDWdDKUIX88zy3z372s7a1tWWvec1rgrPm+xxisJTXqOk9X0Wm6AbcCHiUWlTjq0C1mbM2KFXSvqYrNeoHwYLrROd6jIl+nhbSaENY5F9J9DwHaCNpL5SFtghRsrciUXzVFDB/B9qQugsXBKyhocFGR0ftyJEjdurUqcDJ0p5amorFKdACExAtvZkEOSF16FOyFOtQUKLolP889sxfiQSfT1Ol7e3xPcMETlp0QQpYq6PZM4wkxp8u/1pxpylndQqhXUC90MbqPI+m07XdEUUs2ndQn0m5ZTgjyAjpZuRDbxIgo6AySSrILG6Oq7xI/3lwBbXfG/uj/EStEtV+Z6wLa6eUEuXOafBlZuFca/pcW3con4w9Yw3h6fn2GQQO8NdALZFDeLt8hmYO2EddQ3qxEsBq8IATRZBbW1sbtQbxAaw6vnC5oK1oAEtgDvKE48uzodNAKkHWcKhJEY6Ojga9r62+9Gxp8K9pUCgQ2usUBHZubi5KSWqqF/1F4Q22BWBjYGAgvNS5QU6rqqqCPiAtf/fuXbt165bdvn3bRkZGgoMzOzsbnh8KTkNDQ+Q8HT9+3E6cOBE5bWQj6urqArAxPz9vY2Njdvv2bRsdHbXbt2/brVu3whpCP8ARVT1x/PhxGxgYsOPHj4d/9/b2BvqIpq2VH3rr1q3wXOwZvM3FxUUzs0AD4Cz19fXZiRMnbHBwMNqv9vb2cC5AXJeWlsJajY6O2vDwsN26dctGRkZsYmLCnn322QNpA1M6gGb28pe/PP/kJz8ZkB6UjU/9TExMRJw8JZRDHAWlAJ0ANVAFyiXVkLqVMIpS47CCNOIUcdg8zxA0SVOEKDSttJuYmLB3v/vdtr6+bv/4H//j4FhqexV1vJTfoZVKKBiQCQyqQuk8j5KaMQjKseD9NJ2kjav1FgRgcXVaid6VJI6TTLd75RNqFK28GJAd1o00GeumaXFQHa0G1ao2LZzgmXhOqui4G5R1U6V59+5d+8u//EtbWFiw1tbWQMwG7aNzPUbH970CwaToBnmDf+bTjB452t7eudKNdQHN0bVDIZMaZL1JucM906o8ggycEFB0HCsleyuqjULWSmtdN39OVd4UJdUbD1DMyBtrp+1VtHGxyhtBoHI+9eYZgi4vb6yhNgXX/nOsm1IjWLe7d+8GxJE0FI6iIh04OMrb45zmeR7Wjf3heVhDjCrrRn9NDfr4HC0CIIiqra2N1s0j9Hozg09rI2/Itddx2mWAc0pPNXSCOobsmVZvo4ebmprC3DW9rBxZrYD36KuXOS2IYd1wDOFv+v0BdFA0lAIRdeBTfengwuLUELymzil6p7m52czud0bgzKtcayGeVrPqDUJaTMS6qbx51Bresl8zdDa/Y3a/WwDntGjdKIqoq6sLFe2aVVOqga6bdl9Q7re3C4A1ml1A5ngvOJrKB8VpZz4pfqZSpkD7sXU8v94X7dfs4x//uM3OzpYO4EGMhx56KP/gBz8YDDOHiqgSRalEaiUZw+nggGgRgRpklFdd3f27d7WvoO+rBJeKSMnsftsOhFarb0FZcDb5XSVOLyws2M/+7M/a1taWvf3tbw/kc5AqbaxMqk+bSSuKo9WuZvdbLmh/PVWKcAjpPwayotcxaUsXEA4iKQyYmQVuBCgtCIp+hjYrxVEnRaXNcbUliaaKtNjDN//VVJT2U6OQhUOsfFD9qo2JzSxqBwTa98QTT9jW1pY9+uijUbNvlJc6HNrwWBtOaxsXrZRjLUlxsVZ6Gw3Ppg2Yabar7SN4aVsV/q+tX7R5tLaN8a1x1tbWot/Vdi6pdjy6f6mr0rSpubb/0edERrhtQjk32sgVeWQ9dZ1803RaRSllBPnVZ1DE2V/JSMCoV1L62yQ4w+gKflfbT6hTo/0TtT+mFqbxfmpM+TyMGygzbZe0fx5OYldXV0BMCUYISFIBoxa/oRcVqcQh6OjoiKgA6Fr0K5Wv7LdyVLVViN7ug9zggLa3t0dUFKW+kPYzs6hIBEMNKjQ2NhbWcGFhIZyjurq6gL7zGb64AF0OF29zczPqlnDnzh27ffu23b59O+I0633E0AyUf6doF/LQ3NwcZFMLNO7cuRPQLpBDLQjZ2toKskyhRF9fnx0/ftwGBwft+PHjEbVGA1+cqLGxsYCmgXLdvn072N/l5eWgY3DUjh49aidOnLCTJ0/a4OBgtEcE4mYW9eljrXie4eHhqBIZ3YGjRquWwcHB8CwUZSjXHNs5Ozsb9v327dt28+ZNGx4eDkjk3bt3o4wC56W3tzcgg6Cex48fDw5wS0tL0FVLS0s2NjZmb3/72+3SpUulA3gQ48KFC/lHP/rRUOGJ4cAZ09QvihAIGyOlBHBfLICHr0oDo6HpIJAsjVa0BYD23fIEetJDeu0UQgPqw2e8733vs/X1dXv1q18doi8+A5SxpaUlpGd8yb82m+Y5tORe0+QgmfPz81Erg6KeU3yGprfUwBZ9hqJXGAyeg/Yp+hxwaEAt9ID5lJYiZLOzs+EzqqqqompXXwCDQWK9cEqhFMBpSaFJm5ubNj09bdvb23b8+PGQdk/tuxYS8RlUSaLIPW2BnlzIr6Zs/XP09PRE/RaLiqPUCBWdEQII/xz+pgC9AUM5VCn6hfbj82dEzyFICJ/BOcQYaYsekGu+T384/QwoHqlziGypk6hNvxV95TNIOW9tbUWN1bUFj7ak0FsV+AwQUa1WpTCH9HbqjGgFrsqvOr3adsefQ84IQStOqKLI/hxqoRgOr7bUIBDWz9DG4XyGtr9KnUNSvSDVnBGt7AU5JMhnT7RPp3Ze8PLLZ3AWCdg4h8hv0Q0TBJq+cMnLL8FBU1NTeH7OoZ4RtVWk/fkM7d3qkUJsFZ/BOeSMqB3hHLLvBB96RpqamqLiMj2HzEPvWsdWkX7X9j/+jGhGTM+Ionfsud4dDRUD9E6L1wg8ADOgz6g91P3AVjU1NVlNTU14Dm3UvdcZ0a4QWp2u7aG0mHJjY8Pe/va32zPPPFM6gAcxHnnkkfxjH/uY1dbWhs7jS0tLUTUlh1b5Hzgz3FWIR+97pnFoiTBwmLQHlB4kbQ5KahFhh9+hPYlUgaKsQPv0DkQq7f7gD/7Atra27Ju+6ZuCkiaK06IFRSS0ATGokEbxoBLaUJWUJXwojCJcNHUqaLgJQsDz+yuotI+SVvApQsT7qYNHBGl2/5oxImXlemozY9AxLfbRptC+WbJyA5mbolq+YTFooV5Rps2Rn3zySaupqbHXvOY1AeHTK9C0WbbOmffW681842VtJg3qjbFjTbQPJuijpu+1oTNrwrromhStN5GztpJh/XQtFBWGp6mpEhBFvYEDNE4biyO3WsXOe4Nuw7/E6TGziMsHxw5OpDZPRvnDT1ROqb8FKHUDEJw6fy+y8mQVZdYqYAyHcgR5f/hSIKHae1L5xZxjbYrNfOlPBtVEaQacPdZei3yUF6j9GBX516pbOG04CZ2dnYF3SPEBqB38KOXnEXTAW0bfkEKEm+dbeGj7I62Opl0IPDmcEZwJUCmKa0Dxjh8/bseOHQtIHtw17ecIv1BRKfZEiye0IKS/vz+gRTxHf39/FPiTOpyamgpo2u3btwOPDLmam5sLuqexsTHs78DAgJ08edJOnjwZeIx9fX3hXFdVVQWbMjk5acPDw+HFs2Br5ufng35obm4OSOfx48dtaGjITp48GTVCRieZWUhDj4+P282bN+369evhWUZGRmxWignRD62trRGKpp/BGurNOVpIcuPGDbt+/XpAO+/cuRP1vVV+OMijvlSelHajhSQ3btywGzdu2K1bt8IZISgjyIDOwR6cPHky8BS5meb1r3+9ffWrXy0dwIMYZ8+ezX/91389VNzhtGgfLS2zV66M8iMwJnCy9EWjTKo9cRBUEetn8P2VlZWQqlP+kpJliUq0ySnNnYmktWr1wx/+sK2vr9v58+fDM6AIQAO0r5O2CEC4MYoYQp0/yANVe6S/NOWl3DgUM84m/B4cKOVeQYxVHp62qtCGmlphBvKgNzLoLQgapVHNRqQ2NzdnZve5KaxPqkq0s7Mz8MdqamoC92V+fj6q9OKz6N23srISkeS7urpsfn7eWltb7XWve12oKMeZ0OuhNKJl7iBY09PTUbSJwaJiTau6iWxxnOHEgsIh97QrGBsbi9I0ensCgVBPT08wIto3UosycKKo1tWqTN/vDKeG1jV61vr7+6NiJL16jwCIFCBOA2dPi1mQQSq3dY2OHj1qbW1twbHQRt++TYZH8wlWsiyLilU0zQgSR6+92traKNDivbV6VdOlZhYcK20qq1Wk2mtS036ghJwxj4gRwGjfTM6VL7AADSOopi+hVldqQQDopJlFug7UWx1DkBft7ai3Uaj8oDNw0peWlkLQ1tDQEKGdKqc463qLifIMtVKe1DVFSmtra1GFMrKjawRdh9QrgaGvxkdOQY41MPWpal6KFhIAaHGBr1RHV2ggQ1sduLLamaGvry8qtCJgoL0XHEldI61AptMEARJpUL9GSjXCXpKe5hm0wwTy6zNNoKmqq5EjBQg0wEtV2COjCwsLUdcAbRjtbxPp7OwMFJyqqqqo76ieY/QGhUz4FNraBv3T19dnv/RLv2RXr14tHcCDGI8++mj+qU99KhxyDqA2btSqVSIzvXhbeRwcQDYfY618BN9LEENHdZ723NLyfA6JomcoWD0c2vsKwZ2fnw9cn+rq6kB41iIPbTBL7zcziypqEVYcMKJuT6xVI63ohDauRTHhqGqhAFEqUbPZ/btwqQjWuyxxvnx6Wo0bnwGSS/NWHGDe29/RqYilv21DL1Bnzqy3Ijaa3mHeFDeAsqIoWA+MljYppjgIpVhbWxvkRZtl42RoXy+9ng6nyDdBxjEGyfI3veh6K1oGAqZ37yqHDHQIZxcEUZthK2UCVA5kVW+mQA6pOCW9yppAjNfm7FohTwpVnSycCC3+UoRMkSXkzFMYfMqGe7a1cMkHS74BLbKihhf9olXwynXUBsxUd+r8lQ+rvSZBkDCMfX19oSgBfhOOlSJu8Nu0KA7Us7GxMbpeC/RCye5cI7a5uRnRObSykqBvbW0tOKp6s8iJEyfsxIkTNjAwENYINK+2tjZwkGdnZ21kZCSgbCB64+PjUVN49kznrJ+BXtDWNTMzM8FG3Lp1y27cuGHDw8NBj83NzQWUXdfl+PHjdvLkSRsaGor4a3pHOrIyOjpqN27csJs3b0bro3xn5tbd3R1QIzhyJ06ciHp6IusLCwsBsbt586bdvHnTbty4YWNjY0H/mlng82LfBgYG7PTp0zY0NGQnTpwItqOhoSHYC01FX79+3a5du2Y3b94MDZ9nZmaC04ve6urqssHBQRsaGrJTp06FtVd7l+d50Lmjo6OBZ8f6DA8PR/QT5ScODAzYiRMnbGhoKHyGVrsjj8vLy8H5Hh4etuvXr9v169eDzI+Ojobgu6qqKti4/v5+O3XqlA0NDYVK3+PHj0ctj6DfTE5OhjVnX2/evBkC9oWFhahVlMri0NCQ/eIv/mLJATyocerUqfz9739/EDSMHugNCkS7h9OnBwgarkBjY2M4KCiSgYGBUMFG2xJSbBppoJxGR0ejViw4BSi/o0eP2rFjx4JiwsFqbW0NEat2yqc0njJ8Ij4ienpcwQnR7uMocVChI0eORNG2thJg7vAKFxYWoiuaQFJ0XdQomN2vTsN4jY+PhzSGVhSTasvzPCKe877Hjh2LKi6Jwojw5ubmwpw52Cg+HCA6z6O4NeVCawLtg0hqUxFjXR8UE72q4EfhPNAmgCACXpwaevZ0fHw8GALlypCayvM8GAXWRVNffX19oYquvr4+qtRjvhj7kZGR6Lom0uANDQ27WlGw7iDVinYrQqZnSXu8MeDcdHZ2RuRrgiGaKZNWQ7Fq0KaIPQbb7H6lKeikku+Rda4QhMrg95T5k+paWFgIqAnyglGAdI9D19XVZWYWkApNdSHruqfKrSIw8bLO2VLUZ3l5OTjMKuvsL1WeS0tLofiFuauxpzUGqU4NrpBFbldAzyCnpHup+Gf/0F80OSeDoV0FVH/x3iCTY2NjYQ55nkeotsoLzwGS1NDQEJ55bm4uuqFB5866gTJ6HYBBpitCV1dXoGhsb2/v0uukFdFr8FY5p5x3dTi1vyCBCvoF3YtDqKlwzSgQuDJ31ob1QX/x3vAikRMtnFCklvngMPf29gYH68SJE1G1Ls8JwgkKT0qajMLExESgaWxvb4dglj3FqcImUfDjbTX7yFdknWBG++myDjhrrLumcgEgcMaZuwYqKVutKfXBwcGwLtg8bLVWLmvRjSKEUH5479u3b9vi4mLpAB7EeOyxx/JPf/rTtrGxETXr1KokHDIqkihTV+OH8GvHeK3eQyGwyVQhoegQnvr6+oD4wfkg/8+h0oa32hdLhQehwsnLssy6urpsbW3NWltb7bWvfW1wOLRLOkPRUNaChph3794NZft5ngcCK8odo6dtCNQ5ZW5wYKhkQ0HybDU1NRGvkvfVtKW2alDirRpT1h6kUo2pOhl6bZL2j6NthgYDoAhwj7TJLw6QXh+EkaZBMqgZqB4OAFciXb582WZmZoKTY2bBUe/p6QmKXNM/RJrV1dVRPzjtL4Yjo/fGYig6Ojoip0iRFdIl2hTbOxU40RghWvBghNQwQ19AGdPaZXl5OaTidd6jo6MhZa9k9q6ursjY8wI1wJFbWVkJaXJ1FO/cuRMc3KWlpUBVaGlp2fWeAwMDUbsluIHLy8vh+dVBBD0kbURApI1ikT2cCQI5OJ6atkammTOpWU37smecFSoK4QsT+NE/jWACnphykZF/Ra9w3jBonE9ty8KZw7EaHh4OsjE1NRUqIaurq4Ou6+vrC4ZSdRI8STOL6CzKO9M0LAGTFjTBm8NpI4jgd1dWVoJeGxkZCaiMthHRO52V3gAHTCknIHl5nkcOvs4ZRxb+6+bmZtRAe3Bw0E6ePGnHjx+PnB6cL1Dvqamp8L7KX0M21tfXrbGxMQTaWj2LXLPOpIs1oBoeHo7Qu7GxsaA30EnQJZALnNiBgYGoWEmvPcUGKk9Rm7Pr9Y7YQK2U1d6bqpOwVcqtJMW9sLAQBfbaAxAZIdhpbW0NsrGyshJdIcdaM2e4gpoZ4Pm1wpc9aGpqCulw0HX1C/AN2AfONw73U089ZVNTU6UDeBDj9OnT+X/4D//Bent7Q/qwuro6GPzp6ekgoMqN4T5gUrYYfUXQtAkoB5d+bChgNl9Tq9o8FeRQOQZaJYRwaDNp5Riog7i6umrPPvusbW9v28te9rJAnAWx8E1SQYgwcktLS7t6YHG41OhzELQRtq8y06pr7YlI+gDnGJSVqix4bBohEkFreb7eO6k3GqgDi8OB802/M9+TTjvUa3sY0EQI0VTesb+0FMqyLCg0bbarKXf4THCaPvWpT9nq6qo98sgjIW3Nc7Aem5ubgX/K7SbM26fcU1dJaaNgFA7otJlFvE3dSwIR5IMbZ2jOqlwmNc56dykpDt8sHbScZwLp0ds2tL8gXE0CEsjq+r56wwbKXdFJqAFQP3Bg2Fu4b/CKkDmcuP7+/uBkUSmNQ8t81fFU+gTBC84s51xTpyk0hTOibTQUJddbLDRFjSOk/GEKXswsqlxUQ4fjBddQ0St1WAYHBwNVBRQly7IovU669ObNmxFnlbNVV1cX5gaZf2hoKApKOCtbW1uR8waZH309NjYWkKU8z4Pu7O/vt6GhITt9+nRoJdLf3x/a4lRVVUXV1NeuXbNr164Fp2V0dDS6vk6r9E+fPm2nTp2yU6dOBUcA7iu34jDnGzduhPfGuZ+YmAhoPmtBevf06dN25syZCM0DfQZ9ZC2uXr1qV69eDXt4+/btUNS1vb0d5tvf329nzpyxM2fOBKeT9CV2C905Pj5uV69etWvXroWCBtq2cFahXXR3d4f3PXXqVHC0oEfV1dUFXiJrwXvjwLEWBDroN9bi9OnTUdNoguvt7e3gfI+MjET7x5xB97a3t6ObvHhfUMcTJ05E2UG9wYsU8c2bN8OcuVVrfX09cNK7urpCiljXGOoSgSqUHFLbN27cCI4nlIjJyUnb2toqHcCDGC9/+cvzT3ziE2ZmEVFZkZ5USgNUQ1M9AwMDgUDc3NwcoNvl5eXoyhzeV9szaNWj8n5wKDs6OgLysL6+HpwylJyiJcpxIz3d3NxsfX199sQTT9iRI0fsXe96V7juhzSH9hoDkdIUKanjtbW1QGYH7tZ0ESiakv15Vk0BKgFWizk0EsYQaiGBGiytZgT2BwGlWTNGVhsaK4IGB62+vj5qe6CoLWuhhQ9Eza2trcE51/QZBQVNTU3BQYa/oqnWkZGRqHFxQ0ODraysWH19vb3qVa+Kuu9r9/iGhoaoI34qBTozMxPd0UkRAGgO6DLoJIiqFk9oik/5cdqrT5uGs2fqnNNbkbSnpvjZM9AnrdbFSPG+2q2/vb09aoOCQ6QyRrHKwsKCbWxsBOdT0TIN2rQpOJXKIIe6Z3fu3An7tbq6GrUiUURSL6nHYQaN8GlIdARXCq6trYWCFN6XuaJ7SMtCccCAIFcjIyNROw0tKiNQ0DSY9i7FPoBEwl+EU6e3B+mVhAS+rC1UFfSF2f1enkq055wpN5JK2Lq6usBT1Ipb5YjRQJfef37PxsbGAoq8ubkZtfNRKgCfoUUCzGd6ejpCvpk7V/3hABEQaHZBi9GQb71+VBFevQmEPWOuoN68N7SA1tbW6E5yLZZAN6IX5+fnQ9Ut6XnWV9+XZ9GCJ0V4NahBprVnp+otRRwJ1vU+ZQARX+HNOVQuNbZBz1hvb2843xRy0oBabQ4v7baBPgG9w+Ygy9p5QNsHqc0hKAMd3d7etvZ7d2d3d3dHsoCN02bwFKBgy1hbzjT0oeHhYVtZWSkdwIMYNIIG8kUotI2BOkCgRmYWkUw5QHoLCJU8ZvcvRdeKSiIUUD+EUY2JktdxLn2HejgQvBfVWP7C+qamJvvyl79s1dXV9v3f//3h/bRqD5lQWF1RLZBAvQkFFApOCSgLSoBCGFJEoEHadFbbpRCBk37Slh20AQENVEQOFIrqY1rG6BViVK2hKHwbEyJeHBaz+30btRG0tnaBYE+BDe/Be/sWLMxBW8bg1BOVPvnkk7a5uWlnz54NjjGGnvfFQPGVn9MAXAMQAgZeen2hNqzWqwy1/xTPpM2iteGxOrC0jdEWNKCf2lCc/lk1NTXR9Vh6hR9KnD6PkK+ZGzxHRVOVD6sFWCC1pO05I8iFmYUzAbpMda4ih/56KFJ8pAv5PG6ioUG8Vs1iXHiOmpqasEf+GjKceS0U0z6BvokwrUHYNy3KAQnC4cR5gWeoFdykN0lRHz16NPRpJKhDP0LCJ+U2OTkZKDNQOQhoKVQYGhqKipVwpmdmZsJ7kYK8fv16VIlJcNXZ2RlQFYoIBgcHo36MeiMJiA3oFW1LkGktXgO9On36dEQB4PzCmaVQ48qVK3blypWwX1NTU+E8trS0BKTq1KlTdubMGTt79mxUgc/5X1hYCAUC169fD0geRX0zMzNRo3IQtlOnTgX0Ece4ubk5Kvq6fv26XblyJRRm3LhxI2SH1tbWIvR1aGjIzp49a2fPng1p2L6+vvBMtDmhIIPnV14i57C+vj44bPq+mimDA762thZSoTdv3gyooNKxKNxpbGwM6DPFHUNDQzYwMBD0jF7scPv27YASI7MjIyNR6zKoQceOHQvrqmltdGGe58GW37lzJ8gWDuHY2FiwDVmWRR0LQLXhwvf09IRegltbW9G9wJqGn52dtWeffdbW1tZKB/AgxsMPP5x/9KMftfr6+qh/nvKatAcURF/aXYAkKFLX1dVlbW1tIRWkHBNF6zBCCwsLwSEBWVQUkDYpKDS9JkajW9JimpqgXQAK+DOf+YwdOXLE3vOe94S0KQpdL8JWRBGe2tLSUnBmaHGgHLT+/n5raWkJvA/6sfniAtZBe/rBQQPpwKAV8RNJ2/l50pRU08V64TjIDIYXpIfCFo1CQQDVkcTJUL4cpf/d3d2hC32WZZGDoLxB0FBukeEmBeV+Xrlyxdra2uwtb3lLcM41iFDngL3Xnno4QigyRY26u7vDdU1VVVUByWE9STegbOkXCdLHVUbqdGhBDI4MrV30xTwhwqOkScups4FSpDeY53hCncC4m92/9UWvEFPkAceB1hWrq6tBHvVFAQbIA+i7Fo8wz+7u7qgvoUe7dZ5UVxLgsB9agIX+aG1tDTfRrK2t7bo0HqQbuaCpLDoE9AWnUy+k19sYFO1XKgNDb0dg348dOxY53QQGq6urEarHWYJDDRGfAEPT6KCG7feuE4MyQwAK+qh35RbNUxEnvU6QYBCuKXNFh1DEtry8HArY6GGHLsaQU3RD+g496XUdNBnS8qT76e3n50n2SPnjONqq65in562qTqbgi6BRCyZS84RjCxABuqg6GbsH3QE6DHZS6Q4aGBKs0jfRv7RiVoM2zWoAyhC0kH7H7uKocy8ynGuAglnpIKC8RoJZuHwEbd52UCkPXUyvpGSe2uhdOZ7ME8SZbAZrjFOZ53l0xaW+79zcnH3lK18pEcCDGg8//HD+W7/1W6HtAeiDv86HthyaAlZjqIcNQVZelHLm4DzAxyDy1LYVoH7algXh0B6FivqRZqSFh29S3dbWZo8//rjV1NTYz/3cz4WryDAg+r5Uy0GsxmBhYPQ6Og4DhG2cJZxUvRILlDPP8yhVgNNIWxHaoii5HIOMA0GHe97PX0sGogfKZGYREsmLPQBpM9tx4GiYrFee6dVrRGugadqgWq9N4/O1STLvxaCNCnP66le/ahsbG3bhwoWgkEF+FbXUJs9mFhRdCg1VZQRSqZ3otTG3NuDFYJLCJmjh/Tc2NqJm3NpYWXsX8szag1GLDlD6eiWhvo/eEY2s0FxdW63wwmFkXZWL2dnZGV0lhvFlDTc2NqJ7bFP9wFIV0drLDG5nXV3drgp0UBJ0AX3wSHMpB06LOXBgWXsqHzFmFGtpeppngzsFKV2Lh1hv7UEHB+n27dvBeaXQiWIW3gsUbmBgIMhTlmVhf0dGRkJLEG3oq3dP42SdOHEioG+kj0GIOPtwCJVDhyGHUsO+gridOXMmoJpQVODk4bRcu3bNrly5YpcuXQpB4NTUVNApbW1tAb2Bj3f27NnAFW5ra4sKNC5fvhwQN9aTZv8bGxvBCezv77eHHnrIHnroITtz5kz4HsVG8D55j6tXr4b3Rmevrq6GQrGBgYEwN5DBoaGhcLarq6uD83vr1i27fPmyXbx4MSBid+7cCdmB6urqUMwAenfu3LlQjNHZ2Wlm969eGx4eDqidomLaSong7OTJk3bu3Dk7e/ZsaKDd398f3ZENZw+UETQUmSRD1NLSEqGAIM0ACFSBQxtibrR5IQBgUMgHYsf7aqEnNnd6ejogyrR1uXXrVnQO1QGkpYsG0Q0NDcFm6B3QvB80mSeffNJWV1dLB/Agxrlz5/IPfvCD1tHRERkT3/eKqj4MV01NTVDIWvkK8sCh4M5fvScSBYjhm5+fD2k8Dq9vUUFrirq6utBMUoVOo+LV1dXgqGDoQClBWnp6ekKlK0idcg8UXdI+YnBQent7o3YIKAK9xkvXjzVUxAIHdT9ruLy8HJG9WUOU3+LiYjBMvJ9vBwHiV1dXF13Npe0UiITX1tbCGuql58wRXldLS0vUjFb5JorM6s0lRHzwbaioRLHAi9H2A1oFCpoCDxEnybczoKCC51hcXAzPRzWbclF5PyqZfRUsJHlIyxqE6Bri1NC6gH5Zfg31zlMKBSg08msITxRnk4gf1FDbT3R2dob1poIv1cJFOZdw7ahyBTFljjwHRS7sM50CWAuQIwqKdP14KbcMdEur7TXroA2kUzwtrVqkAfzS0lLEXVU+FYHKkSNHAkKC03XixImIA8gaws/SDgk8MygUSFlbW1vYX13D5ubmQO3wHQb0/WjFxBpyx6zyoY8dOxYc7+rq6oC83b17N7xfag2rqqqi5uF69ggy9D5zlRnWkIbMuobMkTSptnHSYjTPdaR4AhRJr81LtflR7qAWnqnTxnV5Wh2uBUuKkNH6J8uyYIcmJiaiNcRuEVjivGlPQ/i+igbjGCnHVVuoEdDX19cHeVM5BFwBBYfKgdOqrV64c17lUPmXyhPU22s0wFP9ReBIn1W/hspFJmA2s6jpP2uohZis4ZEjR6ICHG0VBedSb8LSuoHR0VH71Kc+ZfPz86UDeBDjFa94Rf67v/u7oVcZwuqbbnKjBV68lr1r9axeqaVKE8MDUre8vByqcKkeVoIoUQsQOyklUgEQkIkutre3A/KiUSVEb0jdGFGMmFZUUr20trYWHCnSSTgUHPL6+vpgIDCK2oh6amoqRLma6mtvbw/r1X6vIz4tc3AcPYpDAQ5rQbqDFCeGHxSL1BEpfUWDMDJmFtpR6HVdoEwgmxSGgFrpvDA8eu0d3E34mxgIHE91Fufm5sKaKR0A1JDUsDal5v5J0ETlaiq3FKW4vr4eXaaulbx81WIdnokeb9zBymeAZNbX10ecV703GCOlCB+Gj+uPfOsEn24BIQCByPM8qhLHAGjzba7/amhoCA6IGlD6B1ZXV4fUmjohBBTc0MKNH52dnVF7CwwpKHWWZdFNMvC3tLBFeYugKdowtru7O+wDTjDXYIEe8fwLCwuBG9vd3R2hHbwvSHpNTU1UgAaCogU9NLZvaGgIHDXQDpoVs+ea4oVPdvny5Yj3RiDW3t4ecdPgpymCi/4ZHR21S5cu2eXLlyNERh0ZmhCfOnUqcMgGBweD46QVwdevX7eLFy/axYsXAyo6Ojoa1ri5uTnM7cyZM3bu3Dk7d+5ccAZbW1vDfd13794N73XlypUQdGtGqK+vL6wXSN7p06cD+qrFAzdv3rRLly7ZxYsXoybGjLq6uoAQnTp1yi5cuGAPPfRQdKUZlJXp6emwbpcvXw4I4czMTEDRtMfguXPnwvzUzuC83LlzJ7wXXMnr16+H7EaWZSFYP3nyZHgvbfvFndFLS0tB3q5evRrei55/VMmSXgVZhBtJH1ecybt370aoIu+n3Fhsy/Hjx4OMaOswMwsoMtw6kGT4kNhUzldPT09UdczcOjo6wnPMzc0Fzqo218YxXV1dDY5ub29vkBXOfm9vb3RnsfoM2t5tdXXVLl26VHIAD2qcPn06/8AHPmADAwNWV1cXUiEYLEij165dCxDx/Px8aNHS2toaHVYirJ6eHjOzgGwooRMB5nYRSM04b6dOnYruAQQ14P2I7iGeQmjWyjmcmoGBgYhw+sQTT1hra6t97/d+r5mZra6uRukjDgJOxNzcXHC2Ojo6wnNivEDWGMoB8XObm5uz7e3tkOqGEEy7BIw1e7C2thYU961bt8L7qcNEKrq9vT08J/dYUtXJ+9ETb3R0NJob78VVYFT16iHl/dgDEE5kBCNNBePc3Fzgu2jaSOemNzpwqwCpt6985Ss2OjoanDKUJTwfP7eBgYHghKJAVH5RvDh4mqrVlAnvpX3SlC8EMf3mzZuRA8y6eeXGvmoKXufGPoyPjwf6haKakLtJl1Bpz7Mq54q53bhxI3LklFrBs4LyQepmsAe6bsqDpRVMS0uLnTx5Mrwf70WjZ6oQQY6YG8UMoIV6XRXvBSIwMDAQiobMLMpGIG/opLm5Oauurg7vR7qOcw/6z3stLS0FHaKpVIKkpaWl8JzMzZPh0ZdZlkXIlqb9OFuk39va2iJ9qVXC2pcPxCOlL+fm5oJ+6+rqis4W8tbY2LhLXzI3r5NoJo1OIl3K2err6wvygb70c9PKZZBQClRoKYKMoC8JHFSXX79+3YaHhyN9ybNqUYKmSxnoSz83+lHOzc1FVeW8l5775ubm8H7KXWbdhoeHw3ttbW2FdeMmDN1T9KXZTnGlgiu6brwfgEhqbuhLBu3ZVJffvHkzrBt8bfSlXzf0pdkO/YbnxAZeu3Yt8P65mYN90LkRECp9BAoZPSWZHyjr2tpaeC8CB84WCCNB7/b2dpgb+vJDH/qQzc7Olg7gQYzHHnss/8QnPhGUDkpfG2uCPNXV1QXBHhwcDBEBXL3W1tZQbTU5ORm4KXjv9KQCkenv7w9RO1/7+voCWgTxm55ccGi035xymhAkdViOHDkSBGl0dNT+1b/6V7a+vm7f/u3fHhq0wtEj5QJHAUUIatTa2hpxHoiggOJHRkZsbW0tcOmUiI0h1+o0eFszMzNBKQwPDwfIfH5+PmpySxSrvCitrGWtUIA3btyI+rlRZNPW1hatOaiTNu/Wtgx6mTrXL21vb0fXAGGAaKfS0dFha2trIb2ua4WTAdpnZhEhfHBw0K5du2YdHR32tre9LaRpQBDu3LkTFJ72fgN5aW5uDkiQ9gsjlVldXR3daapXTYH00RoBdBrZ0tYIyvUkSmWdbt26Faq74TqxziqnoKVZloU2EjwfzhdcLL0qTZvDIlsUIDU0NET9AkEfbt++HdYqz/OAQukVUZoWhPtKURgKnXOtKVAtCKNy9MSJEyH1RNCwtrYWBVoY1fHx8YCA0woKwwWXCzS4qakpSjddu3bNrl69Gtb+zp07oVq6uro6yMKJEyfs7Nmzdvr06ZBSpFiLVB8cuKtXr4bOByCO3EvK8ynyqCiynhkqQ3GiZ2dnrbGxMawXyNvp06eDbtViDXhv6D5eersLBS+Dg4P20EMP2blz50LRT09PT8RdZT70hCOQYWjjaBCkU6dOBWe4qqoqyNCtW7fs0qVLdunSpShNrJXvinzylXZLR44cCXQMkLeLFy/a9evXAz2Fgi4aIiv/Dmec6vjl5eXgzGv1sN6EoZQg1v7UqVOhUEiLzW7fvh2hdzdv3rSRkZEoEwOCrags/V7b2toCAj4xMRHQ4hs3bgRnEHtYU1MT9XxkrUj3U6RJGv3GjRt2+fLlwAfEyaUYrbOzM8g6Ad+JEycCt9nMgn4fHh4OZwi9TAs1si5wH8+cORPd6Uz19PT0dDjPoH/32rUEfrk2f0cujh07FnTgxsZGcIZxQlUHzszMWHV1tY2OjpYcwIMap0+fzn/t134tOEvA5jgROIU3b95k4QN/DQXDhp46dSriLkCcx1nSzue8l9kOKqKVtBg1bqSACIxwqENCyoO+TvR6S3GP6uvr7Yd/+IfNzOw973lPSKcpX4EICkJ/U1NT9B7KLTOzYLgxIBjK0dHRqGWMVnui6OG90eQWfpL2asJJmb1Xga2d7eGNEKVrU2UIx/RwU07QxMRE2Gf4adw2wiHl5oSmpiZbW1sLPB2tDiclRzPpLMuso6Mj4mqRfiSFBmpFNZpyI0Ff4IYdOXLEXvWqV4U5KSeNVGZR70q93F3vZlb+HSkb1kJpC0ScXAVHCpy0e2dnZ3AqtBcZd+uSKtRbZFg3DBZBEHwsnAnuu21paQlRsypYvaVBK765Tk9vOyB9WVdXF9o7cSsDzgSUBR9QaUNYnrO+vj4UHoGa63uNjIyENke1tbWBL4WBPHfuXFR8ggM5NTVlV69etStXrgSE9ebNm1GhE47JyZMn7ezZsyH1Buqn/fquXLliFy9etEuXLoWAg/YhDQ0N1tPTEww2Dt3p06cDNzHLsqBjbty4YRcvXrTnnnsucFB5Lwzk+fPnQ6oSJ7q9vT20SxofHw9FCzgCly9fju761jYpDz/8sD388MMBuezu7g6UgunpaXvmmWfC82Fs0VvIFc9H2vPs2bPh+dHxoKlPP/20Pffcc6GNzcTEROig0NnZaRcuXAjPh5PS0tISzg7ozNWrV0O6+Pr16yEVWlVVFRC706dPR8+HjtDbezTlDIKkty/hdJ06dcoeeughO3/+vJ08eTLQdjY3N4OsX7161Z577jm7ePFiVPWrt+lQfILDe+rUKWtqagpBhBY3kL5WFJXm611dXXb69OmQGtZuDjhLU1NT4bxoIQbO0ubmZrAROL1nz54N6D+pV5B0nLdr165FvfNwLKFwELCwf1B8qqqqomsqmRt8wKmpqehWoxTiTH9LEEBFsJFPunforS99fX0ROIKsb25uhutF9VaykZER+8xnPmMLCwulA+hHlmWdZvYBM3uDmU2a2f+W5/lHKv3NK17xivzjH/94iDYVxYAkD9etrq4u8uJJ2VC639zcHFAaLsK+fv263bp1K2pVoVwg5dnA8YAPNz8/H7iIOJDDw8NRN3dtjMp8tC0HvLWZmRm7ceOGvfvd745umICLSDNQTRtxeGngC3rBfECNZuUqNIRaU4GDg4PBsJpZMCAoTdKTtMoAbdDUKSm7Y8d2ur2jeEkP65wmJiZCdapWaOpl4yC2DQ0NAYUEAYGDhHNdVVUVkCUOPggUDZ/NLJTvKwLCGiliAcdNU2EaNS8sLNiHP/xhW1pasrNnzwYUGURLKzFBkekuDzmZQSRP0Qdz0ipevY+YiHlgYCDMZ2trKwQfINGkbempx3ygCeA0MaeamprQl09J8ARXyCJNlXFQlXKA8tfGvKSAiJRxDEGGm5ubgzPIfE6cOBGMW1VVVdRzCycT7i/3QhPsKUcOTg+VnxRSafUsDjU32Rw5ciTMQeWou7s7GFvaOymSfePGjeBYrq+vB0OBQzE0NBSapXd2dtrq6mpo+aHIhF4FCGoHx4k1wtml9c/GxsYuSsGNGzcCN3R5eTnqWQraxU0HNALX1lWgVPCZJycnw3xaWlrCXPQr1e6gIAQq+l4EahQXdHZ2Rql6buBpbm6Orh5kfbSHnZmFPqd6zRl7R0/WI0eOhEBzfHw8zAcHiWbOILgDAwNBhtTos78gQDgOOG1a3Kd3Eut1dMjYyspKOAt6ZknJK2p99OjRMB8CcwJD+OrKl8O5mZ2dDRQAnktRefYM1A19oTQBUsCkzgnsmc/g4GCYT319fdARoIB6L+/Y2Bh+gNXX1wfdw/rgtKOrtM+vVgMToFdVVQV0jnM/NDQU3XSDXp+ZmQnrg7N2+/Zt29jYCHMiE0NG5eTJk+G5GhoaQpHexMTELjrL7L1bmtra2uzq1aulA5gaWZZ91MyqzOwHzeyVZvYHZvYteZ4/XfQ3586dyz/0oQ9Ze3t7KGggpaV3TU5MTISoHnK+3iahqZ4sy8I9vXqbBPAyQkNRBFVkWjEHdw2lQMqOZqAcGubDHcIgkFT4KYdobm7O3vnOd9rm5qa97W1vC5wamm9ywbdGvp2dnSFqJi1Nc2EEk/L/paWlqNkyvdPgc1FYAXrFXaq0yuGl/exofUKFNBe7axsQsx3nS5sdE3njLGvrExoe6yXxVIfRUmZtbS28D5Hb4uJiQK/MLKB63EmphSP19fUhnYwzr+tEgQZDn6+trc2eeeYZq6+vt9e97nWBo0aqnqbfmoIElWZOGD8UGK1YaCmjVdBaiEJz6tra2qhtgTYCpppaG4VjkEnFoEC5ZYZ+fDi/PT09IeVOF3zeQ6vHtQJdkVW9e5sAhn5cEO1xwnhOeJT0dVNuIWcPUrc240Wp37p1K8h4nueREdaUDjKwtrYWnAJSq5cvXw4FSUtLS1H/MpAqkMu+vr5QQbq0tBRQsytXrgTngLRQdXW19fb2hnYnoDlnzpwJOmJrays8z7Vr1wIqND4+HlKk9NAbGBiwRx55xB5++GE7c+ZMWHuuSJuZmbGrV6/aM888Y88880xEVOdMdXd3B2Tw3LlzYV719fWhyTqoJ+nP5557LmoZAl1jcHDQLly4YC972cvs4YcfDs5LXV1dcHRu3LhhTz/9tD399NMhYzM6OhqCyY6ODnvkkUfskUcesfPnzwcj3NLSEnTOrVu3ArKohRXIaWNjY9jrc+fO2YULF8J8aH+D8b9165Y988wz9vTTT9v169cjNAln+dy5cwEN1P6K6JuxsbGABhKcDg8Ph9Y5R44cSe4596RzjRugxuXLl+3SpUt29erViO6BUzM4OGjnz5+3hx56KOpvCtKnrW3goJLKpXJb0UltOcRYXFwM66MBDs7d+vr6rqbJOMvYEfpDzs7OBmSSO3SnpqZsaWkp2AiKYJgHCDzUKJ/54N963au2odI+oNhGs/tVwHRu8G2j0M0tLS3RhRHIMn1E6SWKvKDTuF70S1/6ks3NzZUOoI4sy5rMbMbMXp7n+aV73/uQmY3kef6TRX9HI2guq9bqO1K2GFgzCwcCXtvJkyejmwIwflNTU8EIASVTfYqDp9ESVY+tra1B+dG5nygQ42hmIdWhfDjleuGIci0UBNePfOQjtra2ZufOnQuNiDkUFGUMDg6GxtONjY3BQSAyAUlA4GmJQ+k974ED2djYGBTa3bt3w9qSirh7925IOdPZnQOrzTfpu6ftHvTKLzMLV0dxSPWyb73bkn0eHR0NyBgVYDQtJaXBHmEsaABLyhZ58ZWfHHb6U6EM9Q5WYH4idXinTz75pC0sLIRmyMiLttjwhUvacgeDTDU2qWAUqyIHKDGaQqPAeCa9TF2DA0UeUWIgPYuLi6HAAF6nRwvb29ujvQap1ZtMlIepVyiy19pqhX0+fvx4SP/keR4CJxA1HCcMDj3yQMIgnutNAqDE8ABv3rwZXavF74KA8h68LwHKyspK1C+MM724uBgQsK6urvAs2vqEsbGxEaGopKK57o4UE0GpIkQ4p5ubmyFdTI+1mzdvJnmN9GuD40pwqYENqWJ/E4imnJkHwW5fX1+YL0g16AloI424zSwEESBNyAzrBjLE1WegVuzz2tpa2A+4qOhegi/QHOU4c1vIrOu1h8NE1gWnDpoQPfEAEqChrK2t7aItKG+7u7s7OMiLi4tRgQJIPvcbwy2DPgQ6qXd1a8U7DtfIyEhAiBWd1IwCWYmOjo5w/hXp4tq+qampcL0glCH2WvlyBMOz93pX6l7DWwU8ULSMvcZJqqmpsdl7TfvHxsai+32xnbT84co4dDiOenNzc6iiBrXHzuJYZlkWFVPqunD1nt6tjrwQ9I2NjVlVVVW4DUg57NrejYBSi250begsArXhy1/+st29e7d0AHVkWfYPzOwv8jxvkO/9r2b22jzP/7n73R8ysx+699+Xm9nfvmgT/cYZ3baTRi/H/VGuSXqU65Ie5brsHuWapEe5LulRrsvucT7P85av901qDmImf49Gs5nNue/Nmdmuhcrz/P1m9n4zsyzLvpLn+Te98NP7xhrluuwe5ZqkR7ku6VGuy+5Rrkl6lOuSHuW67B5Zln3lIN6nau9f+YYai2bW6r7XamYLD2Au5ShHOcpRjnKUoxx/L8dLzQG8ZGY1WZadk+89ZmaFBSDlKEc5ylGOcpSjHIdtvKQcwDzPl8zsE2b2b7Msa8qy7FvN7E1m9qE9/vT9L/jkvjFHuS67R7km6VGuS3qU67J7lGuSHuW6pEe5LrvHgazJS6oIxCz0Afw1M3u9mU2Z2U/u1QewHOUoRznKUY5ylOMwjZecA1iOcpSjHOUoRznKUY7K4yWVAi5HOcpRjnKUoxzlKMfeo3QAy1GOcpSjHOUoRzkO2TjUDmCWZZ1Zln0yy7KlLMtuZln2Lx/0nF7skWVZXZZlH7j3/AtZlj2ZZdl/d+9nQ1mW5VmWLcrrnQ96zi/GyLLsC1mWrcpzX5SffVuWZc9lWbacZdnnsyw7+SDn+mINJweLWZZtZVn2K/d+dmhkJcuyH8my7CtZlq1lWfYb7meFspHtjP8zy7Kpe693Z1xx8RIYReuSZdlrsiz70yzLprMsu5tl2cezLOuXn/9MlmUbTnZOP5CHeAFGhXWpeGZeyvJSYU2+x63H8r01evW9n7/UZaXQHt/7+YHql0PtAJrZe81s3cx6zex7zOzxLMte9mCn9KKPGjO7ZWavNbM2M3unmX0sy7Ih+Z32PM+b773+3QOY44MaPyLPfd7MLMuybtupNH+nmXWa2VfM7Lcf4BxftCFr0Ww7Z2bFzD7ufu0wyModM/s/bKfYLIx9yMYPmdmbbac11aNm9s/M7H9+4af7oo3kuphZh+1ULQ6Z2Unb6cv66+53flvlK8/zay/0ZF/EUbQujKIz81KWl+Sa5Hn+Yadn/rWZXTOzv5ZfeynLSqE9fiH0y6F1ALOde4O/y8zemef5Yp7n/9nMft/MvvfBzuzFHXmeL+V5/jN5nt/I83w7z/PPmNl1M3v1g57b39PxFjN7Os/zj+d5vmpmP2Nmj2VZduHBTutFH281swkz+9KDnsiLPfI8/0Se579nO10GdOwlG99nZu/J8/x2nucjZvYeM/v+F2fWL/woWpc8z//w3prM53m+bGb/3sy+9UHM8UGMCvKy13jJysvzWJPvM7MP5oekWnUPe3zg+uXQOoBm9pCZbeV5fkm+95SZHTYEMBpZlvXaztpo8+ybWZbdzrLs1+9FIYdl/HyWZZNZlv2XLMv+23vfe5ntyImZhd6TV+3wyU2RYj6ssmK2t2xEP7fDq2/+qe1uzv/P76WIn86y7IcfxKQe4Cg6M4daXu6lN/+pmX3Q/ejQyIqzxweuXw6zA7jve4MPy8iyrNbMPmxm/zHP8+ds5wLub7adtM2rbWdtPvzgZviijneY2WkzG7Cd9NWnsyw7Y6XcWJZlg7aToviP8u3DLCuMvWTD/3zOzJpfKryu/Ywsyx41s582s5+Qb3/MzB42sx4z+5/M7KezLPvuBzC9F3vsdWYOu7z8D2b2pTzPr8v3Do2sJOzxgeuXw+wAlvcGy8iyrMp2bkxZN7MfMTO7lxr/Sp7nm3mej9/7/huyLPPr9pIbeZ7/ZZ7nC3mer+V5/h/N7L+Y2XdYKTdmO4r5P6tiPsyyImMv2fA/bzWzxcOS3sqy7KyZ/aGZ/Vie54E6kOf5M3me38nzfCvP878ws1+2HYrBS3rs48wcanmxHT2jQeahkZWUPbYXQL8cZgewvDf43rgXIXzAdoj935Xn+UbBryJIhyUC1ZHbznM/bTtyYmaBS3rGDpfc7FLMiXEYZWUv2Yh+bodI39xL533OzP5dnud7Xc3JWTtsw5+Zwywv32pmx8zsd/b41ZecrFSwxweuXw6tA/h13Bv8UhyP2w6s/s/zPF/hm1mW/cMsy85nWVaVZVmXmf3fZvaFPM89DP2SGlmWtWdZ9u1ZltVnWVaTZdn32A4X5Y/N7JNm9vIsy74ry7J620ln/dd7EP1LfmRZ9i22kxb/uPv+oZGVezJRb2bVZlaNnNjesvFBM/vxLMsGsiw7Zmb/i5n9xgN4hBdkFK1LlmUDZvZnZvbePM/fl/i7N2VZ1nGvjcV/Y2Y/amafenFn/8KNCuuy15l5ycpLhTPE+D4z+908zxfc372kZeXeSNpjeyH0S57nh/ZlO6XUv2dmS2Y2bGb/8kHP6QGswUnbiaJWbQdC5vU9ZvbdtlOBtGRmo/cErO9Bz/lFWJMeM/sr24HWZ83sy2b2evn568zsOdtpg/IFMxt60HN+Edfm/zGzDyW+f2hkxXaq73L3+pm9ZMN2kIp3m9n0vde77d51nC+FV9G6mNm77v1b9cui/N1HbacadPHe2v3og36WF2ldKp6Zl7K87HGG6u/p3W9L/N1LXVYK7fG9nx+ofinvAi5HOcpRjnKUoxzlOGTj0KaAy1GOcpSjHOUoRzkO6ygdwHKUoxzlKEc5ylGOQzZKB7Ac5ShHOcpRjnKU45CN0gEsRznKUY5ylKMc5Thko3QAy1GOcpSjHOUoRzkO2SgdwHKUoxzlKEc5ylGOQzZKB7Ac5ShHOcpRjnKU45CN0gEsRznKUY5ylKMc5Thko3QAy1GOcpTjAEeWZf9flmUfy7Ls32ZZdjXLstUsy/5rlmXf9qDnVo5ylKMcjPImkHKUoxzlOKBx7z7TBTPbNrO/NLP/y3buO/0527lD+Uye55MPbILlKEc5ynFv1Oz9K+UoRznKUY59jkds5y7TL9rO/dFbZmZZlk3bzt2d/8R2LnUvRznKUY4HOsoUcDnKUY5yHNx49b2v/zvO373x3L2vXS/yfMpRjnKUIzlKB7Ac5ShHOQ5uvMrM7uR5/l/c94/d+3r7RZ5POcpRjnIkR+kAlqMc5SjHwY1XmdlI4vv/wsyWzexLL+50ylGOcpQjPUoOYDnKUY5yHMDIsqzKzB4zs6Usy2ryPN+89/1jZvavzezf53m+9CDnWI5ylKMcjLIKuBzlKEc5DmBkWfaImT1tZrdspwjk183suJn9tJlNmdk/zfN89cHNsBzlKEc57o8yBVyOcpSjHAczXnXv63eYWbuZfdrM3m1mnzWzbyudv3KUoxx/n0aZAi5HOcpRjoMZrzaz23me/62Z/bMHPZlylKMc5ag0SgSwHOUoRzkOZrzKzL76oCdRjnKUoxz7GaUDWI5ylKMcX+fIsiwzs1da6QCWoxzl+AYZZRFIOcpRjnKUoxzlKMchGyUCWI5ylKMc5ShHOcpxyEbpAJajHOUoRznKUY5yHLJROoDlKEc5ylGOcpSjHIdslA5gOcpRjnKUoxzlKMchG6UDWI5ylKMc5ShHOcpxyEbpAJajHOUoRznKUY5yHLJROoDlKEc5ylGOcpSjHIds/P8vJCLVEXEK8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i1, i2, crop_i = 100, 101, 150\n",
    "p1, p2, p3 = 22, 60, 35\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(9, 5))\n",
    "ax1.plot([p1, p1], [-1, 1], \"k--\", label=\"$p = {}$\".format(p1))\n",
    "ax1.plot([p2, p2], [-1, 1], \"k--\", label=\"$p = {}$\".format(p2), alpha=0.5)\n",
    "ax1.plot(p3, PE[p3, i1], \"bx\", label=\"$p = {}$\".format(p3))\n",
    "ax1.plot(PE[:,i1], \"b-\", label=\"$i = {}$\".format(i1))\n",
    "ax1.plot(PE[:,i2], \"r-\", label=\"$i = {}$\".format(i2))\n",
    "ax1.plot([p1, p2], [PE[p1, i1], PE[p2, i1]], \"bo\")\n",
    "ax1.plot([p1, p2], [PE[p1, i2], PE[p2, i2]], \"ro\")\n",
    "ax1.legend(loc=\"center right\", fontsize=14, framealpha=0.95)\n",
    "ax1.set_ylabel(\"$P_{(p,i)}$\", rotation=0, fontsize=16)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.hlines(0, 0, max_steps - 1, color=\"k\", linewidth=1, alpha=0.3)\n",
    "ax1.axis([0, max_steps - 1, -1, 1])\n",
    "ax2.imshow(PE.T[:crop_i], cmap=\"gray\", interpolation=\"bilinear\", aspect=\"auto\")\n",
    "ax2.hlines(i1, 0, max_steps - 1, color=\"b\")\n",
    "cheat = 2 # need to raise the red line a bit, or else it hides the blue one\n",
    "ax2.hlines(i2+cheat, 0, max_steps - 1, color=\"r\")\n",
    "ax2.plot([p1, p1], [0, crop_i], \"k--\")\n",
    "ax2.plot([p2, p2], [0, crop_i], \"k--\", alpha=0.5)\n",
    "ax2.plot([p1, p2], [i2+cheat, i2+cheat], \"ro\")\n",
    "ax2.plot([p1, p2], [i1, i1], \"bo\")\n",
    "ax2.axis([0, max_steps - 1, 0, crop_i])\n",
    "ax2.set_xlabel(\"$p$\", fontsize=16)\n",
    "ax2.set_ylabel(\"$i$\", rotation=0, fontsize=16)\n",
    "save_fig(\"positional_embedding_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512; max_steps = 500; vocab_size = 10000\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "positional_encoding = PositionalEncoding(max_steps, max_dims=embed_size)\n",
    "encoder_in = positional_encoding(encoder_embeddings)\n",
    "decoder_in = positional_encoding(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a (very) simplified Transformer (the actual architecture has skip connections, layer norm, dense nets, and most importantly it uses Multi-Head Attention instead of regular Attention):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = encoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, Z])\n",
    "\n",
    "encoder_outputs = Z\n",
    "Z = decoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True, causal=True)([Z, Z])\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, encoder_outputs])\n",
    "\n",
    "outputs = keras.layers.TimeDistributed(\n",
    "    keras.layers.Dense(vocab_size, activation=\"softmax\"))(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a basic implementation of the `MultiHeadAttention` layer. One will likely be added to `keras.layers` in the near future. Note that `Conv1D` layers with `kernel_size=1` (and the default `padding=\"valid\"` and `strides=1`) is equivalent to a `TimeDistributed(Dense(...))` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, n_heads, causal=False, use_scale=False, **kwargs):\n",
    "        self.n_heads = n_heads\n",
    "        self.causal = causal\n",
    "        self.use_scale = use_scale\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.dims = batch_input_shape[0][-1]\n",
    "        self.q_dims, self.v_dims, self.k_dims = [self.dims // self.n_heads] * 3 # could be hyperparameters instead\n",
    "        self.q_linear = keras.layers.Conv1D(self.n_heads * self.q_dims, kernel_size=1, use_bias=False)\n",
    "        self.v_linear = keras.layers.Conv1D(self.n_heads * self.v_dims, kernel_size=1, use_bias=False)\n",
    "        self.k_linear = keras.layers.Conv1D(self.n_heads * self.k_dims, kernel_size=1, use_bias=False)\n",
    "        self.attention = keras.layers.Attention(causal=self.causal, use_scale=self.use_scale)\n",
    "        self.out_linear = keras.layers.Conv1D(self.dims, kernel_size=1, use_bias=False)\n",
    "        super().build(batch_input_shape)\n",
    "    def _multi_head_linear(self, inputs, linear):\n",
    "        shape = K.concatenate([K.shape(inputs)[:-1], [self.n_heads, -1]])\n",
    "        projected = K.reshape(linear(inputs), shape)\n",
    "        perm = K.permute_dimensions(projected, [0, 2, 1, 3])\n",
    "        return K.reshape(perm, [shape[0] * self.n_heads, shape[1], -1])\n",
    "    def call(self, inputs):\n",
    "        q = inputs[0]\n",
    "        v = inputs[1]\n",
    "        k = inputs[2] if len(inputs) > 2 else v\n",
    "        shape = K.shape(q)\n",
    "        q_proj = self._multi_head_linear(q, self.q_linear)\n",
    "        v_proj = self._multi_head_linear(v, self.v_linear)\n",
    "        k_proj = self._multi_head_linear(k, self.k_linear)\n",
    "        multi_attended = self.attention([q_proj, v_proj, k_proj])\n",
    "        shape_attended = K.shape(multi_attended)\n",
    "        reshaped_attended = K.reshape(multi_attended, [shape[0], self.n_heads, shape_attended[1], shape_attended[2]])\n",
    "        perm = K.permute_dimensions(reshaped_attended, [0, 2, 1, 3])\n",
    "        concat = K.reshape(perm, [shape[0], shape_attended[1], -1])\n",
    "        return self.out_linear(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 50, 512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.random.rand(2, 50, 512)\n",
    "V = np.random.rand(2, 80, 512)\n",
    "multi_attn = MultiHeadAttention(8)\n",
    "multi_attn([Q, V]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "_Exercise:_ Embedded Reber grammars _were used by Hochreiter and Schmidhuber in [their paper](https://homl.info/93) about LSTMs. They are artificial grammars that produce strings such as \"BPBTSXXVPSEPE.\" Check out Jenny Orr's [nice introduction](https://homl.info/108) to this topic. Choose a particular embedded Reber grammar (such as the one represented on Jenny Orr's page), then train an RNN to identify whether a string respects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don't._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build a function that generates strings based on a grammar. The grammar will be represented as a list of possible transitions for each state. A transition specifies the string to output (or a grammar to generate it) and the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_reber_grammar = [\n",
    "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
    "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
    "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
    "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
    "    [(\"X\", 3), (\"S\", 6)],\n",
    "    [(\"P\", 4), (\"V\", 6)],\n",
    "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
    "\n",
    "embedded_reber_grammar = [\n",
    "    [(\"B\", 1)],\n",
    "    [(\"T\", 2), (\"P\", 3)],\n",
    "    [(default_reber_grammar, 4)],\n",
    "    [(default_reber_grammar, 5)],\n",
    "    [(\"T\", 6)],\n",
    "    [(\"P\", 6)],\n",
    "    [(\"E\", None)]]\n",
    "\n",
    "def generate_string(grammar):\n",
    "    state = 0\n",
    "    output = []\n",
    "    while state is not None:\n",
    "        index = np.random.randint(len(grammar[state]))\n",
    "        production, state = grammar[state][index]\n",
    "        if isinstance(production, list):\n",
    "            production = generate_string(grammar=production)\n",
    "        output.append(production)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a few strings based on the default Reber grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(default_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's generate a few strings based on the embedded Reber grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need a function to generate strings that do not respect the grammar. We could generate a random string, but the task would be a bit too easy, so instead we will generate a string that respects the grammar, and we will corrupt it by changing just one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
    "    good_string = generate_string(grammar)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few corrupted strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot feed strings directly to an RNN, so we need to encode them somehow. One option would be to one-hot encode each character. Another option is to use embeddings. Let's go for the second option (but since there are just a handful of characters, one-hot encoding would probably be a good option as well). For embeddings to work, we need to convert each string into a sequence of character IDs. Let's write a function for that, using each character's index in the string of possible characters \"BEPSTVX\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 4, 4, 6, 6, 5, 5, 1, 4, 1]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_ids(\"BTTTXXVVETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate the dataset, with 50% good strings, and 50% bad strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size):\n",
    "    good_strings = [string_to_ids(generate_string(embedded_reber_grammar))\n",
    "                    for _ in range(size // 2)]\n",
    "    bad_strings = [string_to_ids(generate_corrupted_string(embedded_reber_grammar))\n",
    "                   for _ in range(size - size // 2)]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
    "    y = np.array([[1.] for _ in range(len(good_strings))] +\n",
    "                 [[0.] for _ in range(len(bad_strings))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, y_train = generate_dataset(10000)\n",
    "X_valid, y_valid = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first training sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int32, numpy=array([0, 4, 0, 2, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What class does it belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We are ready to create the RNN to identify good strings. We build a simple sequence binary classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kleme\\anaconda3\\envs\\ML_Advanced\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/gru_12/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/gru_12/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/gru_12/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 8ms/step - loss: 0.6910 - accuracy: 0.5095 - val_loss: 0.6825 - val_accuracy: 0.5645\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6678 - accuracy: 0.5659 - val_loss: 0.6635 - val_accuracy: 0.6105\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6504 - accuracy: 0.5766 - val_loss: 0.6521 - val_accuracy: 0.6110\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6347 - accuracy: 0.5980 - val_loss: 0.6224 - val_accuracy: 0.6445\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6054 - accuracy: 0.6361 - val_loss: 0.5779 - val_accuracy: 0.6980\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5414 - accuracy: 0.7093 - val_loss: 0.4695 - val_accuracy: 0.7795\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3733 - accuracy: 0.8424 - val_loss: 0.3297 - val_accuracy: 0.8810\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3397 - accuracy: 0.8600 - val_loss: 0.2452 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1636 - accuracy: 0.9491 - val_loss: 0.1054 - val_accuracy: 0.9705\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0668 - accuracy: 0.9836 - val_loss: 0.0240 - val_accuracy: 0.9925\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0529 - val_accuracy: 0.9880\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2052 - accuracy: 0.9290 - val_loss: 0.0950 - val_accuracy: 0.9825\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0462 - accuracy: 0.9890 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.9679e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 7.9697e-04 - accuracy: 1.0000 - val_loss: 6.9065e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 5.8491e-04 - accuracy: 1.0000 - val_loss: 4.7408e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 4.4735e-04 - accuracy: 1.0000 - val_loss: 3.8224e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.6598e-04 - accuracy: 1.0000 - val_loss: 3.2211e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.1071e-04 - accuracy: 1.0000 - val_loss: 2.7499e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "embedding_size = 5\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum = 0.95, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our RNN on two tricky strings: the first one is bad while the second one is good. They only differ by the second to last character. If the RNN gets this right, it shows that it managed to notice the pattern that the second letter should always be equal to the second to last letter. That requires a fairly long short-term memory (which is the reason why we used a GRU cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated probability that these are Reber strings:\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 0.18%\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.96%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
    "\n",
    "y_proba = model.predict(X_test)\n",
    "print()\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta-da! It worked fine. The RNN found the correct answers with very high confidence. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "_Exercise: Train an Encoder–Decoder model that can convert a date string from one format to another (e.g., from \"April 22, 2019\" to \"2019-04-22\")._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the dataset. We will use random days between 1000-01-01 and 9999-12-31:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# cannot use strftime()'s %B format since it depends on the locale\n",
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few random dates, displayed in both the input format and the target format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the list of all possible characters in the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the list of possible characters in the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to convert a string to a list of character IDs, as we did in the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
    "\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version: a very basic seq2seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try the simplest possible model: we feed in the input sequence, which first goes through the encoder (an embedding layer followed by a single LSTM layer), which outputs a vector, then it goes through a decoder (a single LSTM layer, followed by a dense output layer), which outputs a sequence of vectors, each representing the estimated probabilities for all possible output character.\n",
    "\n",
    "Since the decoder expects a sequence as input, we repeat the vector (which is output by the encoder) as many times as the longest possible output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 9s 19ms/step - loss: 1.8114 - accuracy: 0.3499 - val_loss: 1.3780 - val_accuracy: 0.4863\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.2183 - accuracy: 0.5545 - val_loss: 1.0626 - val_accuracy: 0.6155\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.0847 - accuracy: 0.6127 - val_loss: 0.9444 - val_accuracy: 0.6502\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.8502 - accuracy: 0.6962 - val_loss: 0.7680 - val_accuracy: 0.7179\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.5856 - accuracy: 0.7784 - val_loss: 0.4904 - val_accuracy: 0.8067\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.5504 - accuracy: 0.7987 - val_loss: 0.3897 - val_accuracy: 0.8484\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4571 - accuracy: 0.8369 - val_loss: 0.3217 - val_accuracy: 0.8787\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2423 - accuracy: 0.9145 - val_loss: 0.1913 - val_accuracy: 0.9364\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1406 - accuracy: 0.9615 - val_loss: 0.1083 - val_accuracy: 0.9718\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0783 - accuracy: 0.9845 - val_loss: 0.0607 - val_accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1739 - accuracy: 0.9603 - val_loss: 0.0513 - val_accuracy: 0.9919\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0373 - accuracy: 0.9954 - val_loss: 0.0293 - val_accuracy: 0.9970\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0225 - accuracy: 0.9979 - val_loss: 0.0193 - val_accuracy: 0.9987\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 0.0133 - val_accuracy: 0.9991\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1527 - accuracy: 0.9639 - val_loss: 0.0253 - val_accuracy: 0.9983\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0153 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9995\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9998\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0056 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9999\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
    "                           output_dim=embedding_size,\n",
    "                           input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great, we reach 100% validation accuracy! Let's use the model to make some predictions. We will need to be able to convert a sequence of character IDs to a readable string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
    "            for sequence in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model to convert some dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"September 17, 2009\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "#ids = model.predict_classes(X_new)\n",
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since the model was only trained on input strings of length 18 (which is the length of the longest date), it does not perform well if we try to use it to make predictions on shorter sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-02\n",
      "1789-01-14\n"
     ]
    }
   ],
   "source": [
    "#ids = model.predict_classes(X_new)\n",
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! We need to ensure that we always pass sequences of the same length as during training, using padding if necessary. Let's write a little helper function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = X_train.shape[1]\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    #ids = model.predict_classes(X)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Granted, there are certainly much easier ways to write a date conversion tool (e.g., using regular expressions or even basic string manipulation), but you have to admit that using neural networks is way cooler. ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, real-life sequence-to-sequence problems will usually be harder, so for the sake of completeness, let's build a more powerful model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version: feeding the shifted targets to the decoder (teacher forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of feeding the decoder a simple repetition of the encoder's output vector, we can feed it the target sequence, shifted by one time step to the right. This way, at each time step the decoder will know what the previous target character was. This should help is tackle more complex sequence-to-sequence problems.\n",
    "\n",
    "Since the first output character of each target sequence has no previous character, we will need a new token to represent the start-of-sequence (sos).\n",
    "\n",
    "During inference, we won't know the target, so what will we feed the decoder? We can just predict one character at a time, starting with an sos token, then feeding the decoder all the characters that were predicted so far (we will look at this in more details later in this notebook).\n",
    "\n",
    "But if the decoder's LSTM expects to get the previous target as input at each step, how shall we pass it it the vector output by the encoder? Well, one option is to ignore the output vector, and instead use the encoder's LSTM state as the initial state of the decoder's LSTM (which requires that encoder's LSTM must have the same number of units as the decoder's LSTM).\n",
    "\n",
    "Now let's create the decoder's inputs (for training, validation and testing). The sos token will be represented using the last possible output character's ID + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def shifted_output_sequences(Y):\n",
    "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
    "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(Y_train)\n",
    "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
    "X_test_decoder = shifted_output_sequences(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the decoder's training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10), dtype=int32, numpy=\n",
       "array([[12,  8,  1, ..., 10, 11,  3],\n",
       "       [12,  9,  6, ...,  6, 11,  2],\n",
       "       [12,  8,  2, ...,  2, 11,  2],\n",
       "       ...,\n",
       "       [12, 10,  8, ...,  2, 11,  4],\n",
       "       [12,  2,  2, ...,  3, 11,  3],\n",
       "       [12,  8,  9, ...,  8, 11,  3]])>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the model. It's not a simple sequential model anymore, so let's use the functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 9s 19ms/step - loss: 1.6825 - accuracy: 0.3732 - val_loss: 1.4074 - val_accuracy: 0.4687\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.2020 - accuracy: 0.5519 - val_loss: 0.9507 - val_accuracy: 0.6418\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6526 - accuracy: 0.7638 - val_loss: 0.3892 - val_accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2280 - accuracy: 0.9414 - val_loss: 0.1349 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0723 - accuracy: 0.9926 - val_loss: 0.0432 - val_accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0591 - accuracy: 0.9919 - val_loss: 0.0236 - val_accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0317 - accuracy: 0.9962 - val_loss: 0.0192 - val_accuracy: 0.9998\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0119 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "lstm_units = 128\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(INPUT_CHARS) + 1,\n",
    "    output_dim=encoder_embedding_size)(encoder_input)\n",
    "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(\n",
    "    lstm_units, return_state=True)(encoder_embedding)\n",
    "encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(OUTPUT_CHARS) + 2,\n",
    "    output_dim=decoder_embedding_size)(decoder_input)\n",
    "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
    "    decoder_embedding, initial_state=encoder_state)\n",
    "decoder_output = keras.layers.Dense(len(OUTPUT_CHARS) + 1,\n",
    "                                    activation=\"softmax\")(decoder_lstm_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_input, decoder_input],\n",
    "                           outputs=[decoder_output])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model also reaches 100% validation accuracy, but it does so even faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's once again use the model to make some predictions. This time we need to predict characters one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
    "    for index in range(max_output_length):\n",
    "        pad_size = max_output_length - Y_pred.shape[1]\n",
    "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
    "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
    "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
    "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
    "    return ids_to_date_strs(Y_pred[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works fine! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third version: using TF-Addons's seq2seq implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build exactly the same model, but using TF-Addon's seq2seq API. The implementation below is almost very similar to the TFA example higher in this notebook, except without the model input to specify the output sequence length, for simplicity (but you can easily add it back in if you need it for your projects, when the output sequences have very different lengths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - 9s 20ms/step - loss: 1.6782 - accuracy: 0.3654 - val_loss: 1.4655 - val_accuracy: 0.4413\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.3860 - accuracy: 0.4599 - val_loss: 1.2257 - val_accuracy: 0.5235\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.9765 - accuracy: 0.6341 - val_loss: 0.7100 - val_accuracy: 0.7405\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4238 - accuracy: 0.8633 - val_loss: 0.2191 - val_accuracy: 0.9502\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.1285 - accuracy: 0.9798 - val_loss: 0.0645 - val_accuracy: 0.9959\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0783 - accuracy: 0.9890 - val_loss: 0.0848 - val_accuracy: 0.9874\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0287 - accuracy: 0.9990 - val_loss: 0.0188 - val_accuracy: 0.9995\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 0.0121 - val_accuracy: 0.9998\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9999\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9999\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9999\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=15,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again, 100% validation accuracy! To use the model, we can just reuse the `predict_date_strs()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there's a much more efficient way to perform inference. Until now, during inference, we've run the model once for each new character. Instead, we can create a new decoder, based on the previously trained layers, but using a `GreedyEmbeddingSampler` instead of a `TrainingSampler`.\n",
    "\n",
    "At each time step, the `GreedyEmbeddingSampler` will compute the argmax of the decoder's outputs, and run the resulting token IDs through the decoder's embedding layer. Then it will feed the resulting embeddings to the decoder's LSTM cell at the next time step. This way, we only need to run the decoder once to get the full prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes:\n",
    "* The `GreedyEmbeddingSampler` needs the `start_tokens` (a vector containing the start-of-sequence ID for each decoder sequence), and the `end_token` (the decoder will stop decoding a sequence once the model outputs this token).\n",
    "* We must set `maximum_iterations` when creating the `BasicDecoder`, or else it may run into an infinite loop (if the model never outputs the end token for at least one of the sequences). This would force you would to restart the Jupyter kernel.\n",
    "* The decoder inputs are not needed anymore, since all the decoder inputs are generated dynamically based on the outputs from the previous time step.\n",
    "* The model's outputs are `final_outputs.sample_id` instead of the softmax of `final_outputs.rnn_outputs`. This allows us to directly get the argmax of the model's outputs. If you prefer to have access to the logits, you can replace `final_outputs.sample_id` with `final_outputs.rnn_outputs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a simple function that uses the model to perform the date format conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it really is faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.9 ms ± 354 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more than a 10x speedup! And it would be even more if we were handling longer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth version: using TF-Addons's seq2seq implementation with a scheduled sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: due to a TF bug, this version only works using TensorFlow 2.2 or above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we trained the previous model, at each time step _t_ we gave the model the target token for time step _t_ - 1. However, at inference time, the model did not get the previous target at each time step. Instead, it got the previous prediction. So there is a discrepancy between training and inference, which may lead to disappointing performance. To alleviate this, we can gradually replace the targets with the predictions, during training. For this, we just need to replace the `TrainingSampler` with a `ScheduledEmbeddingTrainingSampler`, and use a Keras callback to gradually increase the `sampling_probability` (i.e., the probability that the decoder will use the prediction from the previous time step rather than the target for the previous time step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kleme\\anaconda3\\envs\\ML_Advanced\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_1_grad/Identity_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_1_grad/Identity_3:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_1_grad/Identity_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kleme\\anaconda3\\envs\\ML_Advanced\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/gradients/grad_ys_0_values:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kleme\\anaconda3\\envs\\ML_Advanced\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/basic_decoder_3/decoder/while/gradients/model_5/basic_decoder_3/decoder/while/cond_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 24ms/step - loss: 1.6782 - accuracy: 0.3654 - val_loss: 1.4655 - val_accuracy: 0.4415\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.4054 - accuracy: 0.4526 - val_loss: 1.8386 - val_accuracy: 0.3936\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.0802 - accuracy: 0.5965 - val_loss: 0.9311 - val_accuracy: 0.6471\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.6572 - accuracy: 0.7556 - val_loss: 0.4618 - val_accuracy: 0.8289\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.3831 - accuracy: 0.8669 - val_loss: 0.2745 - val_accuracy: 0.9117\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.2570 - accuracy: 0.9248 - val_loss: 0.1967 - val_accuracy: 0.9442\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.1419 - accuracy: 0.9634 - val_loss: 0.1062 - val_accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0822 - accuracy: 0.9818 - val_loss: 0.0646 - val_accuracy: 0.9862\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0463 - accuracy: 0.9917 - val_loss: 0.0362 - val_accuracy: 0.9944\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.1743 - accuracy: 0.9550 - val_loss: 0.0936 - val_accuracy: 0.9821\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0437 - accuracy: 0.9933 - val_loss: 0.0266 - val_accuracy: 0.9963\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0173 - accuracy: 0.9983 - val_loss: 0.0144 - val_accuracy: 0.9984\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0106 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9990\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 0.9990\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9996\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9997\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0921 - accuracy: 0.9804 - val_loss: 0.0343 - val_accuracy: 0.9934\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.0055 - val_accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_epochs = 20\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(\n",
    "    sampling_probability=0.,\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "# we must set the sampling_probability after creating the sampler\n",
    "# (see https://github.com/tensorflow/addons/pull/1714)\n",
    "sampler.sampling_probability = tf.Variable(0.)\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "def update_sampling_probability(epoch, logs):\n",
    "    proba = min(1.0, epoch / (n_epochs - 10))\n",
    "    sampler.sampling_probability.assign(proba)\n",
    "\n",
    "sampling_probability_cb = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=update_sampling_probability)\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid),\n",
    "                    callbacks=[sampling_probability_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite 100% validation accuracy, but close enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inference, we could do the exact same thing as earlier, using a `GreedyEmbeddingSampler`. However, just for the sake of completeness, let's use a `SampleEmbeddingSampler` instead. It's almost the same thing, except that instead of using the argmax of the model's output to find the token ID, it treats the outputs as logits and uses them to sample a token ID randomly. This can be useful when you want to generate text. The `softmax_temperature` argument serves the \n",
    "same purpose as when we generated Shakespeare-like text (the higher this argument, the more random the generated text will be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_temperature = tf.Variable(1.)\n",
    "\n",
    "inference_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer,\n",
    "    softmax_temperature=softmax_temperature)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
    "    softmax_temperature.assign(temperature)\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates look good at room temperature. Now let's heat things up a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2478505-12', '9262960-01']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"],\n",
    "                           temperature=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, the dates are overcooked, now. Let's call them \"creative\" dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth version: using TFA seq2seq, the Keras subclassing API and attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences in this problem are pretty short, but if we wanted to tackle longer sequences, we would probably have to use attention mechanisms. While it's possible to code our own implementation, it's simpler and more efficient to use TF-Addons's implementation instead. Let's do that now, this time using Keras' subclassing API.\n",
    "\n",
    "**Warning**: due to a TensorFlow bug (see [this issue](https://github.com/tensorflow/addons/issues/1153) for details), the `get_initial_state()` method fails in eager mode, so for now we have to use the subclassing API, as Keras automatically calls `tf.function()` on the `call()` method (so it runs in graph mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, we've reverted back to using the `TrainingSampler`, for simplicity (but you can easily tweak it to use a `ScheduledEmbeddingTrainingSampler` instead). We also use a `GreedyEmbeddingSampler` during inference, so this class is pretty easy to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTranslation(keras.models.Model):\n",
    "    def __init__(self, units=128, encoder_embedding_size=32,\n",
    "                 decoder_embedding_size=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(INPUT_CHARS) + 1,\n",
    "            output_dim=encoder_embedding_size)\n",
    "        self.encoder = keras.layers.LSTM(units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True)\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(OUTPUT_CHARS) + 2,\n",
    "            output_dim=decoder_embedding_size)\n",
    "        self.attention = tfa.seq2seq.LuongAttention(units)\n",
    "        decoder_inner_cell = keras.layers.LSTMCell(units)\n",
    "        self.decoder_cell = tfa.seq2seq.AttentionWrapper(\n",
    "            cell=decoder_inner_cell,\n",
    "            attention_mechanism=self.attention)\n",
    "        output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.TrainingSampler(),\n",
    "            output_layer=output_layer)\n",
    "        self.inference_decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "                embedding_fn=self.decoder_embedding),\n",
    "            output_layer=output_layer,\n",
    "            maximum_iterations=max_output_length)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        encoder_input, decoder_input = inputs\n",
    "        encoder_embeddings = self.encoder_embedding(encoder_input)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = self.encoder(\n",
    "            encoder_embeddings,\n",
    "            training=training)\n",
    "        encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        self.attention(encoder_outputs,\n",
    "                       setup_memory=True)\n",
    "        \n",
    "        decoder_embeddings = self.decoder_embedding(decoder_input)\n",
    "\n",
    "        decoder_initial_state = self.decoder_cell.get_initial_state(\n",
    "            decoder_embeddings)\n",
    "        decoder_initial_state = decoder_initial_state.clone(\n",
    "            cell_state=encoder_state)\n",
    "        \n",
    "        if training:\n",
    "            decoder_outputs, _, _ = self.decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                training=training)\n",
    "        else:\n",
    "            start_tokens = tf.zeros_like(encoder_input[:, 0]) + sos_id\n",
    "            decoder_outputs, _, _ = self.inference_decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=0)\n",
    "\n",
    "        return tf.nn.softmax(decoder_outputs.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "313/313 [==============================] - 13s 26ms/step - loss: 2.1402 - accuracy: 0.2318 - val_loss: 2.1562 - val_accuracy: 0.2234\n",
      "Epoch 2/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.7101 - accuracy: 0.3862 - val_loss: 1.4488 - val_accuracy: 0.4749\n",
      "Epoch 3/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.3075 - accuracy: 0.5143 - val_loss: 1.2592 - val_accuracy: 0.5317\n",
      "Epoch 4/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.9941 - accuracy: 0.2917 - val_loss: 1.8461 - val_accuracy: 0.3819\n",
      "Epoch 5/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.5044 - accuracy: 0.4408 - val_loss: 1.3402 - val_accuracy: 0.4979\n",
      "Epoch 6/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.2795 - accuracy: 0.5191 - val_loss: 1.2222 - val_accuracy: 0.5385\n",
      "Epoch 7/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.1954 - accuracy: 0.5471 - val_loss: 1.1822 - val_accuracy: 0.5439\n",
      "Epoch 8/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.3154 - accuracy: 0.5140 - val_loss: 2.3970 - val_accuracy: 0.1581\n",
      "Epoch 9/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.5823 - accuracy: 0.4473 - val_loss: 3.2734 - val_accuracy: 0.3243\n",
      "Epoch 10/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.2442 - accuracy: 0.5632 - val_loss: 1.1605 - val_accuracy: 0.5606\n",
      "Epoch 11/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.1089 - accuracy: 0.5840 - val_loss: 1.0854 - val_accuracy: 0.5924\n",
      "Epoch 12/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.0118 - accuracy: 0.6105 - val_loss: 1.2534 - val_accuracy: 0.5721\n",
      "Epoch 13/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.9494 - accuracy: 0.6323 - val_loss: 1.0713 - val_accuracy: 0.6302\n",
      "Epoch 14/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.8182 - accuracy: 0.6806 - val_loss: 1.0265 - val_accuracy: 0.6666\n",
      "Epoch 15/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6682 - accuracy: 0.7421 - val_loss: 0.8065 - val_accuracy: 0.7332\n",
      "Epoch 16/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5363 - accuracy: 0.7958 - val_loss: 0.6227 - val_accuracy: 0.7936\n",
      "Epoch 17/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4195 - accuracy: 0.8490 - val_loss: 0.5543 - val_accuracy: 0.8119\n",
      "Epoch 18/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3192 - accuracy: 0.8909 - val_loss: 0.4404 - val_accuracy: 0.8759\n",
      "Epoch 19/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2422 - accuracy: 0.9243 - val_loss: 0.3128 - val_accuracy: 0.9054\n",
      "Epoch 20/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.1791 - accuracy: 0.9512 - val_loss: 0.1954 - val_accuracy: 0.9452\n",
      "Epoch 21/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.1320 - accuracy: 0.9686 - val_loss: 0.2024 - val_accuracy: 0.9314\n",
      "Epoch 22/25\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.1028 - accuracy: 0.9782 - val_loss: 0.1294 - val_accuracy: 0.9700\n",
      "Epoch 23/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0757 - accuracy: 0.9855 - val_loss: 0.0769 - val_accuracy: 0.9837\n",
      "Epoch 24/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0828 - accuracy: 0.9822 - val_loss: 0.0480 - val_accuracy: 0.9955\n",
      "Epoch 25/25\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0506 - accuracy: 0.9921 - val_loss: 0.0788 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = DateTranslation()\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=25,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite 100% validation accuracy, but close. It took a bit longer to converge this time, but there were also more parameters and more computations per iteration. And we did not use a scheduled sampler.\n",
    "\n",
    "To use the model, we can write yet another little function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs_v2(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    X_decoder = tf.zeros(shape=(len(X), max_output_length), dtype=tf.int32)\n",
    "    Y_probas = model.predict([X, X_decoder])\n",
    "    Y_pred = tf.argmax(Y_probas, axis=-1)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs_v2([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a few interesting features from TF-Addons that you may want to look at:\n",
    "* Using a `BeamSearchDecoder` rather than a `BasicDecoder` for inference. Instead of outputing the character with the highest probability, this decoder keeps track of the several candidates, and keeps only the most likely sequences of candidates (see chapter 16 in the book for more details).\n",
    "* Setting masks or specifying `sequence_length` if the input or target sequences may have very different lengths.\n",
    "* Using a `ScheduledOutputTrainingSampler`, which gives you more flexibility than the `ScheduledEmbeddingTrainingSampler` to decide how to feed the output at time _t_ to the cell at time _t_+1. By default it feeds the outputs directly to cell, without computing the argmax ID and passing it through an embedding layer. Alternatively, you specify a `next_inputs_fn` function that will be used to convert the cell outputs to inputs at the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "_Exercise: Go through TensorFlow's [Neural Machine Translation with Attention tutorial](https://homl.info/nmttuto)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply open the Colab and follow its instructions. Alternatively, if you want a simpler example of using TF-Addons's seq2seq implementation for Neural Machine Translation (NMT), look at the solution to the previous question. The last model implementation will give you a simpler example of using TF-Addons to build an NMT model using attention mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.\n",
    "_Exercise: Use one of the recent language models (e.g., GPT) to generate more convincing Shakespearean text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to use recent language models is to use the excellent [transformers library](https://huggingface.co/transformers/), open sourced by Hugging Face. It provides many modern neural net architectures (including BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet and more) for Natural Language Processing (NLP), including many pretrained models. It relies on either TensorFlow or PyTorch. Best of all: it's amazingly simple to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load a pretrained model. In this example, we will use OpenAI's GPT model, with an additional Language Model on top (just a linear layer with weights tied to the input embeddings). Let's import it and load the pretrained weights (this will download about 445MB of data to `~/.cache/torch/transformers`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666a575b6c414f6986179ec20c0baebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/656 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c084541d08c743cc8d10e99770eefbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFOpenAIGPTLMHeadModel.\n",
      "\n",
      "All the layers of TFOpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-gpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFOpenAIGPTLMHeadModel\n",
    "\n",
    "model = TFOpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need a specialized tokenizer for this model. This one will try to use the [spaCy](https://spacy.io/) and [ftfy](https://pypi.org/project/ftfy/) libraries if they are installed, or else it will fall back to BERT's `BasicTokenizer` followed by Byte-Pair Encoding (which should be fine for most use cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c454094b4b459f890deb226cc23251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b26118b87442e88264f7f82dfad54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/448k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad2eeede12c488b8e295e8ef09ec3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTTokenizer\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the tokenizer to tokenize and encode the prompt text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187]])>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = \"This royal throne of kings, this sceptred isle\"\n",
    "encoded_prompt = tokenizer.encode(prompt_text,\n",
    "                                  add_special_tokens=False,\n",
    "                                  return_tensors=\"tf\")\n",
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy! Next, let's use the model to generate text after the prompt. We will generate 5 different sentences, each starting with the prompt text, followed by 40 additional tokens. For an explanation of what all the hyperparameters do, make sure to check out this great [blog post](https://huggingface.co/blog/how-to-generate) by Patrick von Platen (from Hugging Face). You can play around with the hyperparameters to try to obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   239,   781,   575,  5887,   246,  3912,  1347, 36580,\n",
       "          239, 40477,   520,   558,  3637,  2903,   240,   702,  1274,\n",
       "          793,   260,   485,  2150,   481,  3016,   498,   481,  1463,\n",
       "          498, 36580,   488,   513,  1158,   239,   500,   616,   638,\n",
       "          240,   520,   868,  4549,   481],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   812,   580,  7752,   498,   589,  2212,   488, 22600,\n",
       "          240,   488,   481,  1424, 10022,   812,   580,  8084,   702,\n",
       "          481,  4160, 12703,   239,   808,   674,   759,   616,  6404,\n",
       "          580,  3774,   488,   481,  1424,  1114,   498,   481,  3746,\n",
       "         3876,  2821,   580,   492,  3502],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   980,   987,  1074, 13062,   498,  9606,   239,   244,\n",
       "        40477,   246, 11970,   500,   481,  2489,   509,  3807,   504,\n",
       "          531, 31316,   240,  4869, 10826,   240, 14592,   240,   488,\n",
       "        13586,   239,   905,   498,   481, 27497,   641,  2482,   500,\n",
       "         1674, 11953,   240,   568,   481],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   544,   481, 16741,   485,   481,  1424,  1276,   240,\n",
       "          481,  1424,  3476,   260,  3141,   240,   556,  4261,   664,\n",
       "         1885,  1436,   635,  3297,   848,   239, 40477,   481,   908,\n",
       "          485,   481,  1583,  1114,   498,   497,  3446,   509, 16451,\n",
       "          239,   669,   600,  1461,   240],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   544,  2194,   239,   589,   481,  1164,   240,   249,\n",
       "          812,   595, 14482,   566,   728,   485,   580,   634,   811,\n",
       "          622,  3138,  1147,   510,   239,   481, 25577,  2821,  4144,\n",
       "          485,   510,   239,   256, 40477,   487,   999,   481,  3766,\n",
       "          491,  1098,   240,   488,   669]])>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences = 5\n",
    "length = 40\n",
    "\n",
    "generated_sequences = model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    do_sample=True,\n",
    "    max_length=length + len(encoded_prompt[0]),\n",
    "    temperature=1.0,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    num_return_sequences=num_sequences,\n",
    ")\n",
    "\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's decode the generated sequences and print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this royal throne of kings, this sceptred isle. before him knelt a prince called athaliah. \n",
      " she had grown wise, by coming here - to become the queen of the family of athaliah and her father. in this way, she never forgot the\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle will be stripped of all art and riches, and the great halls will be haunted by the ancient wizards. only then can this throne be removed and the great house of the golden star shall be rebuilt\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle has its own guild of kings. \" \n",
      " a siren in the distance was carrying on an orgy, beating drums, chanting, and whistling. most of the travellers were dressed in blue uniforms, but the\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle is the gateway to the great world, the great west - gate, with whom no living god could possibly come. \n",
      " the door to the high house of hador was barred. when they opened,\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle is perfect. all the same, i will not permit one other to be led off our country without me. the messengers shall report to me.'\n",
      " he left the court at once, and when\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sequence in generated_sequences:\n",
    "    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try more recent (and larger) models, such as GPT-2, CTRL, Transformer-XL or XLNet, which are all available as pretrained models in the transformers library, including variants with Language Models on top. The preprocessing steps vary slightly between models, so make sure to check out this [generation example](https://github.com/huggingface/transformers/blob/master/examples/run_generation.py) from the transformers documentation (this example uses PyTorch, but it will work with very little tweaks, such as adding `TF` at the beginning of the model class name, removing the `.to()` method calls, and using `return_tensors=\"tf\"` instead of `\"pt\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you enjoyed this chapter! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
